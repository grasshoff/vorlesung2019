{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain \n",
    "import nltk  #To install this package in windows with conda please run:  'conda install -c anaconda nltk'. to install this package in windows with pip please run: 'pip install nltk'\n",
    "import sklearn\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import sklearn_crfsuite  #to install this package in windows with pip please run: 'pip install sklearn-crfsuite'\n",
    "from sklearn_crfsuite import metrics, scorers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use CoNLL 2002 data to build a NER system\n",
    "\n",
    "CoNLL2002 corpus is available in NLTK. We use Spanish data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package conll2002 to\n",
      "[nltk_data]     C:\\Users\\moha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2002 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk  \n",
    "nltk.download('conll2002')    # the data can be also found here\n",
    "#nltk.corpus.conll2002.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_sents = list(nltk.corpus.conll2002.iob_sents('esp.train')) #The data consists of three files: one training file and two test files testa and testb. \n",
    "test_sents = list(nltk.corpus.conll2002.iob_sents('esp.testb')) #The first test file will be used in the development phase for finding good parameters for the learning system. The second test file will be used for the final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents=train_sents[0:4000]\n",
    "test_sents=test_sents[0:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sents) #sent is abbrivation of sentences! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Random Sample of data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Como', 'CS', 'O'),\n",
       " ('contrapartida', 'NC', 'O'),\n",
       " (',', 'Fc', 'O'),\n",
       " ('Deutsche', 'NC', 'B-ORG'),\n",
       " ('Telekom', 'NC', 'I-ORG'),\n",
       " ('venderá', 'VMI', 'O'),\n",
       " ('al', 'SP', 'O'),\n",
       " ('consorcio', 'NC', 'O'),\n",
       " ('francés', 'AQ', 'O'),\n",
       " ('su', 'DP', 'O'),\n",
       " ('participación', 'NC', 'O'),\n",
       " ('del', 'SP', 'O'),\n",
       " ('25', 'Z', 'O'),\n",
       " ('por', 'SP', 'O'),\n",
       " ('ciento', 'PN', 'O'),\n",
       " ('en', 'SP', 'O'),\n",
       " ('el', 'DA', 'O'),\n",
       " ('empresa', 'NC', 'O'),\n",
       " ('mixta', 'AQ', 'O'),\n",
       " ('británica', 'AQ', 'O'),\n",
       " ('MetroHoldings', 'NC', 'B-ORG'),\n",
       " ('.', 'Fp', 'O')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[20] # 4th sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "Next, define some features. In this example we use word identity, word suffix, word shape and word POS tag; also, some information from nearby words is used. \n",
    "\n",
    "This makes a simple baseline, but you certainly can add and remove some features to get (much?) better results - experiment with it.\n",
    "\n",
    "sklearn-crfsuite (and python-crfsuite) supports several feature formats; here we use feature dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    \n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],        \n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "        \n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "                \n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is what word2features extracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': ',',\n",
       " 'word[-3:]': ',',\n",
       " 'word[-2:]': ',',\n",
       " 'word.isupper()': False,\n",
       " 'word.istitle()': False,\n",
       " 'word.isdigit()': False,\n",
       " 'postag': 'Fc',\n",
       " 'postag[:2]': 'Fc',\n",
       " '-1:word.lower()': 'contrapartida',\n",
       " '-1:word.istitle()': False,\n",
       " '-1:word.isupper()': False,\n",
       " '-1:postag': 'NC',\n",
       " '-1:postag[:2]': 'NC',\n",
       " '+1:word.lower()': 'deutsche',\n",
       " '+1:word.istitle()': True,\n",
       " '+1:word.isupper()': False,\n",
       " '+1:postag': 'NC',\n",
       " '+1:postag[:2]': 'NC'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2features(train_sents[20],2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is what sent2features extracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bias': 1.0,\n",
       "  'word.lower()': 'como',\n",
       "  'word[-3:]': 'omo',\n",
       "  'word[-2:]': 'mo',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'CS',\n",
       "  'postag[:2]': 'CS',\n",
       "  'BOS': True,\n",
       "  '+1:word.lower()': 'contrapartida',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NC',\n",
       "  '+1:postag[:2]': 'NC'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'contrapartida',\n",
       "  'word[-3:]': 'ida',\n",
       "  'word[-2:]': 'da',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NC',\n",
       "  'postag[:2]': 'NC',\n",
       "  '-1:word.lower()': 'como',\n",
       "  '-1:word.istitle()': True,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'CS',\n",
       "  '-1:postag[:2]': 'CS',\n",
       "  '+1:word.lower()': ',',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'Fc',\n",
       "  '+1:postag[:2]': 'Fc'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': ',',\n",
       "  'word[-3:]': ',',\n",
       "  'word[-2:]': ',',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'Fc',\n",
       "  'postag[:2]': 'Fc',\n",
       "  '-1:word.lower()': 'contrapartida',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NC',\n",
       "  '-1:postag[:2]': 'NC',\n",
       "  '+1:word.lower()': 'deutsche',\n",
       "  '+1:word.istitle()': True,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NC',\n",
       "  '+1:postag[:2]': 'NC'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'deutsche',\n",
       "  'word[-3:]': 'che',\n",
       "  'word[-2:]': 'he',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NC',\n",
       "  'postag[:2]': 'NC',\n",
       "  '-1:word.lower()': ',',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'Fc',\n",
       "  '-1:postag[:2]': 'Fc',\n",
       "  '+1:word.lower()': 'telekom',\n",
       "  '+1:word.istitle()': True,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NC',\n",
       "  '+1:postag[:2]': 'NC'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'telekom',\n",
       "  'word[-3:]': 'kom',\n",
       "  'word[-2:]': 'om',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': True,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NC',\n",
       "  'postag[:2]': 'NC',\n",
       "  '-1:word.lower()': 'deutsche',\n",
       "  '-1:word.istitle()': True,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NC',\n",
       "  '-1:postag[:2]': 'NC',\n",
       "  '+1:word.lower()': 'venderá',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'VMI',\n",
       "  '+1:postag[:2]': 'VM'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'venderá',\n",
       "  'word[-3:]': 'erá',\n",
       "  'word[-2:]': 'rá',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'VMI',\n",
       "  'postag[:2]': 'VM',\n",
       "  '-1:word.lower()': 'telekom',\n",
       "  '-1:word.istitle()': True,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NC',\n",
       "  '-1:postag[:2]': 'NC',\n",
       "  '+1:word.lower()': 'al',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'SP',\n",
       "  '+1:postag[:2]': 'SP'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'al',\n",
       "  'word[-3:]': 'al',\n",
       "  'word[-2:]': 'al',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'SP',\n",
       "  'postag[:2]': 'SP',\n",
       "  '-1:word.lower()': 'venderá',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'VMI',\n",
       "  '-1:postag[:2]': 'VM',\n",
       "  '+1:word.lower()': 'consorcio',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NC',\n",
       "  '+1:postag[:2]': 'NC'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'consorcio',\n",
       "  'word[-3:]': 'cio',\n",
       "  'word[-2:]': 'io',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NC',\n",
       "  'postag[:2]': 'NC',\n",
       "  '-1:word.lower()': 'al',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'SP',\n",
       "  '-1:postag[:2]': 'SP',\n",
       "  '+1:word.lower()': 'francés',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'AQ',\n",
       "  '+1:postag[:2]': 'AQ'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'francés',\n",
       "  'word[-3:]': 'cés',\n",
       "  'word[-2:]': 'és',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'AQ',\n",
       "  'postag[:2]': 'AQ',\n",
       "  '-1:word.lower()': 'consorcio',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NC',\n",
       "  '-1:postag[:2]': 'NC',\n",
       "  '+1:word.lower()': 'su',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'DP',\n",
       "  '+1:postag[:2]': 'DP'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'su',\n",
       "  'word[-3:]': 'su',\n",
       "  'word[-2:]': 'su',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'DP',\n",
       "  'postag[:2]': 'DP',\n",
       "  '-1:word.lower()': 'francés',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'AQ',\n",
       "  '-1:postag[:2]': 'AQ',\n",
       "  '+1:word.lower()': 'participación',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NC',\n",
       "  '+1:postag[:2]': 'NC'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'participación',\n",
       "  'word[-3:]': 'ión',\n",
       "  'word[-2:]': 'ón',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NC',\n",
       "  'postag[:2]': 'NC',\n",
       "  '-1:word.lower()': 'su',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'DP',\n",
       "  '-1:postag[:2]': 'DP',\n",
       "  '+1:word.lower()': 'del',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'SP',\n",
       "  '+1:postag[:2]': 'SP'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'del',\n",
       "  'word[-3:]': 'del',\n",
       "  'word[-2:]': 'el',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'SP',\n",
       "  'postag[:2]': 'SP',\n",
       "  '-1:word.lower()': 'participación',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NC',\n",
       "  '-1:postag[:2]': 'NC',\n",
       "  '+1:word.lower()': '25',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'Z',\n",
       "  '+1:postag[:2]': 'Z'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': '25',\n",
       "  'word[-3:]': '25',\n",
       "  'word[-2:]': '25',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': True,\n",
       "  'postag': 'Z',\n",
       "  'postag[:2]': 'Z',\n",
       "  '-1:word.lower()': 'del',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'SP',\n",
       "  '-1:postag[:2]': 'SP',\n",
       "  '+1:word.lower()': 'por',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'SP',\n",
       "  '+1:postag[:2]': 'SP'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'por',\n",
       "  'word[-3:]': 'por',\n",
       "  'word[-2:]': 'or',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'SP',\n",
       "  'postag[:2]': 'SP',\n",
       "  '-1:word.lower()': '25',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'Z',\n",
       "  '-1:postag[:2]': 'Z',\n",
       "  '+1:word.lower()': 'ciento',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'PN',\n",
       "  '+1:postag[:2]': 'PN'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'ciento',\n",
       "  'word[-3:]': 'nto',\n",
       "  'word[-2:]': 'to',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'PN',\n",
       "  'postag[:2]': 'PN',\n",
       "  '-1:word.lower()': 'por',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'SP',\n",
       "  '-1:postag[:2]': 'SP',\n",
       "  '+1:word.lower()': 'en',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'SP',\n",
       "  '+1:postag[:2]': 'SP'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'en',\n",
       "  'word[-3:]': 'en',\n",
       "  'word[-2:]': 'en',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'SP',\n",
       "  'postag[:2]': 'SP',\n",
       "  '-1:word.lower()': 'ciento',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'PN',\n",
       "  '-1:postag[:2]': 'PN',\n",
       "  '+1:word.lower()': 'el',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'DA',\n",
       "  '+1:postag[:2]': 'DA'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'el',\n",
       "  'word[-3:]': 'el',\n",
       "  'word[-2:]': 'el',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'DA',\n",
       "  'postag[:2]': 'DA',\n",
       "  '-1:word.lower()': 'en',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'SP',\n",
       "  '-1:postag[:2]': 'SP',\n",
       "  '+1:word.lower()': 'empresa',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NC',\n",
       "  '+1:postag[:2]': 'NC'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'empresa',\n",
       "  'word[-3:]': 'esa',\n",
       "  'word[-2:]': 'sa',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NC',\n",
       "  'postag[:2]': 'NC',\n",
       "  '-1:word.lower()': 'el',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'DA',\n",
       "  '-1:postag[:2]': 'DA',\n",
       "  '+1:word.lower()': 'mixta',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'AQ',\n",
       "  '+1:postag[:2]': 'AQ'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'mixta',\n",
       "  'word[-3:]': 'xta',\n",
       "  'word[-2:]': 'ta',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'AQ',\n",
       "  'postag[:2]': 'AQ',\n",
       "  '-1:word.lower()': 'empresa',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NC',\n",
       "  '-1:postag[:2]': 'NC',\n",
       "  '+1:word.lower()': 'británica',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'AQ',\n",
       "  '+1:postag[:2]': 'AQ'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'británica',\n",
       "  'word[-3:]': 'ica',\n",
       "  'word[-2:]': 'ca',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'AQ',\n",
       "  'postag[:2]': 'AQ',\n",
       "  '-1:word.lower()': 'mixta',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'AQ',\n",
       "  '-1:postag[:2]': 'AQ',\n",
       "  '+1:word.lower()': 'metroholdings',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'NC',\n",
       "  '+1:postag[:2]': 'NC'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': 'metroholdings',\n",
       "  'word[-3:]': 'ngs',\n",
       "  'word[-2:]': 'gs',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'NC',\n",
       "  'postag[:2]': 'NC',\n",
       "  '-1:word.lower()': 'británica',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'AQ',\n",
       "  '-1:postag[:2]': 'AQ',\n",
       "  '+1:word.lower()': '.',\n",
       "  '+1:word.istitle()': False,\n",
       "  '+1:word.isupper()': False,\n",
       "  '+1:postag': 'Fp',\n",
       "  '+1:postag[:2]': 'Fp'},\n",
       " {'bias': 1.0,\n",
       "  'word.lower()': '.',\n",
       "  'word[-3:]': '.',\n",
       "  'word[-2:]': '.',\n",
       "  'word.isupper()': False,\n",
       "  'word.istitle()': False,\n",
       "  'word.isdigit()': False,\n",
       "  'postag': 'Fp',\n",
       "  'postag[:2]': 'Fp',\n",
       "  '-1:word.lower()': 'metroholdings',\n",
       "  '-1:word.istitle()': False,\n",
       "  '-1:word.isupper()': False,\n",
       "  '-1:postag': 'NC',\n",
       "  '-1:postag[:2]': 'NC',\n",
       "  'EOS': True}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(train_sents[20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is what sent2labels extracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'I-ORG',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-ORG',\n",
       " 'O']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2labels(train_sents[20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features from the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is what sent2tokens extracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Como',\n",
       " 'contrapartida',\n",
       " ',',\n",
       " 'Deutsche',\n",
       " 'Telekom',\n",
       " 'venderá',\n",
       " 'al',\n",
       " 'consorcio',\n",
       " 'francés',\n",
       " 'su',\n",
       " 'participación',\n",
       " 'del',\n",
       " '25',\n",
       " 'por',\n",
       " 'ciento',\n",
       " 'en',\n",
       " 'el',\n",
       " 'empresa',\n",
       " 'mixta',\n",
       " 'británica',\n",
       " 'MetroHoldings',\n",
       " '.']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2tokens(train_sents[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 480 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "To see all possible CRF parameters check its docstring. Here we are useing L-BFGS training algorithm (it is default) with Elastic Net (L1 + L2) regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "There is much more O entities in data set, but we're more interested in other entities. To account for this we'll use averaged F1 score computed for all labels except for O. ``sklearn-crfsuite.metrics`` package provides some useful metrics for sequence classification task, including this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-LOC', 'B-ORG', 'B-PER', 'I-PER', 'B-MISC', 'I-ORG', 'I-LOC', 'I-MISC']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7410293084158585"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "metrics.flat_f1_score(y_test, y_pred, \n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect per-class results in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC      0.753     0.750     0.752      1084\n",
      "       I-LOC      0.548     0.471     0.507       325\n",
      "      B-MISC      0.583     0.434     0.497       339\n",
      "      I-MISC      0.568     0.478     0.519       557\n",
      "       B-ORG      0.797     0.781     0.789      1400\n",
      "       I-ORG      0.797     0.766     0.782      1104\n",
      "       B-PER      0.800     0.861     0.830       735\n",
      "       I-PER      0.858     0.924     0.890       634\n",
      "\n",
      "   micro avg      0.758     0.734     0.746      6178\n",
      "   macro avg      0.713     0.683     0.696      6178\n",
      "weighted avg      0.751     0.734     0.741      6178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# group B and I results\n",
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization\n",
    "\n",
    "To improve quality try to select regularization parameters using randomized search and 3-fold cross-validation.\n",
    "\n",
    "I takes quite a lot of CPU time and RAM (we're fitting a model ``50 * 3 = 150`` times), so grab a tea and be patient, or reduce n_iter in RandomizedSearchCV, or fit model only on a subset of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# define fixed parameters and parameters to search\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score, \n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space, \n",
    "                        cv=3, \n",
    "                        verbose=1, \n",
    "                        n_jobs=-1, \n",
    "                        n_iter=5, \n",
    "                        scoring=f1_scorer)\n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best params: {'c1': 0.18217460758684698, 'c2': 0.07560257235551793}\n",
      "best CV score: 0.7390181562702433\n",
      "model size: 0.71M\n"
     ]
    }
   ],
   "source": [
    "# crf = rs.best_estimator_\n",
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([8.64951833, 8.5536921 , 8.57835658, 8.41075357, 8.46973372]),\n",
       " 'std_fit_time': array([0.53735559, 0.34659121, 0.43728475, 0.27637101, 0.60209581]),\n",
       " 'mean_score_time': array([0.42084988, 0.40203476, 0.43387318, 0.41166766, 0.40605036]),\n",
       " 'std_score_time': array([0.04562385, 0.03890944, 0.0635739 , 0.0514427 , 0.03187468]),\n",
       " 'param_c1': masked_array(data=[0.8356301624778462, 0.41920591435609644,\n",
       "                    1.069675198012202, 0.22905813691576424,\n",
       "                    0.18217460758684698],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_c2': masked_array(data=[0.012143369127797163, 0.21880474484859902,\n",
       "                    0.017487806045237687, 0.13048480853187902,\n",
       "                    0.07560257235551793],\n",
       "              mask=[False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'c1': 0.8356301624778462, 'c2': 0.012143369127797163},\n",
       "  {'c1': 0.41920591435609644, 'c2': 0.21880474484859902},\n",
       "  {'c1': 1.069675198012202, 'c2': 0.017487806045237687},\n",
       "  {'c1': 0.22905813691576424, 'c2': 0.13048480853187902},\n",
       "  {'c1': 0.18217460758684698, 'c2': 0.07560257235551793}],\n",
       " 'split0_test_score': array([0.72842345, 0.7372383 , 0.72395917, 0.74307495, 0.74614973]),\n",
       " 'split1_test_score': array([0.70768122, 0.71664311, 0.69763713, 0.7259048 , 0.72485   ]),\n",
       " 'split2_test_score': array([0.73869515, 0.72886779, 0.73655185, 0.74019111, 0.74604939]),\n",
       " 'mean_test_score': array([0.72493414, 0.72758548, 0.71938386, 0.73639196, 0.73901816]),\n",
       " 'std_test_score': array([0.01289817, 0.00845721, 0.01621123, 0.00750705, 0.01001661]),\n",
       " 'rank_test_score': array([4, 3, 5, 2, 1]),\n",
       " 'split0_train_score': array([0.90165202, 0.94249519, 0.87871466, 0.97759771, 0.9856217 ]),\n",
       " 'split1_train_score': array([0.89688173, 0.93566602, 0.8798509 , 0.97632583, 0.98422192]),\n",
       " 'split2_train_score': array([0.89484683, 0.94074223, 0.8758397 , 0.97803979, 0.98427188]),\n",
       " 'mean_train_score': array([0.89779352, 0.93963448, 0.87813509, 0.97732111, 0.98470517]),\n",
       " 'std_train_score': array([0.00285204, 0.00289594, 0.00168807, 0.00072654, 0.00064841])}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check parameter space\n",
    "\n",
    "A chart which shows which ``c1`` and ``c2`` values have RandomizedSearchCV checked. Red color means better results, blue means worse."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "_x = [s.['c1'] for s in rs.cv_results__]\n",
    "_y = [s.params['c2'] for s in rs.cv_results_]\n",
    "_c = [s.mean_validation_score for s in rs.cv_results_]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(12, 12)\n",
    "ax = plt.gca()\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('C1')\n",
    "ax.set_ylabel('C2')\n",
    "ax.set_title(\"Randomized Hyperparameter Search CV Results (min={:0.3}, max={:0.3})\".format(\n",
    "    min(_c), max(_c)\n",
    "))\n",
    "\n",
    "ax.scatter(_x, _y, c=_c, s=60, alpha=0.9, edgecolors=[0,0,0])\n",
    "\n",
    "print(\"Dark blue => {:0.4}, dark red => {:0.4}\".format(min(_c), max(_c)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check best estimator on our test data\n",
    "\n",
    "As you can see, quality is improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC      0.751     0.744     0.747      1084\n",
      "       I-LOC      0.535     0.446     0.487       325\n",
      "      B-MISC      0.586     0.434     0.498       339\n",
      "      I-MISC      0.557     0.476     0.513       557\n",
      "       B-ORG      0.791     0.778     0.785      1400\n",
      "       I-ORG      0.786     0.769     0.777      1104\n",
      "       B-PER      0.793     0.857     0.824       735\n",
      "       I-PER      0.853     0.918     0.884       634\n",
      "\n",
      "   micro avg      0.752     0.730     0.741      6178\n",
      "   macro avg      0.707     0.678     0.689      6178\n",
      "weighted avg      0.744     0.730     0.736      6178\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crf = rs.best_estimator_\n",
    "y_pred = crf.predict(X_test)\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's check what classifier learned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "B-MISC -> I-MISC  8.185305\n",
      "I-MISC -> I-MISC  7.528064\n",
      "B-LOC  -> I-LOC   6.343427\n",
      "B-PER  -> I-PER   5.832125\n",
      "B-ORG  -> I-ORG   5.709613\n",
      "I-LOC  -> I-LOC   5.365236\n",
      "I-ORG  -> I-ORG   4.828668\n",
      "I-PER  -> I-PER   4.033823\n",
      "O      -> O       3.702218\n",
      "O      -> B-ORG   1.950945\n",
      "O      -> B-PER   1.336051\n",
      "O      -> B-LOC   1.013002\n",
      "O      -> B-MISC  0.911307\n",
      "I-PER  -> B-LOC   0.211734\n",
      "B-LOC  -> B-LOC   0.103000\n",
      "B-ORG  -> O       -0.053004\n",
      "B-MISC -> O       -0.057276\n",
      "B-MISC -> I-LOC   -0.178759\n",
      "B-PER  -> O       -0.248781\n",
      "B-PER  -> I-MISC  -0.255145\n",
      "\n",
      "Top unlikely transitions:\n",
      "I-PER  -> B-MISC  -2.013218\n",
      "I-ORG  -> I-LOC   -2.075814\n",
      "I-MISC -> B-ORG   -2.138798\n",
      "B-LOC  -> I-ORG   -2.161732\n",
      "I-PER  -> I-ORG   -2.164271\n",
      "I-LOC  -> B-LOC   -2.178574\n",
      "I-MISC -> B-LOC   -2.201608\n",
      "I-LOC  -> B-PER   -2.211915\n",
      "I-ORG  -> I-PER   -2.486622\n",
      "I-ORG  -> B-MISC  -2.502074\n",
      "I-PER  -> B-ORG   -2.597654\n",
      "I-PER  -> B-PER   -2.602817\n",
      "I-MISC -> I-ORG   -2.769440\n",
      "B-PER  -> B-PER   -2.848963\n",
      "I-ORG  -> B-LOC   -2.995805\n",
      "B-ORG  -> B-MISC  -3.065439\n",
      "O      -> I-MISC  -4.612669\n",
      "O      -> I-PER   -5.578266\n",
      "O      -> I-LOC   -5.710405\n",
      "O      -> I-ORG   -6.420795\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, for example, it is very likely that the beginning of an organization name (B-ORG) will be followed by a token inside organization name (I-ORG), but transitions to I-ORG from tokens with other labels are penalized.\n",
    "\n",
    "Check the state features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "7.592764 B-ORG    word.lower():psoe-progresistas\n",
      "5.821067 O        BOS\n",
      "4.785025 B-ORG    -1:word.lower():distancia\n",
      "4.777626 B-ORG    word.lower():petrobras\n",
      "4.760178 B-ORG    word[-2:]:-e\n",
      "4.702719 B-MISC   word.lower():cc2305001730\n",
      "4.702719 B-MISC   word[-3:]:730\n",
      "4.498578 B-ORG    word.lower():coag-extremadura\n",
      "4.483249 B-MISC   word.lower():diversia\n",
      "4.454884 B-ORG    word.lower():telefónica\n",
      "4.452901 O        bias\n",
      "4.443639 O        word.lower():r.\n",
      "4.443639 O        word[-3:]:R.\n",
      "4.443032 B-ORG    word.lower():esquerra\n",
      "4.440906 B-ORG    +1:word.lower():plasencia\n",
      "4.422201 O        -1:word.lower():siglo\n",
      "4.400474 B-MISC   word.lower():justicia\n",
      "4.387753 B-ORG    word.lower():terra\n",
      "4.386111 B-MISC   word.lower():exteriores\n",
      "4.344909 O        word.lower():b\n",
      "4.344909 O        word[-3:]:B\n",
      "4.344909 O        word[-2:]:B\n",
      "4.275126 B-PER    -1:word.lower():según\n",
      "4.211182 B-MISC   word.lower():competencia\n",
      "4.137659 B-LOC    -1:word.lower():cantabria\n",
      "4.082948 B-LOC    +1:word.lower():finalizaron\n",
      "4.013310 O        word.lower():c\n",
      "3.919252 B-ORG    word.isupper()\n",
      "3.895734 O        word.lower():v\n",
      "3.817218 B-MISC   word.isupper()\n",
      "\n",
      "Top negative:\n",
      "-1.633054 B-ORG    -1:word.lower():en\n",
      "-1.662825 B-ORG    -1:word.isupper()\n",
      "-1.674484 B-PER    -1:word.lower():en\n",
      "-1.684252 O        word[-2:]:it\n",
      "-1.703974 I-ORG    word[-2:]:re\n",
      "-1.705131 O        +1:word.lower():local\n",
      "-1.707736 O        word[-3:]:man\n",
      "-1.712114 B-MISC   +1:word.lower():al\n",
      "-1.782482 I-ORG    -1:word.lower():estado\n",
      "-1.787681 B-ORG    word[-2:]:ro\n",
      "-1.803629 O        -1:word.lower():número\n",
      "-1.820738 O        word[-3:]:ala\n",
      "-1.881466 O        +1:word.lower():porque\n",
      "-1.904371 I-PER    -1:word.lower():san\n",
      "-1.918831 O        -1:word.lower():país\n",
      "-1.975916 I-LOC    +1:word.lower():del\n",
      "-1.979781 O        -1:word.lower():cristina\n",
      "-1.990812 B-PER    word[-2:]:ón\n",
      "-2.066821 B-PER    word[-2:]:os\n",
      "-2.124422 O        +1:word.lower():acogerá\n",
      "-2.177364 O        -1:word.lower():kaerques\n",
      "-2.345082 B-MISC   -1:word.isupper()\n",
      "-2.382721 O        +1:word.lower():plasencia\n",
      "-2.541276 O        postag:NP\n",
      "-2.541276 O        postag[:2]:NP\n",
      "-2.745134 B-LOC    word[-3:]:ión\n",
      "-3.706699 B-PER    -1:word.lower():del\n",
      "-4.918657 O        word[-2:]:om\n",
      "-6.426601 O        word.isupper()\n",
      "-8.229173 O        word.istitle()\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))    \n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(30))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Some observations:\n",
    "\n",
    "   * **9.385823 B-ORG word.lower():psoe-progresistas** - the model remembered names of some entities - maybe it is overfit, or maybe our features are not adequate, or maybe remembering is indeed helpful;\n",
    "   * **4.636151 I-LOC -1:word.lower():calle:** \"calle\" is a street in Spanish; model learns that if a previous word was \"calle\" then the token is likely a part of location;\n",
    "   * **-5.632036 O word.isupper()**, **-8.215073 O word.istitle()** : UPPERCASED or TitleCased words are likely entities of some kind;\n",
    "   * **-2.097561 O postag:NP** - proper nouns (NP is a proper noun in the Spanish tagset) are often entities.\n",
    "\n",
    "What to do next\n",
    "\n",
    "    * Load 'testa' Spanish data.\n",
    "    * Use it to develop better features and to find best model parameters.\n",
    "    * Apply the model to 'testb' data again.\n",
    "\n",
    "The model in this notebook is just a starting point; you certainly can do better!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
