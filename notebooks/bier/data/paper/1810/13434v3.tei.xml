<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/ResearchCloud/Projects/ExoPlanets/notebooks/grobid/grobid-0.5.2/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.2" ident="GROBID" when="2019-01-22T13:30+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Scientific Domain Knowledge Improves Exoplanet Transit Classification with Deep Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2018-11-22">November 22, 2018</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Megan</forename><surname>Ansdell</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Integrative Planetary Science</orgName>
								<orgName type="institution">University of California at Berkeley</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yani</forename><surname>Ioannou</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Machine Intelligence Lab</orgName>
								<orgName type="institution">University of Cambridge</orgName>
								<address>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hugh</forename><forename type="middle">P</forename><surname>Osborn</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Aix Marseille Univ</orgName>
								<orgName type="institution" key="instit2">CNRS</orgName>
								<orgName type="institution" key="instit3">CNES</orgName>
								<orgName type="institution" key="instit4">Laboratoire d&apos;Astrophysique de Marseille</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michele</forename><surname>Sasdelli</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Australian Institute for Machine Learning</orgName>
								<orgName type="institution">University of Adelaide</orgName>
								<address>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeffrey</forename><forename type="middle">C</forename><surname>Smith</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">NASA Ames Research Center</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">SETI Institute</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Douglas</forename><surname>Caldwell</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">NASA Ames Research Center</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="institution">SETI Institute</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jon</forename><forename type="middle">M</forename><surname>Jenkins</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">NASA Ames Research Center</orgName>
								<address>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Chedy</forename><surname>Räissi</surname></persName>
							<affiliation key="aff6">
								<orgName type="laboratory">Institut national de recherche en informatique et en automatique</orgName>
								<address>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Angerhausen</surname></persName>
							<affiliation key="aff7">
								<orgName type="department">Center for Space and Habitability</orgName>
								<orgName type="institution">University of Bern</orgName>
								<address>
									<country key="CH">Switzerland</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Scientific Domain Knowledge Improves Exoplanet Transit Classification with Deep Learning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2018-11-22">November 22, 2018</date>
						</imprint>
					</monogr>
					<note type="submission">Submitted to ApJ Letters</note>
					<note>Draft version Typeset using L A T E X twocolumn style in AASTeX62 (2018 NASA Frontier Development Lab Exoplanet Mentors) (Accepted November 19, 2018)</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>planets and satellites: detection</keywords>
			</textClass>
			<abstract>
				<p>Space-based missions such as Kepler, and soon TESS, provide large datasets that must be analyzed efficiently and systematically. Recent work by Shallue &amp; Vanderburg (2018) successfully used state-of-the-art deep learning models to automatically classify Kepler transit signals as either exoplanets or false positives; our application of their model yielded 95.8% accuracy and 95.5% average precision. Here we expand upon that work by including additional scientific domain knowledge into the network architecture and input representations to significantly increase overall model performance to 97.5% accuracy and 98.0% average precision. Notably, we achieve 15-20% gains in recall for the lowest signal-to-noise transits that can correspond to rocky planets in the habitable zone. We input into the network centroid time-series information derived from Kepler data plus key stellar parameters taken from the Kepler DR25 and Gaia DR2 catalogues. We also implement data augmentation techniques to alleviate model over-fitting. These improvements allow us to drastically reduce the size of the model, while still maintaining improved performance; smaller models are better for generalization, for example from Kepler to TESS data. This work illustrates the importance of including expert domain knowledge in even state-of-the-art deep learning models when applying them to scientific research problems that seek to identify weak signals in noisy data. This classification tool will be especially useful for upcoming space-based photometry missions focused on finding small planets, such as TESS and PLATO.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">INTRODUCTION</head><p>The past twenty-five years have seen the flourishing of two contemporaneous yet disparate fields-that of exoplanets in astronomy, and that of deep learning in computer science; both have rapidly moved from predominantly theoretical to now largely data-driven regimes. For exoplanet science, this has been powered by the launch of wide-field, high-precision space telescopes designed to search for transiting exoplanets. These facilities-in particular NASA's Kepler Space Telescope (Borucki 2016)-have discovered more than 3,000 confirmed planets (&gt; 70% of the total known; e.g., <ref type="bibr" target="#b5">Borucki et al. 2011;</ref><ref type="bibr" target="#b25">Mayo et al. 2018</ref>), enabling exoplanet population statistics that are revolutionizing our understanding of the universe (e.g., <ref type="bibr" target="#b7">Dressing &amp; Charbonneau 2015;</ref><ref type="bibr" target="#b9">Gaidos et al. 2016</ref>). For deep learning (see re-view in <ref type="bibr" target="#b22">LeCun et al. 2015</ref>), large labelled datasets, increases in computational power, and modern techniques for training deep neural networks have brought about breakthroughs in computer vision, speech recognition, and natural language processing (e.g., <ref type="bibr" target="#b21">Krizhevsky et al. 2012;</ref><ref type="bibr" target="#b15">Ioffe &amp; Szegedy 2015;</ref><ref type="bibr" target="#b12">He et al. 2016</ref>).</p><p>These two fields now intersect in the detection and classification of transit-like signals in the large quantities of data from space-based observatories like Kepler and soon TESS. These data need to be efficiently and reliably vetted for false-positive signals, such as those caused by stellar eclipses and instrumental noise, which largely outnumber the true planet transit signals. In particular, when searching for low signal-to-noise transit signals (e.g., as for small rocky planets in the habitable zone), chance correlations of stochastic instrumental and stellar signals can mimic transiting planet signals, making it extremely difficult to identify real transits just above the noise floor of the data. Deep learning-a machine learning tool named for its use of computational layers-provides a means to tackle these challenges.</p><p>For these reasons, exoplanet transit classification was selected as a project for the 2018 NASA Frontier Development Lab 1 (FDL), an eight-week research incubator aimed at applying cutting-edge machine learning algorithms to challenges in the space sciences. NASA FDL teams consist of two machine learning experts and two space science researchers, with the aim of enabling more effective machine learning models with the help of scientific "domain knowledge"-i.e., the information, insight, or intuition relevant to a specific problem that a domain expert can provide that may not be immediately obvious to others.</p><p>The use of deep learning for automatically classifying candidate exoplanet transit signals has been previously explored by <ref type="bibr" target="#b31">Shallue &amp; Vanderburg (2018)</ref>, who developed a convolutional neural network trained on Kepler data (see also <ref type="bibr" target="#b35">Zucker &amp; Giryes 2018 and</ref><ref type="bibr" target="#b28">Pearson et al. 2018</ref> for applications of neural networks to simulated transit data). They clearly demonstrated the successful application of deep learning to transit classification, however improvements could be made with the inclusion of additional scientific domain knowledge. In this Letter, we present results from the 2018 NASA FDL program that investigated these possibilities. All code and data used in this work is publicly available. Phase <ref type="figure">Figure 1</ref>. The local (left) and global (right) views of the light curves (cyan) and centroids (maroon) for an example confirmed planet (top) and background eclipsing binary (bottom), illustrating how the centroid curves can be used to identify a common type of astrophysical false positive.</p><p>2. DATASETS</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Flux Time Series (Light Curves)</head><p>In this work, we use the Q1-Q17 Kepler Data Release 24 (DR24) light curves from the Mikulski Archive for Space Telescopes. 3 These were produced by the Kepler Science Processing Pipeline ( <ref type="bibr" target="#b17">Jenkins et al. 2010)</ref>, which starts by calibrating the time-series Target Pixel File (TPF) images, then performs fixed-aperture photometry, and removes systematic instrumental errors (e.g., <ref type="bibr" target="#b32">Smith et al. 2012;</ref><ref type="bibr" target="#b33">Stumpe et al. 2012</ref>). Each light curve consists of integrated flux measurements spaced at 30-minute intervals spanning up to 4 years (70,000 points) and contains one or more "threshold crossing events" (TCEs) identified by the Kepler pipeline. Each TCE is a potential exoplanet transit with a given period, epoch, and duration; however, most TCEs will be false-positive signals, sometimes caused by astrophysical phenomana such as eclipsing binaries (EBs) or background eclipsing binaries (BEBs), but also often by instrumental noise artifacts or other spurious events.</p><p>Following <ref type="bibr" target="#b31">Shallue &amp; Vanderburg (2018)</ref>, we perform additional processing of the light curves for each TCE. First, we flatten the light curve by iteratively fitting a basis spline (with the in-transit points of the TCE excluded to preserve the transit signal), then divide the light curve by the best-fit spline while linearly interpolating over the transit points (see <ref type="bibr" target="#b31">Shallue &amp; Vanderburg 2018</ref> for more details and also <ref type="figure" target="#fig_2">Figure 3</ref> in <ref type="bibr" target="#b34">Vanderburg &amp; Johnson 2014</ref> for an illustration of this process). We implement a different spline-fitting routine than <ref type="bibr" target="#b31">Shallue &amp; Vanderburg (2018)</ref>, which results in 5× faster data processing times; namely, we use LSQUnivariateSpline in SciPy rather than bspline in PyDL (a library of Python replacements for IDL built-in functions). Second, we create "global" and "local" views of each phase-folded TCE following the description in <ref type="bibr" target="#b31">Shallue &amp; Vanderburg (2018)</ref>. Both views are scaled so that the continuum is at 0 and the maximum transit depth is at −1. The global view encapsulates the full view of the phase-folded light curve (e.g., including secondary transits of EBs) at the cost of long-period TCEs having poorly sampled transits. The local view, which depends on the transit duration, then provides a more detailed view of the primary transit shape. These two views are illustrated in <ref type="figure">Fig- ure 1</ref> and used as inputs into the deep learning models implemented in this work (see <ref type="figure" target="#fig_0">Figure 2</ref>; Section 3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Centroid Time Series (Centroid Curves)</head><p>We also use the time-series of the pixel position of the center of light (centroid) measured by the Kepler pipeline from the same TPF as the flux time series (Section 2.1). Centroids provide information on the position of the source of the transit-like signal, which is particularly useful for identifying BEBs. This is because centroids will shift in the opposite direction of the BEB if both the BEB and target star are contained within the photometric aperture used to measure the flux. We use the flux-weighted (first moment) centroids rather than the pixel response function (PRF) centroids; although the PRF centroids are more robust against background noise, a significant number of sources do not have PRF centroid information, which complicates implementation of machine learning algorithms.</p><p>We use the x and y pixel coordinates of the centroid to compute the absolute magnitude (r = x 2 + y 2 ) of the centroid displacement from the TPF center. We then follow the same process as the light curves for smoothing, phase-folding, and translating into local and global views. However, rather than normalizing the centroid curve to the maximum transit depth, we subtract the median and divide by the standard deviation, where these values are calculated out-of-transit and across the entire training dataset (this standard practice is called "normalization" in machine learning). Moreover, we normalize the standard deviation of the centroid curves by that of the light curves, which ensures that TCEs with no significant centroid shifts show flat lines with noise signal strengths similar to that of the light curves (and thus do not dominate the signal strengths). Example phase-folded light curves and associated centroid curves, for both global and local views, are given in Figure 1 for a confirmed exoplanet and BEB.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Stellar Parameters</head><p>We use the updated Kepler DR25 catalogue of <ref type="bibr" target="#b24">Mathur et al. (2017)</ref> to obtain intrinsic stellar parameters. These parameters consist of stellar effective temperature (T eff ), surface gravity (log g), metallicity ( <ref type="bibr">[Fe/H]</ref>), radius (R ), mass (M ), and density (ρ ). These stellar parameters are normalized (Section 2.2): we subtract the median and divide by the standard deviation, where these values are calculated for each parameter across the entire training set, such that the distribution of each parameter has a median of 0.0 and standard deviation of 1.0. We note that we tested the inclusion of proper motions and parallaxes from the Gaia DR2 catalogue ( <ref type="bibr">Gaia Col- laboration et al. 2018</ref>), but found no improvement in model performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Labels</head><p>We use the same labels as <ref type="bibr" target="#b31">Shallue &amp; Vanderburg (2018)</ref>, which are taken from the Kepler DR24 TCE Table available on the NASA Exoplanet Archive. <ref type="bibr">4</ref> The av training set column contains the labels used to train the Autovetter ( <ref type="bibr" target="#b26">McCauliff et al. 2015</ref>) and primarily come from human-vetted KOIs assembled from multiple papers (e.g. <ref type="bibr" target="#b5">Borucki et al. 2011;</ref><ref type="bibr" target="#b3">Batalha et al. 2013;</ref><ref type="bibr" target="#b6">Burke et al. 2014</ref>). The av training set column has four possible values: planet candidate (PC), astrophysical false positive (AFP), non-transiting phenomenon (NTP), and unknown (UNK). Following Shallue &amp; Vanderburg (2018), we ignore the UNK TCEs (4,630 entries) and then binarize the remaining labels as "planet" (PC; 3,600 entries) or "false positive" (AFP + NTP; 12,137 entries). We then randomly divide the TCEs into training (80%), validation (10%), and test (10%) sets using the same random seed as <ref type="bibr" target="#b31">Shallue &amp; Vanderburg (2018)</ref> to preserve comparability. We use the validation set to tune hyperparameters and the test set for our final model performance results (Section 4).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">MACHINE LEARNING MODELS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Astronet: Baseline Model</head><p>Here we briefly summarize Astronet, the deep convolution neural network developed by Shallue &amp; Vanderburg (2018) that we use as our baseline model. Astronet is implemented in TensorFlow ( <ref type="bibr" target="#b0">Abadi et al. 2016</ref>), an open source software library for machine learning originally developed at Google Brain. As shown in ing, the results of which are concatenated and then fed into a series of fully connected layers ending in a sigmoid function that produces an output in the range (0,1) that loosely represents the likeliness of a given TCE being a true planet transit (1) or false positive (0). For model training, Astronet uses the Adam optimization algorithm <ref type="bibr" target="#b19">(Kingma &amp; Ba 2014</ref>) to minimize the cross-entropy error function. During training, data are augmented by applying time inversions to the input light curves with a 50% chance. The Google-Vizier system ( <ref type="bibr" target="#b10">Golovin et al. 2017</ref>) automatically tunes the hyperparameters of the input representations, model architecture, and training; consequently, the model is trained with a batch size of 64 for 50 epochs, and the Adam optimizer is implemented with a learning rate of α = 10 −5 , exponential decay rates of β 1 = 0.9 and β 2 = 0.999, and = 10 −8 (see <ref type="bibr" target="#b19">Kingma &amp; Ba 2014</ref> for details on these parameters). <ref type="bibr" target="#b31">Shallue &amp; Vanderburg (2018)</ref> use model "ensembling" to average the results from 10 independently trained version of the same model with different random parameter initializations. Ensembling makes comparisons between different model architectures more robust because it averages over the stochastic differences in the individual models due to their different random parameter initializations. Moreover, ensembling improves model performance because the individual models can perform slightly better (or worse) in different regions of input space, in particular when the training set is small and thus prone to over-fitting.</p><p>As part of this work, we re-implemented Astronet in PyTorch ( <ref type="bibr" target="#b27">Paszke et al. 2017</ref>) in an effort to expand the user base to those unfamiliar with TensorFlow. Our Astronet performance results given in <ref type="table" target="#tab_0">Table 1</ref> are consistent with those reported in <ref type="bibr" target="#b31">Shallue &amp; Vanderburg (2018)</ref>; for example, we find an accuracy of 0.958 compared to their 0.960 value. We use the values in <ref type="table" target="#tab_0">Table 1</ref> as our baseline for comparison in the rest of this work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Exonet: Revised Model with Domain Knowledge</head><p>Here we use scientific domain knowledge to add several features to our baseline Astronet model architecture and input representations in an effort to increase model performance. This modified model, which we call Exonet, is illustrated in <ref type="figure" target="#fig_0">Figure 2</ref> and compared to the baseline Astronet model. The key modifications are described below. For model training, we retain the use of the Adam optimizer, cross-entropy loss function, batch size of 64, and learning rate of α = 10 −5 used by Astronet (Section 3.1).</p><p>Addition of centroid time-series: we input our analogous global and local views of the centroid timeseries data (Section 2.2) as second channels of the disjoint convolutional columns used for the light curves. The motivation behind this architecture is to help the model learn the connections between the shapes of the light curves and centroid curves, which can be useful for identifying false positives, in particular BEBs <ref type="figure">(Figure 1)</ref>. We note that the addition of centroid information was suggested by <ref type="bibr" target="#b31">Shallue &amp; Vanderburg (2018)</ref> as a potential avenue for improvement.</p><p>Addition of stellar parameters: we concatenate the stellar parameters (Section 2.3) to the flattened outputs of the convolutional layers directly before feeding them into the shared fully connected layers. We add this information because stellar parameters are likely correlated with classification, for example giant stars with large radii are far more likely to host stellar eclipses than planetary transits (which would be undetectable).</p><p>Augmentation of training data: the baseline Astronet model augments the data by randomly flipping the time axis of half the input light curves during training. We adopt this data augmentation technique, also applying the time-axis flip to the associated centroid curves. Because the training set is still quite small compared to typical machine learning problems, and because we found that Astronet suffers from model over-fitting, we apply an additional data augmentation technique during training to mimic measurement uncertainties in the flux measurements. Namely, we add random Gaussian noise to each input light curve, where the standard deviation is randomly chosen from a uniform distribution between 0 and 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Exonet-XS: Reduced Model Size</head><p>With the additions described in Section 3.2, we find that we can drastically reduce the size of the model architecture while still maintaining improved performance. This reduced model architecture, which we call Exonet-XS, is illustrated in <ref type="figure" target="#fig_0">Figure 2</ref>. We reduce the number of convolutional layers from 4 to 2 for the local column and from 10 to 3 for the global column. We also introduce global max pooling at the output of each convolutional column, as global max/average pooling has been shown to reduce the number of model parameters while increasing generalization ( <ref type="bibr" target="#b23">Lin et al. 2013;</ref><ref type="bibr" target="#b14">Ioannou et al. 2016)</ref>, and is used in most state-of-the-art models for ImageNet (e.g., <ref type="bibr" target="#b12">He et al. 2016</ref>). Exonet-XS has a model size 0.07% that of the full Astronet model with 5×10 −4 fewer trainable parameters. Smaller models are often preferred, as they generalize better (or overfit less) ( <ref type="bibr" target="#b11">Hastie et al. 2001)</ref>. Thus Exonet-XS should perform better when re-trained on other datasets, for example those expected from TESS. To assess model performance, we use three key metrics: accuracy, average precision, and precision-recall curves. Accuracy is the fraction of correct classifications by the model, for both planets and false-positives, at a given threshold for deciding when the model output in the range (0,1) becomes a positive class; we use a threshold of 0.5 for our accuracy calculations. Precision is the fraction of transits classified as planets that are true planets, while recall is the fraction of true planets recovered by the model; these can then be plotted on a precision-recall curve, which shows the trade-off between precision and recall for different thresholds. The average precision summarizes the precision-recall curve as the weighted mean of precisions achieved at each threshold. <ref type="table" target="#tab_0">Table 1</ref> gives the ensembled results on the test set, showing the 1.7% increase in accuracy and 2.5% increase in average precision of Exonet over Astronet. For the reduced Exonet-XS model, we see a 0.8% increase in accuracy and 0.8% increase in average precision. We also show results for the reduced model without the additions described in Section 3.2 (Astronet-XS), to illustrate that the gains in performance are still due to the inclusion of new scientific domain knowledge, rather than the change in model architecture. <ref type="figure" target="#fig_2">Figure 3</ref> shows precision-recall curves with each component of scientific domain knowledge added individually to illustrate their separate contributions to improving model performance. For this, we use k-fold crossvalidation on the combined training and validation sets. Cross validation is a method of evaluating model generalization performance that is more robust than using training and test sets; in k-folds cross-validation, the data is instead split repeatedly into k parts of equal size and multiple models are trained (here we use k = 5, which is typical). <ref type="figure" target="#fig_2">Figure 3</ref> shows that the addition of the centroid time series provides the biggest gain in model performance, while stellar parameters also make a significant impact. Data augmentation does not greatly increase model performance by itself, rather the main benefit is to alleviate model over-fitting. Exonet-Centroids is just the addition of the centroid curves, Exonet-Stellar is just the addition of the stellar parameters, and Exonet-Augmented is just the addition of our supplementary data augmentations. Exonet then combines all of these improvements into a single model. <ref type="figure">Figure 4</ref> then shows the precision and recall as a function of a measure of the signal-to-noise of the candidate transits-the so-called "multiple event statistic" (MES; <ref type="bibr" target="#b16">Jenkins et al. 2002</ref>) that the Kepler pipeline reports with each TCE. Notably, Exonet shows 15-20% increases in recall for low-MES transits that often correspond to Earth-sized planets, some of which are in the habitable zone. The scatter in model performance at a given MES value is also noticeably smaller for Exonet, reflecting the robustness of the model. Note we do not perform hyperparameter optimization for Exonet and Exonet-XS, thus the model results could still be improved.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">CONCLUSIONS</head><p>We expanded upon the method of Shallue &amp; Vanderburg (2018) for applying deep learning to automatically classify Kepler candidate transit events with the addition of scientific domain knowledge. We used as our baseline model their convolutional neural network architecture, Astronet, which inputs "global" and "local" views of the phase-folded light curves through disjoint one-dimensional convolutional columns followed by shared fully connected layers that output a number in the range (0,1) that approximates the likeliness of a transit being a planet (1) or a false positive (0). For our modified model, which we call Exonet, we created analogous global and local views of the centroid time-series data and input them as second channels of the disjoint convolutional columns, mainly to help identify BEBs. We then also concatenated key stellar parameters to the flattened outputs of the convolutional layers before feeding them into the shared fully connected layers; this helped to identify other types of false positives, such as giant star eclipsing binaries. Because we found that Astronet was prone to over-fitting, we also implemented data augmentation during training. Astronet already performed random time-axis reflections on the light curves, which we adopted and also applied to the corresponding centroid time series. Furthermore, we added random Gaussian noise to the input light curves to simulate uncertainties on the flux measurements.</p><p>These additions of scientific domain knowledge to the model architecture and input representations significantly improved the model accuracy and average precision by 2.0-2.5%, which is notable given the already impressive performance of Astronet prior to this work. Moreover, we showed that these gains in model performance are disproportionately high for low signal-to-noise transits that can represent the most interesting cases of rocky planets in the habitable zone. This demonstrates the importance of including domain knowledge in even state-of-the-art machine learning models when applying them to scientific research problems that seek to identify weak signals in noisy data. This classification tool will be especially useful for upcoming space-based photometry missions focused on finding small planets, such as TESS ( <ref type="bibr" target="#b30">Ricker et al. 2014</ref>) and PLATO ( <ref type="bibr" target="#b29">Rauer et al. 2014</ref>). A forthcoming paper will document the application of our deep learning model to simulated TESS data ( <ref type="bibr">Osborn et al., in prep)</ref>. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>2 1</head><label>2</label><figDesc>http://frontierdevelopmentlab.org 2 http://gitlab.com/frontierdevelopmentlab/exoplanets</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 ,Figure 2 .</head><label>22</label><figDesc>Figure 2. The convolutional neural network architectures used in this work. Left: Exonet, where the additions over the baseline Astronet model are shown in blue (Section 3.2). The flattened outputs of the disjoint one-dimensional convolutional columns are concatenated with the stellar parameters, then fed into the fully connected layers ending in a sigmoid function. Following Shallue &amp; Vanderburg (2018), the convolutional layers are denoted as CONV-kernel size-number of feature maps, the max pooling layers are denoted as MAXPOOL-window length-stride length, and the fully connected layers are denoted as FC-number of units. Right: the significantly reduced Exonet-XS model version described in Section 3.3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Precision-recall curve of Astronet (Section 3.1) compared to those of Exonet (Section 3.2) with different additions of scientific domain knowledge to show the individual contributions to increases in model performance. Exonet-Centroids is just the addition of the centroid curves, Exonet-Stellar is just the addition of the stellar parameters, and Exonet-Augmented is just the addition of our supplementary data augmentations. Exonet then combines all of these improvements into a single model.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Software: Astropy (Astropy Collaboration et al. 2013, 2018), PyTorch (Paszke et al. 2017), Astronet (Shallue &amp; Vanderburg 2018), Jupyter (Kluyver et al. 2016), SciPy (Jones et al. 2001-), TensorFlow (Abadi et al. 2016), Mat- plotlib (Hunter 2007). We gratefully thank Google Cloud for providing the compute and storage resources critical to completing this work. MA also gratefully acknowledges the NVIDIA Corporation for donating the Quadro P6000 GPU used for this research. We thank Adam Lesnikowski, Noa Kel, Hamed Valizadegan, Yarin Gal, and Richard Galvez for their helpful discussions. This paper includes data from the Kepler mission; funding for Kepler is pro- vided by the NASA Science Mission directorate. The data used in this paper were obtained from the Mikul- ski Archive for Space Telescopes (MAST). STScI is operated by the Association of Universities for Re- search in Astronomy, Inc., under NASA contract NAS5- 26555. MA also acknowledges support from NSF grant AST-1518332 and NASA grants NNX15AC89G and NNX15AD95G/NEXSS. HPO acknowledges support from Centre National d'Etudes Spatiales (CNES) grant 131425-PLATO.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 . Ensembled Results on Test Set</head><label>1</label><figDesc></figDesc><table>Model 
Accuracy Avg. Precision 

Astronet 
0.958 
0.955 

Exonet 
0.975 
0.980 

Astronet-XS 
0.953 
0.936 

Exonet-XS 
0.966 
0.963 

4. RESULTS 

</table></figure>

			<note place="foot" n="3"> http://archive.stsci.edu/kepler</note>

			<note place="foot" n="4"> http://exoplanetarchive.ipac.caltech.edu/</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Abadi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Agarwal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Barham</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1603.04467</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
<note type="report_type">ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Robitaille</surname></persName>
			<affiliation>
				<orgName type="collaboration">Astropy Collaboration</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Tollerud</surname></persName>
			<affiliation>
				<orgName type="collaboration">Astropy Collaboration</orgName>
			</affiliation>
		</author>
	</analytic>
	<monogr>
		<title level="j">A&amp;A</title>
		<imprint>
			<biblScope unit="volume">558</biblScope>
			<biblScope unit="page">33</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Price-Whelan</surname></persName>
			<affiliation>
				<orgName type="collaboration">Astropy Collaboration</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Sip˝ Ocz</surname></persName>
			<affiliation>
				<orgName type="collaboration">Astropy Collaboration</orgName>
			</affiliation>
		</author>
	</analytic>
	<monogr>
		<title level="j">AJ</title>
		<imprint>
			<biblScope unit="volume">156</biblScope>
			<biblScope unit="page">123</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Batalha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Rowe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Bryson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ApJS</title>
		<imprint>
			<biblScope unit="volume">204</biblScope>
			<biblScope unit="page">24</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Borucki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Reports on Progress in Physics</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page">36901</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Borucki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Basri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ApJ</title>
		<imprint>
			<biblScope unit="volume">736</biblScope>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Bryson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Mullally</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ApJS</title>
		<imprint>
			<biblScope unit="volume">210</biblScope>
			<biblScope unit="page">19</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Dressing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Charbonneau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ApJ</title>
		<imprint>
			<biblScope unit="volume">807</biblScope>
			<biblScope unit="page">45</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G A</forename><surname>Brown</surname></persName>
			<affiliation>
				<orgName type="collaboration">Gaia Collaboration</orgName>
			</affiliation>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vallenari</surname></persName>
			<affiliation>
				<orgName type="collaboration">Gaia Collaboration</orgName>
			</affiliation>
		</author>
	</analytic>
	<monogr>
		<title level="j">A&amp;A</title>
		<imprint>
			<biblScope unit="volume">616</biblScope>
			<biblScope unit="page">1</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Gaidos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Mann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Kraus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ireland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MNRAS</title>
		<imprint>
			<biblScope unit="volume">457</biblScope>
			<biblScope unit="page">2877</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Golovin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Solnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Moitra</surname></persName>
		</author>
		<ptr target="http://www.kdd.org/kdd2017/papers/view/google-vizier-a-service-for-black-box-optimization" />
		<title level="m">Google Vizier: A Service for Black-Box Optimization</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tibshirani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Elements of Statistical Learning</title>
		<meeting><address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Springer New York Inc</publisher>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>He</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sun</surname></persName>
		</author>
		<title level="m">14th European Conference on Computer Vision (ECCV)</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2016" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="630" to="645" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Hunter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing In Science &amp; Engineering</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">90</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ioannou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Shotton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cipolla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Criminisi</surname></persName>
		</author>
		<title level="m">International Conference on Learning Representations</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>ICLR</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
		<title level="m">Proceedings of the 32nd International Conference on Machine Learning (ICML)</title>
		<editor>F. R. Bach &amp; D. M. Blei</editor>
		<meeting>the 32nd International Conference on Machine Learning (ICML)</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Caldwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Borucki</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ApJ</title>
		<imprint>
			<biblScope unit="volume">564</biblScope>
			<biblScope unit="page">495</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Caldwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chandrasekaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ApJL</title>
		<imprint>
			<biblScope unit="volume">713</biblScope>
			<biblScope unit="page">87</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Oliphant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Peterson</surname></persName>
		</author>
		<title level="m">SciPy: Open source scientific tools for Python</title>
		<imprint>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note>Online</note>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>ArXiv e-prints</note>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kluyver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ragan-Kelley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pérez</surname></persName>
		</author>
		<title level="m">Positioning and Power in Academic Publishing: Players, Agents and Agendas</title>
		<editor>F. Loizides &amp; B. Schmidt</editor>
		<imprint>
			<publisher>IOS Press</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="87" to="90" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krizhevsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sutskever</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">E</forename><surname>Hinton</surname></persName>
		</author>
		<title level="m">Proceedings of the 25th International Conference on Neural Information Processing Systems (NIPS)</title>
		<meeting>the 25th International Conference on Neural Information Processing Systems (NIPS)</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1097" to="1105" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lecun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bengio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">521</biblScope>
			<biblScope unit="page">436</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Yan</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.4400</idno>
		<ptr target="http://arxiv.org/abs/1312.4400" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mathur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Batalha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Astrophysical Journal Supplement Series</title>
		<imprint>
			<biblScope unit="volume">229</biblScope>
			<biblScope unit="page">30</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Mayo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vanderburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Latham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AJ</title>
		<imprint>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="page">136</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Mccauliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Catanzarite</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Astrophysical Journal</title>
		<imprint>
			<biblScope unit="volume">806</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Paszke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chintala</surname></persName>
		</author>
		<title level="m">NIPS-W</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Pearson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Palafox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Griffith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MNRAS</title>
		<imprint>
			<biblScope unit="volume">474</biblScope>
			<biblScope unit="page">478</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Catala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Aerts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Experimental Astronomy</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page">249</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Ricker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Winn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vanderspek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. SPIE</title>
		<meeting>SPIE</meeting>
		<imprint>
			<publisher>Optical, Infrared, and Millimeter Wave</publisher>
			<date type="published" when="2014" />
			<biblScope unit="volume">9143</biblScope>
			<biblScope unit="page">914320</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Shallue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vanderburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AJ</title>
		<imprint>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="page">94</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Stumpe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Van Cleve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PASP</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page">1000</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Stumpe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Van Cleve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PASP</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page">985</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vanderburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PASP</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="page">948</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Giryes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">AJ</title>
		<imprint>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="page">147</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
