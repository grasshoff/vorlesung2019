<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/ResearchCloud/Projects/ExoPlanets/notebooks/grobid/grobid-0.5.2/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.2" ident="GROBID" when="2018-12-04T16:02+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Experimental design and model selection: The example of exoplanet detection</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2008-02-04">4 Feb 2008</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vijay</forename><surname>Balasubramanian</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">David Rittenhouse Laboratories</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<postCode>19104</postCode>
									<settlement>Philadelphia</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">School of Natural Sciences</orgName>
								<orgName type="department" key="dep2">Institute for Advanced Study</orgName>
								<address>
									<postCode>08540</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Introduction</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Klaus</forename><surname>Larjo</surname></persName>
							<email>klarjo@physics.upenn.edu</email>
							<affiliation key="aff0">
								<orgName type="department">David Rittenhouse Laboratories</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<postCode>19104</postCode>
									<settlement>Philadelphia</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Introduction</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ravi</forename><surname>Sheth</surname></persName>
							<email>shethrk@physics.upenn.edu</email>
							<affiliation key="aff0">
								<orgName type="department">David Rittenhouse Laboratories</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<postCode>19104</postCode>
									<settlement>Philadelphia</settlement>
									<region>PA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Introduction</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Experimental design and model selection: The example of exoplanet detection</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2008-02-04">4 Feb 2008</date>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We apply the Minimum Description Length model selection approach to the detection of extra-solar planets, and use this example to show how specification of the experimental design affects the prior distribution on the model parameter space and hence the posterior likelihood which, in turn, determines which model is regarded as most &apos;correct&apos;. Our analysis shows how conditioning on the experimental design can render a non-compact parameter space effectively compact, so that the MDL model selection problem becomes well-defined.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>The Bayesian approach to parametric model selection requires the specification of a prior probability distribution over the parameter space. The Jeffreys' prior, which is proportional to the square root of the determinant of the Fisher information computed in the parameter space, has been shown to be the uniform prior over all distributions indexed by the parameters in a parametric family <ref type="bibr" target="#b0">[1]</ref>. Geometrically, its integral over a region of the parameter space computes a volume that essentially measures the fraction of statistically distinguishable probability distributions within that region <ref type="bibr" target="#b0">[1]</ref>. In this interpretation, the Jeffreys prior distribution</p><formula xml:id="formula_0">ω(Θ) = det J ij (Θ) d d Θ det J ij (Θ) d d Θ<label>(1)</label></formula><p>where Θ = {θ 1 , · · · , θ d } simply measures the fractional volume of the small element d d Θ relative to total volume of the parametric manifold</p><formula xml:id="formula_1">V = d d Θ det J ij (Θ).</formula><p>Here J ij is the Fisher information on the parameter space Θ ∈ R d and d d Θ is the standard Riemannian volume element on R d . The volume V also appears in the Minimum Description Length (MDL) approach to model selection <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b2">3]</ref>, conceptually because it effectively measures how many different distributions are describable by different parameter choices.</p><p>An important difficulty in applying the MDL approach to model selection occurs when the parameter space is noncompact and the volume V diverges. In this case, from the Bayesian perspective, a uniform prior on the parameter space does not exist, while from the MDL perspective the number of models that might be describable diverges, leading to problems with the definition of the description length. Of course the parameter space can be cut off by hand, but unless the choice of cut-off is well founded, it can lead to artifacts in the comparison of different model families <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5,</ref><ref type="bibr" target="#b5">6]</ref>. Unfortunately in many practical problems the parameter space is noncompact and V diverges. For example, in astrophysics, the detection of exoplanets depends on a model of the light coming from the occluded star. This model will contain a non-compact direction representing the orbital period of the planet -see, e.g., <ref type="bibr" target="#b6">[7]</ref>. For examples from psychophysics see, e.g., <ref type="bibr" target="#b3">[4]</ref>.</p><p>In this note we argue that merely specifying the experimental set-up -before the measurement of any actual data -influences the prior distribution on the parameter space. This occurs because, given the finite number of measurements in any experiment, many of the probability distributions indexed by a parametric manifold will be statistically indistinguishable. In cases where the parameter space is noncompact, the uniform prior conditioned on the experimental setup can thus become well-defined. In the geometric language of <ref type="bibr" target="#b0">[1]</ref>, the volume that measures the number of probability distributions in the parametric family that are statistically distinguishable given a finite number of measurements can be finite even if the parameter space is non-compact. In effect, specifying the experimental set-up can render the parameter space compact.</p><p>Our results illustrate how the choice of experimental set-up influences the measure on the parameter space of a model, thereby affecting which model is regarded as most 'correct'. In section 2 we briefly review the computation of posterior probabilities, and consider the effect of conditioning on the experimental set-up on the parameter space measure. In section 3 we apply these considerations to a physical problem: the analysis of light-curves of stars with orbiting planets. In this example we see that the volume of the parameter space is rendered effectively finite after the experimental set-up is specified.</p><p>2 The effect of experimental design on the parameter space measure</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Review</head><p>Suppose one is interested in some physical phenomenon, and has made N relevant measurements: Y = {y 1 , . . . , y N }. Further suppose that there are two different parametric models, A and B, that aim to describe the phenomenon in question. The basic question to be answered is which of the two models is the better one, considering the experimental data Y . The probability-theoretic answer to this question is to compute the posterior probabilities P (A|Y ) and P (B|Y ), which we can write using the Bayes Rule as</p><formula xml:id="formula_2">P (A|Y ) = P (A) P (Y ) ω(Θ)P (Y |Θ),<label>(2)</label></formula><p>where Θ = (θ 1 , . . . , θ d ) ∈ R d is the vector of variables parametrising A, and ω(Θ) is the volume form associated to the measure on the parameter space, which we will define shortly. A corresponding expression can also be written for P (B|Y ). Since we wish to compare P (A|Y ) and P (B|Y ), we can ignore the common factor P (Y ), and we will assume P (A) = P (B) and drop this factor as well. Thus the only remaining ingredient to be defined is the volume form ω(Θ); we simply quote the result from <ref type="bibr" target="#b0">[1]</ref>: the volume form that gives equal weight to all statistically distinguishable distributions in the parametric family is</p><formula xml:id="formula_3">ω(Θ) = det J ij (Θ) d d Θ det J ij (Θ) d d Θ,<label>(3)</label></formula><p>where J ij (Θ) is the Fisher information matrix, defined as the second derivative of the Kullback-Leibler distance D(Θ p ||Θ q ):</p><formula xml:id="formula_4">J ij (Θ p ) = ∂ θ i ∂ θ j D(Θ p ||Θ p + Φ)| Φ=0 ,<label>(4)</label></formula><formula xml:id="formula_5">D(Θ p ||Θ q ) = dd x Θ p ( x) ln Θ p ( x) Θ q ( x) .<label>(5)</label></formula><p>where dd x is the integration measure over the sample space { x}, and Θ p ( x) is the distribution function associated to the values of the parameters (θ p 1 , . . . , θ p d ). Now we have defined everything needed to compute the posterior probabilities, and we illustrate the formalism by applying it to the analysis of light-curves.</p><p>Using this, we can compute the Fisher information matrix by computing the KullbackLeibler distance between two nearby points and Taylor expanding:</p><formula xml:id="formula_6">D(Θ 0 ||Θ q ) = d N y Θ 0 ( y) ln Θ 0 ( y) Θ q ( y) ≈ − d N y Θ 0 ( y) ln Θ 0 ( y) + ∂ θ i Θ 0 ( y)∆θ i + ∂ θ i ∂ θ j Θ 0 ( y)∆θ i ∆θ j Θ 0 ( y) ≈ − d N y ∂ θ i Θ 0 ( y)∆θ i + ∂ θ i ∂ θ j Θ 0 ( y)∆θ i ∆θ j − 1 2 (∂ θ i Θ 0 ( y))(∂ θ j Θ 0 ( y)) Θ 0 ( y) ∆θ i ∆θ j = 1 2 d N y (∂ θ i Θ 0 ( y))(∂ θ j Θ 0 ( y)) Θ 0 ( y) ≡J ij (Θ 0 ) ∆θ i ∆θ j .<label>(6)</label></formula><p>On the third line, the terms linear in Θ 0 vanish, as exchanging the order of integration and derivation, the integral of Θ 0 will yield a constant 1, which then differentiates to zero.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Effect of the experimental set-up</head><p>The measure <ref type="formula" target="#formula_3">(3)</ref> is independent of the experimental data Y and is constructed under the assumption that the entire sample space can be measured by the observer. However, in real experiments, instrumental and design limitations only allow observation of some subset M of the sample space. Thus an observation either results in no detected outcome, or in a measurement y i ∈ M. Thus the effective predicted distribution of measured outcomes is not the Θ( y), but rather</p><formula xml:id="formula_7">Θ( y) = Θ( y), for y ∈ M, Θ Out , no measured outcome,<label>(7)</label></formula><p>where Θ Out ≡ y / ∈M dd y Θ( y). We will argue that if the models in the asymptotic regions of a noncompact parameter space differ in their predictions mostly outside the observable region M, the Fisher information for the effective distributions (7) can decay sufficiently quickly to render the volume</p><formula xml:id="formula_8">V = d d Θ det J ij (Θ)</formula><p>finite. In this section we will give one set of sufficient conditions for this to happen and in Sec. 3 we will give a detailed example.</p><p>Consider a model, specified by parameters θ = (θ 1 , . . . , θ d ) ∈ R d , and a distribution Θ θ ( x), with y ∈ R n . We will slightly simplify notation simply referring to the distribution as Θ( y) and understanding the implicit parameter dependence. Let us use spherical coordinates in the parameter space R d with ρ being the radial coordinate, i.e. (θ 1 , . . . , θ d ) → (ρ, ϕ 1 , . . . , ϕ d−1 ). Also consider an experimental set-up that can only make measurements inside some compact region M ⊂ R n . Thus,the probability of no measurement being registered by this experiment is Θ Out ≡ y / ∈M dd y Θ( y). Our first assumption is a smoothness condition, so that inside the region M the distribution does not fluctuate too much as one approaches the asymptotics of parameter space:</p><formula xml:id="formula_9">∂ i Θ( y)| y∈M ≤ δ(ρ), for large ρ, i = 1, . . . , d,<label>(8)</label></formula><p>where δ(ρ) goes to zero as ρ goes to infinity; we will later specify the exact scaling needed. Intuitively, this condition says that as the parameter ρ → ∞, the models do not differ too much inside the observable part of the sample space M. This allows us to estimate</p><formula xml:id="formula_10">∂ i Θ Out = ∂ i (1 − y∈M dd y Θ( y)) ≤ Vol(M)δ,<label>(9)</label></formula><p>where Vol(M) denotes the volume of the compact region M.</p><p>Secondly we assume that inside M, the distributions Θ( y) do not decay too quickly as ρ → ∞. Intuitively, since any experiment will only measure a finite amount of data (say N points), if the probability of a single measurement lying inside M is significantly less than 1/N, then the experimental set-up will not detect anything. Thus we will require</p><formula xml:id="formula_11">Θ( y) | y∈M &gt; ǫ(ρ), for large ρ,<label>(10)</label></formula><p>where again we will later specify the scaling of ǫ(ρ) with ρ. 1 Using these assumptions, we can establish an upper bound for the Fisher information (6):</p><formula xml:id="formula_12">|J ij | ≤ y∈M ∂ i Θ( y)∂ j Θ( y) Θ( y) + ∂ i Θ Out ∂ j Θ Out Θ Out &lt; δ 2 y∈M 1 Θ( y) + Vol(M) 2 δ 2 ≤ Vol(M) δ 2 ǫ + Vol(M) 2 δ 2 ∼ Vol(M) δ 2 ǫ .<label>(11)</label></formula><p>Thus the determinant of the Fisher information scales as Det</p><formula xml:id="formula_13">J ij ∼ δ 2 ǫ d 2 ,<label>(12)</label></formula><p>and for the integral V to be finite one must have suppression stronger than Det J ij ∼ ρ −d . Thus the integral converges if δ is suppressed more strongly than</p><formula xml:id="formula_14">δ(ρ) &lt; ǫ(ρ) ρ .<label>(13)</label></formula><p>From the experimental set-up one can estimate how ǫ(ρ) scales with ρ, which then determines how δ(ρ) needs to scale for the integral to converge. This is thus a sufficient condition for rendering the parameter space effectively finite. It is worth stressing that, following the above analysis, any method of deciding the validity of a model is impacted by the choice of the experiment in a completely computable way, and this should be taken into account when designing experiments. 3 The probability of exo-planet detection</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Model for exo-planets</head><p>Consider a star orbited by a planet so that the planet periodically passes between the star and Earth. The light output (light-curve) of such a star is a constant line, with a small periodic dip when the planet is eclipsing part of the star. One model for such a light-curve was proposed in <ref type="bibr" target="#b6">[7]</ref> as</p><formula xml:id="formula_15">y(T, D, η, τ, b; t) = b − D 2 tanh c( ˜ t + 1 2 ) − tanh c( ˜ t − 1 2 ) ,<label>(14)</label></formula><p>where</p><formula xml:id="formula_16">˜ t = T sin π(t−τ ) T πη .<label>(15)</label></formula><p>An example light-curve is shown in <ref type="figure" target="#fig_0">figure 1</ref>; T is the period of the planet; η is the duration of the transit, i.e. how long the planet eclipses the star; D is the depth of the dip in the curve; b is the total observed brightness of the star; and τ is a phase parameter specifying when the planets transit occurs. Finally, c is a constant parameter specifying the sharpness of the edges of the light-curve, expected to be fairly large as the transition between transit/notransit is relatively quick. The assumption c ≫ 1 greatly simplifies our analysis, and is not physically very restrictive. The parameter space for this model is clearly non-compact as T can range to infinity. However, we will argue that the space is effectively rendered compact after the experimental set-up is specified. To be precise, the parameter space is 2 :</p><formula xml:id="formula_17">T ∈ [0, ∞), D ∈ [0, b], τ ∈ [0, T ], η ∈ [0, δT ], b ∈ [0, b max ],<label>(16)</label></formula><p>where δ is a small number that we will estimate, and the maximal brightness b max is naturally given by the brightness of Sirius, the brightest star visible from Earth. Assuming a circular orbit as in <ref type="figure" target="#fig_1">Figure 2</ref>, the ratio of the transit time to the period of the planet is given by</p><formula xml:id="formula_18">η T ≈ 2r/v planet 2πR/v planet = 1 π r R .</formula><p>2 Note that we consider c to be a constant, not a parameter. For the currently known transiting exo-planets this ratio is around ∼ 0.1 <ref type="bibr">[8]</ref>, although for a typical system one expects it to be smaller as large planets orbiting close to the star are easier to observe, which favors largest values of the ratio. For an elliptical orbit, the answer will differ by an O(1) factor, but will have the same dependence on r/R. Thus, η will always be a small fraction of T . Now we can write down the probability density for measuring values y = (y 1 , . . . , y N ) for the light-curve at times (t 1 , . . . , t N ) with the light-curve specified by parameters</p><formula xml:id="formula_19">(θ 0 1 , θ 0 2 , θ 0 3 , θ 0 4 , θ 0 5 ) = (T, D, η, τ, b) as Θ 0 ( y) = N k=1 1 √ 2πσ k e − (y k −y 0 (θ 0 i ;t k )) 2 2σ 2 k = (2πσ) − N 2 e − 1 2σ 2 P N k=1 (y k −y 0 (θ 0 i ;t k )) 2 ,<label>(17)</label></formula><p>where we have assumed that the uncertainty in each measurement is Gaussian, and further we have chosen the standard deviation to be equal for all measurements for simplicity. Using (17) in the formula (6), we see that the the integrals in the Fisher information are Gaussian in y k ; thus we can compute them analytically to get</p><formula xml:id="formula_20">J ij = 1 σ 2 N k=1 ∂ θ i y(θ; t k )∂ θ j y(θ; t k ).<label>(18)</label></formula><p>This is our key formula, and we shall spend the next subsection analysing its properties.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Finiteness of light-curve parameter space</head><p>We now wish to apply the general arguments of section 2 to the exo-planet system. Consider an experimental set-up that can barely measure two periods, and then consider shortening the experiment slightly so that only one dip is detected; this is depicted in <ref type="figure" target="#fig_0">figure 1</ref>. To be precise, the shorter set-up measures the beginning and end of a transit at t 1 and t 2 , n points in between, and m points after the transit. The longer set-up makes measurements at the same times, and additionally at times t 3 and t 4 , detecting the second transit. In the next subsections we will show that J short ≪ J long , indicating that detecting the second dip is of fundamental importance to experimental design; without the second dip the experimental set-up can't differentiate models with large enough T . This renders the parameter space effectively finite, as an experiment can not differentiate between models that have period T larger than the duration of the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1">Effect of measuring a second transit on det(J)</head><p>In this subsection we will give an estimate for the magnitude of the determinant of the Fisher information, and show how it is affected by the inclusion of the second transit in the data. In subsequent subsections we will exactly compute the determinant for a few specific experimental set-ups. <ref type="bibr">From (18)</ref> and the definition of a determinant, we see that in each term of the determinant each parameter θ i appears exactly twice in the derivatives, i.e. each term is of the form</p><formula xml:id="formula_21">J i 1 j 1 J i 2 j 2 J i 3 j 3 J i 4 j 4 J i 5 j 5 ∼ 1 σ 10 ∂ T y ∂ T y ∂ D y ∂ D y ∂ η y ∂ η y ∂ τ y ∂ τ y ∂ b y ∂ b y.<label>(19)</label></formula><p>As a rough estimate of the size the determinant, we investigate how large terms of this type can be. The derivatives are</p><formula xml:id="formula_22">∂ T y(θ, t) = cD 2 f ( ˜ t) πη sin π(t − τ ) T − π(t − τ ) T cos π(t − τ ) T ,<label>(20)</label></formula><formula xml:id="formula_23">∂ D y(θ, t) = 1 2 tanh c( ˜ t − 1 2 ) − tanh c( ˜ t + 1 2 ) ,<label>(21)</label></formula><formula xml:id="formula_24">∂ τ y(θ, t) = − cD 2 f ( ˜ t) η cos π(t − τ ) T ,<label>(22)</label></formula><formula xml:id="formula_25">∂ η y(θ, t) = − cD 2 ˜ tf ( ˜ t) η , ∂ b y(θ, t) = 1,<label>(23)</label></formula><p>with</p><formula xml:id="formula_26">f ( ˜ t) ≡ tanh 2 c( ˜ t + 1 2 ) − tanh 2 c( ˜ t − 1 2 ).<label>(24)</label></formula><p>From <ref type="formula" target="#formula_2">(24)</ref> we see that f ( ˜ t) = 0 only wheñ t ≈ ± 1 2 , again assuming large c. This tells us that the measurements that contribute most to the Fisher information are the ones on the edges of the dips 3 , i.e. at times t 1 , t 2 , t 3 and t 4 in <ref type="figure" target="#fig_0">figure 1</ref>. We write the condition</p><formula xml:id="formula_27">| ˜ t| ≈ 1 2 as sin π(t − τ ) T = π 2 η T ,<label>(25)</label></formula><p>and note that the ratio of transit time to period is very small, η T ≪ 1. This gives us the solutions</p><formula xml:id="formula_28">t − τ T ≈ n ± η 2T ,<label>(26)</label></formula><p>where n is an integer indexing the number of the dip, with n = 0 denoting the solitary dip if only one is present in the data.</p><formula xml:id="formula_29">| max ,<label>(27)</label></formula><p>where both the numerator and the denominator are of the form <ref type="bibr">(19)</ref>, and according to the argument above the maximal contributions come from the edge measurements. From (21-23) we see that the derivatives with respect to D, η, τ and b are all periodic at the edges: |∂ θ i y(θ, t 1 )| = . . . = |∂ θ i y(θ, t 4 )| for θ i = T , and thus will cancel in the ratio <ref type="bibr">(27)</ref>. It is crucial that ∂ T y, however, is not periodic due to the second term in <ref type="bibr">(20)</ref>. At the first dip, t 1 , t 2 = ± η</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2T</head><p>, we expand <ref type="formula" target="#formula_2">(20)</ref> to find</p><formula xml:id="formula_30">∂ T y(t 1 ) ≈ ∂ T y(t 2 ) ≈ π 2 cD 48 η 2 T 3 ,<label>(28)</label></formula><p>while at the second dip, t 3 , t 4 = 1 ± η</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>2T</head><p>, the contribution is</p><formula xml:id="formula_31">|∂ T y(t 3 )| ≈ |∂ T y(t 4 )| ≈ cD 2η ,<label>(29)</label></formula><p>ignoring signs that are irrelevant for this estimate. Thus we see that the Fisher information increases strongly as the second dip is included:</p><formula xml:id="formula_32">J short J long ∼ (∂ T y(t 1,2 )) 2 (∂ T y(t 1,2 )) 2 + (∂ T y(t 1,2 )∂ T y(t 3,4 )) + (∂ T y(t 3,4 )) 2 ∼ η T 6 ≪ 1, (30)</formula><p>where we ignored order one coefficients. This is an explicit example of how our arguments from section 2 work for a realistic model: when an experimental set-up does not have the capability to detect two dips, it becomes impossible to determine the period, and consequently the Fisher information is very small (or vanishing) compared to an experiment that is able to detect two dips and determine the period more accurately. For any given experiment of finite duration ∆t, the Fisher Information will decline with T when T ≫ ∆t effectively rendering the parameter space compact.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2">The tail T → ∞</head><p>To verify our claim that the parameter space is really rendered compact we need to show that det J → 0 strongly enough as T is taken to infinity. It is easy enough to find the T -scaling of the derivatives (20-23); ∂ T y scales as T −3 , while the others stay finite in the large T limit. Thus, as seen from <ref type="formula" target="#formula_0">(19)</ref>, the determinant will scale as</p><formula xml:id="formula_33">√ det J ∼ ∂ T y ∼ 1 T 3 ,<label>(31)</label></formula><p>which shows that that the parameter space measure vanishes fast enough for large T to render the parameter space volume finite.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3">Explicit computation of Det(J ij ) for specific experimental set-ups</head><p>While the order of magnitude estimate of the previous subsection offers an intuitive reason as to why the Fisher information decreases sharply when the number of peaks detected falls below two, it is still instructive to explicitly compute the determinant in a few experimental set-ups.</p><p>Detecting two dips: Let us first consider the case J long from section 3.2, i.e. measurements at times indicated in <ref type="figure" target="#fig_0">figure 1</ref>. Using the derivatives (20-23) one can write down the Fisher information matrix <ref type="formula" target="#formula_0">(18)</ref> as</p><formula xml:id="formula_34">J long ij =       2(T 2 1 + T 2 3 ) −T 1 2T 1 X −4T 3 X 2T 1 −T 1 1 + n −2X 0 −(2 + n) 2T 1 X −2X 4X 2 0 4X −4T 3 X 0 0 16X 2 0 2T 1 −(2 + n) 4X 0 4 + n + m       ,<label>(32)</label></formula><p>where for brevity we defined</p><formula xml:id="formula_35">T 1 ≡ ∂ T y(t 1 ) = ∂ T y(t 2 ) = cDπ 2 48 η 2 T 3 , T 3 ≡ ∂ T y(t 3 ) = −∂ T y(t 4 ) = cD 2η ,<label>(33)</label></formula><formula xml:id="formula_36">X ≡ − cD 4η = ∂ η y(t 1,2,3,4 ) = − ∂ τ y(t 1,3 ) 2 = ∂ τ y(t 2,4 ) 2 .<label>(34)</label></formula><p>In computing this matrix we used that f ( ˜ t) = 0 for˜tfor˜ for˜t = ± 1 2 , which is true up to corrections of order e −c , as seen from <ref type="formula" target="#formula_2">(24)</ref>; for this reason one does not need to specify the exact times of the n measurements during the dip, or the m measurements outside the dip, as up to e −c corrections they all contribute equally. The determinant of the Fisher information is simple,</p><formula xml:id="formula_37">Det(J long ij ) = 64nmX 4 (T 2 1 + T 2 3 ) ≈ 64nmX 4 T 2 3 .<label>(35)</label></formula><p>This result explains the subtlety referred to earlier: although measurements at the edges contribute the most to the Fisher information, if one only has measurements at the edges (n = m = 0) the Fisher information actually vanishes. Physically this is easy to interpret, as only measuring the edges t 1 , . . . , t 4 will yield four points lying on a line, and thus they cannot be used to determine any information about the curve; other data points are needed to 'anchor' the data.</p><p>Detecting only one dip: Similarly one can compute the Fisher information in the 'short' experimental set-up, where measurements are made at the same times as before, except not at t 3 and t 4 . This yields</p><formula xml:id="formula_38">J short ij =       2T 2 1 −T 1 2T 1 X 0 2T 1 −T 1 1 2 + n −X 0 −(1 + n) 2T 1 X −X 2X 2 0 2X 0 0 0 8X 2 0 2T 1 −(1 + n) 2X 0 2 + n + m       ,<label>(36)</label></formula><p>and perhaps surprisingly the determinant vanishes: Det(J short ij ) = 0, up to tiny e −c corrections. This indicates that the estimate in section 3.2.1 was an overestimate 4 : terms in the determinant of J short are of the magnitude estimated, but the determinant is arranged in such a way that the terms cancel to a high accuracy, and the compactness of the parameter space is strengthened.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Discussion</head><p>Our analysis has shown how the specification of an experimental design affects the measure on model parameter spaces in MDL model selection (or equivalently the prior probability distribution on parameters in the Bayesian approach). Interestingly, the finite number of measurements within a bounded sample space in any practical experiment can effectively render a non-compact parameter space compact thereby leading to a well-defined prior distribution (3). Our analysis could be turned around to design experiments to discriminate well between models in some chosen region of the parameter space by ensuring that the Fisher information <ref type="formula" target="#formula_0">(18)</ref> is large in the desired region. It would also be useful to determine general conditions under which experimental design effectively makes model parameter spaces compact, perhaps following the arguments of Sec. 2.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Figure 1: An example of a light-curve.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Figure 2: The basic set-up: an extra-solar planet orbiting a star of radius r with an average distance R.</figDesc></figure>

			<note place="foot" n="1"> This condition can be relaxed by recognizing that if Θ( y)| y∈M decays too quickly as ρ → ∞, then the models in the asymptotic region of the parameter space make no measurable predictions for experiments designed with a finite number of measurements. The example in the Sec. 3 will illustrate such a scenario.</note>

			<note place="foot" n="3"> This statement is somewhat subtle, and we will discuss this matter in more detail in section 3.2.3; for our current purposes it is sufficiently accurate.</note>

			<note place="foot" n="4"> As the estimate illustrates an intuitive reason why the appearance of the second peak is so important, we decided to include it.</note>
		</body>
		<back>

			<div type="acknowledgement">
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A Geometric Formulation of Occam&apos;s Razor for Inference of Parametric Distributions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">; V</forename><surname>Balasubramanian</surname></persName>
		</author>
		<idno type="arXiv">arXiv:cond-mat/9601030</idno>
		<idno>arXiv:adap-org/9601001</idno>
	</analytic>
	<monogr>
		<title level="m">Statistical Inference, Occam&apos;s Razor and Statistical Mechanics on The Space of Probability Distributions</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Modeling by shortest data description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rissanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Automatica</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1080" to="1100" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Fisher information and stochastic complexity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rissanen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform.Theory</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="page" from="40" to="47" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Counting Probability Distributions: Differential Geometry and Model Selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">J</forename><surname>Myung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Balasubramanian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Pitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Science</title>
		<meeting>the National Academy of Science</meeting>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="11170" to="11175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Exact minimax strategies for predic-tive density estimation, data compression, and model selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Barron</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Transactions on Information Theory</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="page" from="2708" to="2726" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">The Minimum Description Length Principle</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">D</forename><surname>Grünwald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007-06" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
	<note>Chapter</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Fast identification of transits from lightcurves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Protopapas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jimenez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Alcock</surname></persName>
		</author>
		<idno type="arXiv">arXiv:astro-ph/0502301</idno>
	</analytic>
	<monogr>
		<title level="j">Mon. Not. Roy. Astron. Soc</title>
		<imprint>
			<biblScope unit="volume">362</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
