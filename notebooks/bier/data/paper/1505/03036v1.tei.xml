<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/ResearchCloud/Projects/ExoPlanets/notebooks/grobid/grobid-0.5.2/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.2" ident="GROBID" when="2018-12-11T12:26+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Removing systematic errors for exoplanet search via latent causes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bernhard</forename><surname>Schölkopf</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="department" key="dep2">FOREMAN.MACKEY@GMAIL.COM Center for Cosmology and Particle Physics</orgName>
								<orgName type="department" key="dep3">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>72076, 10003, 72076</postCode>
									<settlement>Tübingen, New York, Tübingen</settlement>
									<region>NY</region>
									<country>GERMANY, USA, GERMANY</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bs@tuebingen</forename><forename type="middle">Mpg</forename><surname>De</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="department" key="dep2">FOREMAN.MACKEY@GMAIL.COM Center for Cosmology and Particle Physics</orgName>
								<orgName type="department" key="dep3">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>72076, 10003, 72076</postCode>
									<settlement>Tübingen, New York, Tübingen</settlement>
									<region>NY</region>
									<country>GERMANY, USA, GERMANY</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><forename type="middle">W</forename><surname>Hogg</surname></persName>
							<email>david.hogg@nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="department" key="dep2">FOREMAN.MACKEY@GMAIL.COM Center for Cosmology and Particle Physics</orgName>
								<orgName type="department" key="dep3">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>72076, 10003, 72076</postCode>
									<settlement>Tübingen, New York, Tübingen</settlement>
									<region>NY</region>
									<country>GERMANY, USA, GERMANY</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dun</forename><surname>Wang</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="department" key="dep2">FOREMAN.MACKEY@GMAIL.COM Center for Cosmology and Particle Physics</orgName>
								<orgName type="department" key="dep3">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>72076, 10003, 72076</postCode>
									<settlement>Tübingen, New York, Tübingen</settlement>
									<region>NY</region>
									<country>GERMANY, USA, GERMANY</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Daniel</forename><surname>Foreman-Mackey</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="department" key="dep2">FOREMAN.MACKEY@GMAIL.COM Center for Cosmology and Particle Physics</orgName>
								<orgName type="department" key="dep3">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>72076, 10003, 72076</postCode>
									<settlement>Tübingen, New York, Tübingen</settlement>
									<region>NY</region>
									<country>GERMANY, USA, GERMANY</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dominik</forename><surname>Janzing</surname></persName>
							<email>dominik.janzing@tuebingen.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="department" key="dep2">FOREMAN.MACKEY@GMAIL.COM Center for Cosmology and Particle Physics</orgName>
								<orgName type="department" key="dep3">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>72076, 10003, 72076</postCode>
									<settlement>Tübingen, New York, Tübingen</settlement>
									<region>NY</region>
									<country>GERMANY, USA, GERMANY</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carl-Johann</forename><surname>Simon-Gabriel</surname></persName>
							<email>carl-johann.simon-gabriel@tuebingen.mpg.de</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="department" key="dep2">FOREMAN.MACKEY@GMAIL.COM Center for Cosmology and Particle Physics</orgName>
								<orgName type="department" key="dep3">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>72076, 10003, 72076</postCode>
									<settlement>Tübingen, New York, Tübingen</settlement>
									<region>NY</region>
									<country>GERMANY, USA, GERMANY</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><surname>Peters</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="department" key="dep2">FOREMAN.MACKEY@GMAIL.COM Center for Cosmology and Particle Physics</orgName>
								<orgName type="department" key="dep3">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>72076, 10003, 72076</postCode>
									<settlement>Tübingen, New York, Tübingen</settlement>
									<region>NY</region>
									<country>GERMANY, USA, GERMANY</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jonas</forename><forename type="middle">Mpg</forename><surname>Peters@tuebingen</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="department" key="dep2">FOREMAN.MACKEY@GMAIL.COM Center for Cosmology and Particle Physics</orgName>
								<orgName type="department" key="dep3">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>72076, 10003, 72076</postCode>
									<settlement>Tübingen, New York, Tübingen</settlement>
									<region>NY</region>
									<country>GERMANY, USA, GERMANY</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>De</surname></persName>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="department" key="dep2">FOREMAN.MACKEY@GMAIL.COM Center for Cosmology and Particle Physics</orgName>
								<orgName type="department" key="dep3">Max Planck Institute for Intelligent Systems</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>72076, 10003, 72076</postCode>
									<settlement>Tübingen, New York, Tübingen</settlement>
									<region>NY</region>
									<country>GERMANY, USA, GERMANY</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Removing systematic errors for exoplanet search via latent causes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<abstract>
				<p>We describe a method for removing the effect of confounders in order to reconstruct a latent quantity of interest. The method, referred to as half-sibling regression, is inspired by recent work in causal inference using additive noise models. We provide a theoretical justification and illustrate the potential of the method in a challenging astronomy application.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The present paper proposes and analyzes a method for removing the effect of confounding noise. The analysis is based on a hypothetical underlying causal structure. The method does not infer causal structures; rather, it is influenced by a recent thrust to try to understand how causal structures facilitate machine learning tasks ( <ref type="bibr" target="#b12">Schölkopf et al., 2012</ref>).</p><p>Causal graphical models as pioneered by <ref type="bibr" target="#b9">Pearl (2000)</ref>; <ref type="bibr" target="#b14">Spirtes et al. (1993)</ref> are joint probability distributions over a set of variables X 1 , . . . , X n , along with directed graphs (usually, acyclicity is assumed) with vertices X i , and arrows indicating direct causal influences. By the causal Markov assumption, each vertex X i is independent of its non-descendants, given its parents.</p><p>There is an alternative view of causal models, which does not start from a joint distribution. Instead, it assumes a set of jointly independent noise variables, one for each vertex, and a "structural equation" for each variable that describes how the latter is computed by evaluating a deterministic function of its noise variable and its parents. This view, referred to as a functional causal model (or nonlinear structural equation model), leads to the same class of joint distributions over all variables <ref type="bibr" target="#b9">(Pearl, 2000;</ref><ref type="bibr" target="#b10">Peters et al., 2014</ref>), and we may thus choose either representation.</p><p>The functional point of view is useful in that it often makes it easier to come up with assumptions on the causal mechanisms that are at work, i.e., on the functions associated with the variables. For instance, it was recently shown <ref type="bibr" target="#b4">(Hoyer et al., 2009</ref>) that assuming nonlinear functions with additive noise renders the two-variable case identifiable -i.e., a case where conditional independence tests do not provide any information, and it was thus previously believed that it is impossible to infer the structure of the graph based on observational data.</p><p>In this work we start from the functional point of view and assume the underlying causal graph shown in <ref type="figure">Fig. 1</ref>. Here, N, Q, X, Y are jointly random variables (RVs) (i.e., RVs defined on the same underlying probability space), taking values denoted by n, q, x, y. We do not require the ranges of the random variables to be R, in particular, they may be vectorial. All equalities regarding random variables should be interpreted to hold with probability one. We further (implicitly) assume the existence of conditional expectations.</p><p>Note that while the causal motivation was helpful for our work, one can also view <ref type="figure">Fig. 1</ref> as a DAG (directed acyclic graph) without causal interpretation, i.e., as a directed a graphical model. We need Q and X (and in some cases Removing systematic errors for exoplanet search via latent causes unobserved observed Y X N Q <ref type="figure">Figure 1</ref>. We are interested in reconstructing the quantity Q based on the observables X and Y affected by noise N , using the knowledge that (N, X) ⊥ ⊥ Q. Note that the involved quantities need not be scalars, which makes the model more general than it seems at first glance. For instance, we can think of N as a multidimensional vector, some components of which affect only X, some only Y , and some both X and Y . also N ) to be independent, which follows from the given structure no matter whether one views this as a causal graph or as a graphical model.</p><p>In the next section, we present the method. Section 3 describes the application and provides experimental results, and Section 4 summarizes our conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Half-Sibling Regression</head><p>Suppose we are interested in the quantity Q, but unfortunately we cannot observe it directly. Instead, we observe Y , which we think of as a degraded version of Q that is affected by noise N . Clearly, without knowledge of N , there is no way to recover Q. However, we assume that N also affects another observable quantity (or a collection of quantities) X. By the graph structure, conditional on Y , the variables Q and X are dependent (in the generic case), thus X contains information about Q. This situation is quite common if X and Y are measurements performed with the same apparatus, introducing the noise N . In the physical sciences, this is often referred to as systematics, to convey the intuition that these errors are not simply due to random fluctuations, but caused by systematic influences of the measuring device. In our application below, both types of errors occur, but we will not try to tease them apart. Our method addresses errors that affect both X and Y , for instance by acting on N , no matter whether we call them random or systematic.</p><p>How can we use this information in practice? Unfortunately, without further restrictions, this problem is still too hard. Suppose that N randomly switches between {1, . . . , v}, where v ∈ N ( <ref type="bibr" target="#b12">Schölkopf et al., 2012</ref>). Define the structural equation f Y for the variable Y as follows: y = f Y (n, q) := f n (q), where f 1 , . . . , f v are v distinct functions that compute Y from Q -in other words, we randomly switch between v different mechanisms. Clearly, no matter how many pairs (x, y) we observe, we can choose a sufficiently large v along with functions f 1 , . . . , f v such that there is no way of gleaning any reliable information on Q from the f i (Q) -e.g., there may be more f i than there were data points. Things could get even worse: for instance, N could be real valued, and switch between an uncountable number of functions. To prevent this kind of behavior, we need to simplify the way in which Y is allowed to depend on N .</p><p>Before we do so, we need to point out a fundamental limitation. The above example shows that it can be arbitrarily hard to get information about Q from finite data. However, even from infinite data, only partial information is available and certain "gauge" degrees of freedom remain. 1 In particular, given a reconstructed Q, we can always construct another one by applying an invertible transformation to it, and incorporating its inverse into the function computing Y from Q and N . This includes the possibility of adding an offset, which we will see below.</p><p>We next propose an assumption which allows for a practical method to solve the problem of reconstructing Q up to the above gauge freedom. The method is surprisingly simple, and while we have not seen it in the same form elsewhere, we do not want to claim originality for it. Related tricks are occasionally applied in practice, often employing factor analysis to account for confounding effects <ref type="bibr" target="#b11">(Price et al., 2006;</ref><ref type="bibr" target="#b17">Yu et al., 2006;</ref><ref type="bibr" target="#b6">Johnson &amp; Li, 2007;</ref><ref type="bibr" target="#b7">Kang et al., 2008;</ref><ref type="bibr" target="#b15">Stegle et al., 2008;</ref><ref type="bibr" target="#b2">Gagnon-Bartsch &amp; Speed, 2011</ref>). We will also present a theoretical analysis that provides insight into why and when these methods work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Complete Information</head><p>Inspired by recent work in causal inference, we use nonlinear additive noise models <ref type="bibr" target="#b4">(Hoyer et al., 2009</ref>). Specifically, we assume that there exists a function f such that</p><formula xml:id="formula_0">Y = Q + f (N ).<label>(1)</label></formula><p>Note that we could equally well assume the more general form Y = g(Q) + f (N ), and the following analysis would look the same. However, in view of the above remark about the gauge freedom, this is not necessary since Q can at most be identified up to a (nonlinear) reparametrization anyway. Note, moreover, that while for <ref type="bibr" target="#b4">Hoyer et al. (2009)</ref>, the input of f is observed and we want to decide if it is a cause of Y , in the present setting the input of f is unobserved ( <ref type="bibr" target="#b5">Janzing et al., 2009)</ref>, and the goal is to recover Q, which for <ref type="bibr" target="#b4">Hoyer et al. (2009)</ref> played the role of the noise.</p><p>The intuition behind our approach is as follows. Since X ⊥ ⊥ Q, X cannot predict Q, and thus neither Q's influence on Y . It may contain information, however, about the influence of N on Y , since X is also influenced by N . Now suppose we try to predict Y from X. As argued above, whatever comes from Q cannot be predicted, hence only the component coming from N will be picked up. Trying to predict Y from X is thus a vehicle to selectively capture N 's influence on Y , with the goal of subsequently removing it, to obtain an estimate of Q referred to asˆQasˆ asˆQ:</p><formula xml:id="formula_1">Definition 1 ˆ Q := Y − E[Y |X]<label>(2)</label></formula><p>For an additive model (1), our intuition can be formalized: in this case, we can predict the additive component in Y coming from N -which is exactly what we want to remove to cancel the confounding effect of N and thus reconstruct Q (up to an offset):</p><p>Proposition 1 Suppose N, X are jointly random variables, and f is a measurable function. If there exists a function ψ such that</p><formula xml:id="formula_2">f (N ) = ψ(X),<label>(3)</label></formula><p>i.e., f (N ) can in principle be predicted from X perfectly, then we have</p><formula xml:id="formula_3">f (N ) = E[f (N )|X].<label>(4)</label></formula><p>If, moreover, the additive model assumption (1) holds, with Q, Y RVs on the same underlying probability space, and</p><formula xml:id="formula_4">Q ⊥ ⊥ X, thenˆQ thenˆ thenˆQ = Q − E[Q].<label>(5)</label></formula><p>In our main application below, N will be systematic errors from an astronomical spacecraft and telescope, Y will be a star under analysis, and X will be a large set of other stars. In this case, the assumption that f (N ) = ψ(X) has a concrete interpretation: it means that the device can be self-calibrated based on measured science data only <ref type="bibr">(Pad- manabhan et al., 2008</ref>).</p><p>Proof. Due to (3), we have</p><formula xml:id="formula_5">E[f (N )|X] = E[ψ(X)|X] = ψ(X) = f (N ). (6)</formula><p>To show the second statement, consider the conditional expectation</p><formula xml:id="formula_6">E[Y |X] = E[Q + f (N )|X]<label>(7)</label></formula><p>Using Q ⊥ ⊥ X and (4), we get</p><formula xml:id="formula_7">E[Y |X] = E[Q] + f (N ) = E[Q] + Y − Q.<label>(8)</label></formula><p>Recalling Definition 1 completes the proof.</p><p>Proposition 1 provides us with a principled recommendation how to remove the effect of the noise and reconstruct the unobserved Q up to its mean E[Q]: we need to subtract the conditional expectation (i.e., the regression)</p><formula xml:id="formula_8">E[Y |X] from the observed Y (Definition 1). The regres- sion E[Y |X]</formula><p>can be estimated from observations (x i , y i ) using (linear or nonlinear) off-the-shelf methods. We refer to this procedure as half-sibling regression to reflect the fact that we are trying to explain aspects of the child Y by regression on its half-sibling(s) X in order to reconstruct properties of its unobserved parent Q.</p><formula xml:id="formula_9">Note that m(x) := E[f (N )|X = x] is a function of x, and E[f (N )|X]</formula><p>is the random variable m(X). Correspondingly, <ref type="formula" target="#formula_3">(4)</ref> is an equality of RVs. By assumption, all RVs live on the same underlying probability space. If we perform the associated random experiment, we obtain values for X and N , and (4) tells us that if we substitute them into m and f , respectively, we get the same value with probability 1. Eq. <ref type="formula" target="#formula_4">(5)</ref> is also an equality of RVs, and the above procedure therefore not only reconstructs some properties of the unobservable RV Q -it reconstructs, up to the mean E <ref type="bibr">[Q]</ref>, and with probability 1, the RV itself. This may sound too good to be true -in practice, of course its accuracy will depend on how well the assumptions of Proposition 1 hold.</p><p>If the following conditions are met, we may expect that the procedure should work well in practice:</p><p>(i) X should be (almost) independent of Q -otherwise, our method could possibly remove parts of Q itself, and thus throw out the baby with the bathtub. A sufficient condition for this to be the case is that N be (almost) independent of Q, which often makes sense in practice, e.g., if N is introduced by a measuring device in a way independent of the underlying object being measured. Clearly, we can only hope to remove noise that is independent of the signal, otherwise it would be unclear what is noise and what is signal. A sufficient condition for N ⊥ ⊥ Q, finally, is that the causal DAG in <ref type="figure">Fig. 1</ref> correctly describes the underlying causal structure. Note, however, that Proposition 1 and thus our method also applies if N ⊥ ⊥ Q, as long as X ⊥ ⊥ Q.</p><p>(ii) The observable X is chosen such that Y can be predicted as well as possible from it; i.e., X contains enough information about f (N ) and, ideally, N acts on both X and Y in similar ways such that a "simple" function class suffices for solving the regression problem in practice. This may sound like a rather strong requirement, but we will see that in our astronomy application, it is not unrealistic: X will be a large vector of pixels of other stars, and we will use them to predict a pixel Y of a star of interest. In this kind of problem, the main variability of Y will often be due to the systematic effects due to the instrument N also affecting other stars, and thus a large set of other stars will indeed allow a good prediction of the measured Y .</p><p>Note that it is not required that the underlying structural equation model be linear -N can act on X and Y in nonlinear ways, as an additive term f (N ).</p><p>In practice, we never observe N directly, and thus it is hard to tell whether the assumption of perfect predictability of f (N ) from X holds true. We now relax this assumption.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Incomplete Information</head><p>First we observe that E[f (N )|X] is a good approximation for f (N ) whenever f (N ) is almost determined by X:</p><p>Lemma 2 For any two jointly random variables Z, X, we have</p><formula xml:id="formula_10">E[(Z − E[Z|X]) 2 ] = E[Var[Z|X]].<label>(9)</label></formula><p>Here </p><formula xml:id="formula_11">E[(Z − g(X)) 2 ] = E[h(X)] .<label>(10)</label></formula><p>Proof. Note that for any random variable Z we have</p><formula xml:id="formula_12">Var[Z|X = x] = E[(Z − E[Z|X = x]) 2 |X = x] ,</formula><p>by the definition of variance, applied to the variable Z| X=x . Hence</p><formula xml:id="formula_13">Var[Z|X] = E[(Z − E[Z|X]) 2 |X] ,</formula><p>where both sides are functions of X. Taking the expectation w.r.t. X on both sides yields</p><formula xml:id="formula_14">E[Var[Z|X]] = E[(Z − E[Z|X]) 2 ] ,</formula><p>where we have used the law of total expectation</p><formula xml:id="formula_15">E[E[W |X]] = E[W ] on the right hand side.</formula><p>This leads to a stronger result for our estimatorˆQestimatorˆ estimatorˆQ (2): </p><formula xml:id="formula_16">Proposition</formula><formula xml:id="formula_17">E[( ˆ Q − (Q − E[Q])) 2 ] = E[Var[f (N )|X]] .<label>(11)</label></formula><p>Proof. We rewrite the argument of the square in (11) asˆQ</p><formula xml:id="formula_18">asˆ asˆQ − (Q − E[Q]) = Y − E[Y |X] − Q + E[Q] = f (N ) + Q − E[f (N )|X] − E[Q|X] − Q + E[Q] = f (N ) − E[f (N )|X].</formula><p>Here, the last step uses</p><formula xml:id="formula_19">E[Q|X] = E[Q], which follows from Q ⊥ ⊥ X.</formula><p>The result follows using Lemma 2 with Z := f (N ).</p><p>Note that Proposition 1 is a special case of Proposition 3: if there exists a function ψ such that ψ(X) = f (N ), then the r.h.s. of <ref type="formula" target="#formula_0">(11)</ref> vanishes. Proposition 3 drops this assumption, which is more realistic: consider the case where X = g(N ) + R, where R is another random variable.</p><p>In this case, we cannot expect to reconstruct the variable f (N ) from X exactly.</p><p>There are, however, two settings where we would still expect good approximate recovery of Q:</p><p>(i) If the standard deviation of R goes to zero, the signal of N in X becomes strong and we can approximately estimate f (N ) from X, see Proposition 4.</p><p>(ii) Alternatively, we observe many different effects of N .</p><p>In the astronomy application below, Q and R are stars, from which we get noisy observations Y and X. Proposition 5 below shows that observing many different X i helps reconstructing Q, even if all X i depend on N through different functions g i and their underlying (independent) signals R i do not follow the same distribution. The intuition is that with increasing number of variables the independent R i "average" out, and thus it becomes easier to reconstruct the effect of N .</p><p>Proposition 4 Assume that Y = Q + f (N ) and let</p><formula xml:id="formula_20">X s := g(N ) + s · R ,</formula><p>where R, N and Q are jointly independent, f ∈ C 1 b (R), g ∈ C 1 (R), s ∈ R, and g is invertible. ThenˆQ</p><formula xml:id="formula_21">Thenˆ ThenˆQ s L 2 → Q − E[Q] as s → 0 , wherê Q s := Y − E[Y |X s ].</formula><p>Proof. We have for s → 0 that</p><formula xml:id="formula_22">s · R P → 0 ⇒ g(N ) + s · R − g(N ) P → 0 * ⇒ g −1 (g(N ) + s · R) − N P → 0 * ⇒ f g −1 (g(N ) + s · R) − f (N ) P → 0 ⇒ ψ s (X s ) − f (N ) P → 0</formula><p>for some ψ s that is bounded in s (the implications * follow from the continuous mapping theorem). <ref type="bibr">2</ref> This implies</p><formula xml:id="formula_23">E[f (N )|X s ] − f (N ) L 2 → 0 2</formula><p>The notation P → denotes convergence in probability with respect to the measure P of the underlying probability space.</p><p>Removing systematic errors for exoplanet search via latent causes</p><formula xml:id="formula_24">because E[(f (N ) − E[f (N )|X s ]) 2 ] ≤ E[(f (N ) − ψ s (X s )) 2 ]→0</formula><p>(L 2 convergence follows because f is bounded). But then</p><formula xml:id="formula_25">Q − E[Q] − ˆ Q s = −f (N ) − E[Q] + E[f (N ) + Q|X s ] = E[f (N )|X s ] − f (N ) L 2 → 0</formula><p>Proposition 5 Assume that Y = Q+f (N ) and that X d := (X 1 , . . . , X d ) satisfies</p><formula xml:id="formula_26">X i := g i (N ) + R i , i = 1, . . . , d,</formula><p>where all R i , N and Q are jointly independent,</p><formula xml:id="formula_27">∞ i=1 1 i 2 var(R i ) &lt; ∞, f ∈ C 1 b (R), g i ∈ C 1 (R) for all i, and˜g and˜ and˜g d := 1 d d j=1 g j is invertible with (˜ g −1 d ) d uniformly equicontinuous. ThenˆQ Thenˆ ThenˆQ d L 2 → Q − E[Q] as d → ∞ ,</formula><p>where we definê</p><formula xml:id="formula_28">Q d := Y − E[Y |X d ].</formula><p>Proof. By Kolmogorov's strong law, we have for</p><formula xml:id="formula_29">¯ µ d := 1 d d i=1 E[R i ] that 1 d d i=1 R i − ¯ µ d P → 0 ⇒ 1 d d i=1 (g i (N ) + R i ) − ¯ µ d − ˜ g d (N ) P → 0 * ⇒ ˜ g −1 d 1 d d i=1 (g i (N ) + R i ) − ¯ µ d − ˜ g −1 d (˜ g d (N )) P → 0 ⇒ ˜ g −1 d 1 d d i=1 X i − ¯ µ d − N P → 0 * * ⇒ f ˜ g −1 d 1 d d i=1 X i − ¯ µ d − f (N ) P → 0 ⇒ ψ d (X d ) − f (N ) P → 0</formula><p>for some ψ d that are uniformly bounded in d (the implication * follows from uniform equicontinuity, implication * * by the continuous mapping theorem). This implies (The convergence of the right hand side follows from</p><formula xml:id="formula_30">E[f (N )|X d ] − f (N ) L 2 → 0 because E[(f (N ) − E[f (N )|X d ]) 2 ] ≤ E[(f (N ) − ψ d (X d )) 2 ]→0</formula><formula xml:id="formula_31">ψ d (X d )−f (N ) P → 0 and boundedness of ψ d (X d )−f (N )). But then Q − E[Q] − ˆ Q d = −f (N ) − E[Q] + E[f (N ) + Q|X d ] = E[f (N )|X d ] − f (N ) L 2 → 0</formula><p>The next two subsections discuss optional extensions of our approach. Readers who are mainly interested in the application may prefer to move to Section 3 directly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Time Series</head><p>Above, we have worked with random variables and assumed that the regression is performed on i.i.d. data drawn from those random variables. However, in practice we also encounter problems where the data are drawn from random processes depending on time.</p><p>Consider a causal graph with an additional confounder T representing time, see <ref type="figure" target="#fig_3">Figure 2</ref>, and assume that the signals R and Q have a time series structure. This representation becomes necessary if R and Q share a strong periodicity, for example. If we want to retain this periodicity, we should not simply regress Y on X.</p><p>In many applications the signals may have a time structure but we expect R and Q as well as Q and N to be independent. We further assume that the signals R and Q will normally not share any strong frequencies. In those situations the representation shown in <ref type="figure" target="#fig_2">Figure 3</ref> may be more appropriate. Because of the independence between Q and R, we can proceed as before and estimate Q t as the residuals after regressing Y t from X t (we could even allow N to have a time structure, too). The graph structure shows that after including X t as a predictor for Y t , all other X t+h , h = 0 may contain further information about Y t . Note however, that this dependence decreases quickly  with increasing |h|, especially when the contribution of R t to X t is small compared to the contribution of N t to X t . Still, in some simulation settings, including different time lags X t+h , h ∈ {. . . , −1, 0, 1, . . .} into the model for Y t improves the performance of the method (in terms of reconstructing Q) compared to predicting Y t only from X t (results not shown). We expect that identifiability statements similar to the i.i.d. case may hold (see sections 2.1 and 2.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">Prediction from Non-Effects of the Noise Variable</head><p>While <ref type="figure">Fig. 1</ref> shows the causal structure motivating our work, our method does not require a directed arrow from N to X -it only requires that N ⊥ ⊥ X, to ensure that X contains information about N . We can represent this by an undirected connection between the two <ref type="figure" target="#fig_5">(Fig. 4)</ref>, and note that such a dependence may arise from an arrow directed in either direction, and/or another confounder that influences both N and X. This confounder need not act deterministically on N , hence effectively removing our earlier requirement of a deterministic effect, cf. (1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Applications</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Synthetic Data</head><p>We analyze two simulated data sets that illustrate the identifiability statements from Sections 2.1 and 2.2.</p><p>Increasing relative strength of N in a single X. We consider 20 instances (each time we sample 200 i.i.d. data points) of the model Y = f (N ) + Q and X = g(N ) + R, where f and g are randomly chosen sigmoid functions and the variables N , Q and R are normally distributed. The standard deviation for R is chosen uniformly between 0.05 and 1, the standard deviation for N is between 0.5 and 1. Because Q can be recovered only up to a shift in the mean, we set its sample mean to zero. The distribution for R, however, has a mean that is chosen uniformly between −1 and 1 and its standard deviation is chosen from the vector (1, 0.5, 0.25, 0.125, 0.0625, 0.03125, 0). Proposition 4 shows that with decreasing standard deviation of R we can recover the signal Q. Standard deviation zero corresponds to the case of complete information (Section 2.1). For regressing Y on X, we use the function gam (penalized regression splines) from the R-package mgcv; <ref type="figure" target="#fig_6">Figure 5</ref> shows that this asymptotic behavior can be seen on finite data sets.</p><p>Increasing number of observed X i variables. Here, we consider the same simulation setting as before, this time simulating X i = g i (N ) + R i for i = 1, . . . , p. We have shown in Proposition 5 that if the number of variables X i tends to infinity, we are able to reconstruct the signal Q. In this experiment, the standard deviation for R i and Q is chosen uniformly between 0.05 and 1; The distribution of N is the same as above. It is interesting to note that even additive models (in the predictor variables) work as a regression method (we use the function gam from the R-package mgcv on all variables X 1 , . . . , X p and its sum X 1 + . . . + X p ). <ref type="figure" target="#fig_6">Figure 5</ref> shows that with increasing p the reconstruction of Q improves. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Exoplanet Light Curves</head><p>The field of exoplanet search has recently become one of the most popular areas of astronomy research. This is largely due to the Kepler space observatory launched in 2009. Kepler observed a tiny fraction of the Milky Way in search of exoplanets. The telescope was pointed at same patch of sky for more than four years ( <ref type="figure" target="#fig_7">Fig. 6 and 7)</ref>. In that patch, it monitored the brightness of 150000 stars (selected from among 3.5 million stars in the search field), taking a stream of half-hour exposures using a set of CCD (ChargeCoupled Device) imaging chips arranged in its focal plane using the layout visible in <ref type="figure" target="#fig_8">Fig. 7</ref>. Kepler detects exoplanets using the transit method. Whenever a planet passes in front of their host star(s), we observe a tiny dip in the light curve <ref type="figure" target="#fig_9">(Fig. 8)</ref>. This signal is rather faint, and for our own planet as seen from space, it would amount to a brightness change smaller than 10 −4 , lasting less than half a day, taking place once a year, and visible from about half a percent of all directions. The level of required photometric precision to detect such transits is one of the main motivations for performing these observations in space, where they are not disturbed by atmospheric effects, and it is possible to observe the same patch almost continuously using the same instrument.</p><p>For planets orbiting stars in the habitable zone (allowing for liquid water) of stars similar to the sun, we would expect the signal to be observable at most every few months. We thus have very few observations of each transit. However, it has become clear that there is a number of confounders introduced by spacecraft and telescope that lead to systematic changes in the light curves which are of the same magnitude or larger than the required accuracy. The dominant error is pointing jitter: if the camera field moves by a tiny fraction of a pixel (for Kepler, the order of magnitude is 0.01 pixels), then the light distribution on the pixels will change. Each star affects a set of pixels ( <ref type="figure">Fig. 9)</ref>, and we integrate their measurements to get an estimate of the star's overall brightness. Unfortunately, the pixel sensitivities are not precisely identical, and even though one can try to correct for this, we are left with significant systematic errors. Overall, although Kepler is highly optimized for stable photometric measurements, its accuracy falls short of what is required for reliably detecting earth-like planets in habitable zones of sun-like stars.</p><p>We obtained the data from the Mikulski Archive for Space Telescopes (MAST) (see http://archive.stsci. edu/index.html). Our system, which we abbreviate as CPM (Causal Pixel Model), is based on the assumption that stars on the same CCD share systematic errors. If we pick two stars on the same CCD that are far away from each other, they will be light years apart in space and no physical interaction between them can take place. As <ref type="figure">Fig. 9</ref> shows, the light curves nevertheless have similar trends, which is caused by systematics. In CPM, we use linear regression to predict the light curve of each pixel belonging to the target star as a linear combination of a set of predictor pixels. Specifically, we use 4000 predictor pixels from about 150 (a) (b) <ref type="figure">Figure 9</ref>. Stars on the same CCD share systematic errors. The two panels show pixel fluxes (brightnesses) for two stars: (a) KIC 5088536, (b) KIC 5949551; here, KIC stands for Kepler Input Catalog. Both stars lie on the same CCD, but far enough apart such that there is no stray light from one affecting the other. Each panel shows the pixels contributing to the respective star. Note that there exist similar trends in some pixels of these two stars, caused by systematic errors. stars, which are selected to be closest in magnitude to the target star. 3 This is done since the systematic effects of the instruments depend somewhat on the star brightness; e.g., when a star saturates a pixel, blooming takes place and the signal leaks to neighboring pixels. To rule out any direct optical cross-talk by stray light, we require that the predictor pixels are from stars sufficiently far away from the target star (at least 20 pixels distance on the CCD), but we always take them from the same CCD (note that Kepler has a number of CCDs, and we expect that systematic errors depend on the CCD). We train the model separately for each month, which contains about 1300 data points. <ref type="bibr">4</ref> Standard L2 regularization is employed to avoid overfitting, and parameters (regularization strength and number of input pixels) were optimized using cross-validation. Nonlinear kernel regression was also evaluated, but did not lead to better results. This may be due to the fact that the set of predictor pixels is relatively large (compared to the training set size); and among this large set, it seems that there are sufficiently many pixels who are affected by the systematics in a rather similar way as the target.</p><p>We have observed in our results that the method removes some of the intrinsic variability of the target star. This is due to the fact that the signals are not i.i.d. and time acts as a confounder. If among the predictor stars, there exists one whose intrinsic variability is very similar to the target star, then the regression can attenuate variability in the latter. This is unlikely to work exactly, but given the limited observation window, an approximate match (e.g., stars varying at slightly different frequencies) will already lead to some amount of attenuation. Since exoplanet transits are very rare, it is extremely unlikely (but not impossible) that the same mechanism will remove some transits.</p><p>Note that for the purpose of exoplanet search, the stellar variability can be considered a confounder as well, independent of the planet positions which are causal for transits. In order to remove this, we use as additional regression inputs also past and future of the target star. This adds an autoregressive (AR) component to our model, removing more of the stellar variability and thus increasing the sensitivity for transits. In this case, we select an exclusion window around the point of time being corrected, to ensure that we do not remove the transit itself. Below, we report results where the AR component uses as inputs the three closest future and the three closest past time points, subject to the constraint that a window of ±9 hours around the considered time point is excluded. Choosing this window corresponds to the assumption that time points earlier than -9 hours or later than +9 hours are not informative for the transit itself. Smaller windows allow more accurate prediction, at the risk of damaging slow transit signals. Our code is available at https://github.com/ jvc2688/KeplerPixelModel.</p><p>To give a view on how our method performs, CPM is applied on several stars with known transit signals. After that, we compare them with the Kepler Pre-search Data Conditioning (PDC) method (see http://keplergo. arc.nasa.gov/PipelinePDC.shtml). PDC builds on the idea that systematic errors have a temporal structure that can be extracted from ancillary quantities. The first version of PDC removed systematic errors based on correlations with a set of ancillary engineering data, including temperatures at the detector electronics below the CCD array, and polynomials describing centroid motions of stars. The current PDC ( <ref type="bibr" target="#b16">Stumpe et al., 2012;</ref><ref type="bibr" target="#b13">Smith et al., 2012)</ref> performs PCA on filtered light curves of stars, projects the light curve of the target star on a PCA subspace, and subsequently removes this projection. The PCA is performed on a set of relatively quiet stars close in position and magnitude. For non-i.i.d. data, this procedure could remove temporal structure of interest. To prevent this, the PCA subspace is restricted to eight dimensions, strongly limiting the capacity of the model (cf. <ref type="bibr" target="#b1">Foreman-Mackey et al., 2015</ref>).</p><p>In <ref type="figure" target="#fig_10">Fig. 10</ref>, we present corrected light curves for three typical stars of different magnitudes, using both CPM and PDC. Note that in our theoretical analysis, we dealt with additive noise, and could deal with multiplicative noise, e.g., by log transforming. In practice, none of the two models is correct for our application. If we are interested in the transit (and not the stellar variability), then the variability is a multiplicative confounder. At the same time, other noises may better be modeled as additive (e.g., CCD noise). In practice, we calibrate the data by dividing by the regression estimate and then subtracting 1, i.e.,</p><formula xml:id="formula_32">Y E[Y |x] − 1 = Y E[Y |x] − E[Y |x] E[Y |x] = Y − E[Y |x] E[Y |x] .</formula><p>Effectively, we thus perform a subtractive normalization, followed by a divisive one. This worked well, taking care of both types of contaminations.</p><p>The results illustrate that our approach removes a major part of the variability present in the PDC light curves, while preserving the transit signals. To provide a quantitative comparison, we ran CPM on 1000 stars from the whole Kepler input catalog (500 chosen randomly from the whole list, and 500 random G-type sun-like stars), and estimate the Combined Differential Photometric Precision (CDPP) for CPM and PDC. CDPP is an estimate of the relative precision in a time window, indicating the noise level seen by a transit signal with a given duration. The duration is typically chosen to be 3, 6, or 12 hours ( <ref type="bibr" target="#b0">Christiansen et al., 2012</ref>). Shorter durations are appropriate for planets close to their host stars, which are the ones that are easier to detect. We use the 12-hours CDPP metric, since the transit duration of an earth-like planet is roughly 10 hours. <ref type="figure" target="#fig_11">Fig. 11</ref> presents our CDPP comparison of CPM and PDC, showing that our method outperforms PDC. This is no small feat, since PDC is highly optimized for the task at hand, incorporating substantial astronomical knowledge (e.g., it attempts to remove stellar variability as well as systematic trends).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>We have assayed half-sibling regression, a simple yet effective method for removing the effect of systematic noise from observations. It utilizes the information contained in a set of other observations affected by the same noise source. The main motivation for the method was its application to exoplanet data processing, which we discussed in some detail, with rather promising results. However, we expect that it will have a large range of applications in other domains as well.</p><p>We expect that our method may enable astronomical discoveries at higher sensitivity on the existing Kepler satellite data. Moreover, we anticipate that methods to remove systematic errors will further increase in importance: by May 2013, two of the four reaction wheels used to control the Kepler spacecraft were disfunctional, and in May 2014, NASA announced the K2 mission, using the remaining two wheels in combination with thrusters to control the spacecraft and continue the search for exoplanets in other star fields. Systematic errors in K2 data are significantly larger since the spacecraft has become harder to control. In addition, NASA is planning the launch of another space telescope for 2017. TESS (Transiting Exoplanet Survey Satellite) <ref type="bibr">5</ref> will perform an all-sky survey for small (earth-like) planets of nearby stars. To date, no earth-like planets orbiting sun-like stars in the habitable zone have been found. This is likely to change in the years to come, which would be a major scientific discovery. <ref type="bibr">6</ref> In particular, while the proposed method treats the problem of removing systematic errors as a preprocessing step, we are also exploring the possibility of jointly modeling systematics and transit events. This incorporates additional knowledge about the events that are looking for in our specific application, and it has already led to promising results <ref type="bibr" target="#b1">(Foreman-Mackey et al., 2015)</ref>. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Extended version of a paper appearing in the Proceedings of the 32 nd International Conference on Machine Learning, Lille, France, 2015. JMLR: W&amp;CP volume 37. Copyright 2015 by the author(s).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>,</head><label></label><figDesc>E[Z|X] is the random variable g(X) with g(x) = E[Z|X = x], and Var[Z|X] is the random variable h(X) with h(x) = Var[Z|X = x]. Then (9) turns into</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>3</head><label>3</label><figDesc>Let f be measurable, N, Q, X, Y jointly random variables with Q ⊥ ⊥ X, and Y = Q + f (N ). The expected squared deviation betweenˆQbetweenˆ betweenˆQ and Q − E[Q] satisfies</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. While Fig. 1 refers to i.i.d. data, the present figure includes an effect of time T on our quantity of interest, Q, and through the signal R on our predictors X which are affected by the same noise N . Simply regressing Y on X as in the i.i.d. case removes some of the signal Q from Y . Allowing for an edge T → N makes the problem even more difficult.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Special case of Figure 2. Here, the signals Q and R are independent and thus regressing Yt on Xt is valid in the sense that it would not remove any information of Qt from Yt.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Causal structure from Fig. 1 when relaxing the assumption that X is an effect of N .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Left: we observe a variable X = g(N ) + R with invertible function g. If the variance of R decreases, the reconstruction of Q improves because it becomes easier to remove the influence f (N ) of the noise N from the variable Y = f (N ) + Q by using X, see Proposition 4. Right: a similar behavior occurs with increasing the number p of predictor variables Xi = gi(N ) + Ri, see Proposition 5. Both plots show 20 scenarios, each connected by a thin line.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. View of the Milky Way with position of the sun and depiction of the Kepler search field (image credit: NASA).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Kepler search field as seen from Earth, located close to the Milky Way plane, in a star-rich area near the constellation Cygnus (image credit: NASA).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Sketch of the transit method for exoplanet detection. As a planet passes in front of its host star, we can observe a small dip in the apparent star brightness (image credit: NASA Ames).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 10 .</head><label>10</label><figDesc>Figure 10. Corrected fluxes using our method, for three example stars, spanning the main magnitude (brightness) range encountered. In (a), we consider a bright star, in (b), a star of moderate brightness, and in (c), a relatively faint star. SAP stands for Simple Aperture Photometry (in our case, a relative flux measure computed from summing over the pixels belonging to a star). In all three panels, the top plot shows the SAP flux (black) and the CPM regression (red), i.e., our prediction of the star from other stars. The middle panel shows the CPM flux corrected using the regression (details see text), and the bottom shows the PDC flux (i.e., the default method). The CPM flux curve preserves the exoplanet transits (little downward spikes), while removing a substantial part of the variability present in the PDC flux. All x-axes show time, measured in days since 1/1/2009.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 11 .</head><label>11</label><figDesc>Figure 11. Comparison of the proposed method (CPM) to the Kepler PDC method in terms of Combined Differential Photometric Precision (CDPP) (see text). Plot (a) shows our performance (red) vs. the PDC performance in a scatter plot, as a function of star magnitude (note that larger magnitude means fainter stars, and smaller values of CDPP indicate a higher quality as measured by CDPP. Plot (b) bins the same dataset and shows box plots within each bin, indicating median, top quartile and bottom quartile. The red box corresponds to CPM, while the black box refers to PDC. Plot (c), finally, shows a histogram of CDPP values. Note that the red histogram has more mass towards the left, i.e., smaller values of CDPP, indicating that our method overall outperforms PDC, the Kepler "gold standard."</figDesc></figure>

			<note place="foot" n="1"> This means that there are some degrees of freedom in the parametrization of the model which do not affect the observable model.</note>

			<note place="foot" n="3"> The exact number of stars varies with brightness, as brighter stars have larger images on the CCD and thus more pixels. 4 The data come in batches which are separated by larger errors, since the spacecraft needs to periodically re-direct its antenna to send the data back to earth.</note>

			<note place="foot" n="5"> http://tess.gsfc.nasa.gov/ 6 &quot;Decades, or even centuries after the TESS survey is completed, the new planetary systems it discovers will continue to be studied because they are both nearby and bright. In fact, when starships transporting colonists first depart the solar system, they may well be headed toward a TESS-discovered planet as their new home.&quot; (Haswell, 2010)</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Stefan Harmeling, James McMurray, Oliver Stegle and Kun Zhang for helpful discussion, and the anonymous reviewers for helpful suggestions and references. C-J S-G was supported by a Google Europe Doctoral Fellowship in Causal Inference.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The Derivation, Properties, and Value of Kepler&apos;s Combined Differential Photometric Precision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Christiansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Caldwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Seader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Barclay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Clarke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Stumpe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Twicken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Van Cleve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Publications of the Astronomical Society of the Pacific</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="1279" to="1287" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">A systematic search for transiting planets in the K2 data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Foreman-Mackey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">T</forename><surname>Montet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Hogg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Morton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1502.04715</idno>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Gagnon-Bartsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">P</forename><surname>Speed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Biostatistics</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="539" to="552" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carole</forename><forename type="middle">A</forename><surname>Haswell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Transiting Exoplanets</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Nonlinear causal discovery with additive noise models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">O</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in Neural Information Processing Systems</title>
		<editor>Koller, D., Schuurmans, D., Bengio, Y., and Bottou, L.</editor>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="689" to="696" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Identifying confounders using additive noise models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">25th Conference on Uncertainty in Artificial Intelligence</title>
		<editor>Bilmes, J and Ng, AY</editor>
		<meeting><address><addrLine>Corvallis, OR, USA</addrLine></address></meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="249" to="257" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Adjusting batch effects in microarray expression data using empirical Bayes methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">118127</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Kang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ye</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Eskin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Genetics</title>
		<imprint>
			<biblScope unit="volume">180</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1909" to="1925" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An Improved Photometric Calibration of the Sloan Digital Sky Survey Imaging Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Padmanabhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Schlegel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Finkbeiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Barentine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Blanton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Brewington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Gunn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Harvanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Hogg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">ˇ</forename><forename type="middle">Z</forename><surname>Ivezi´civezi´c</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Johnston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Kent</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Kleinman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Knapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krzesinski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Long</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Neilsen</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nitta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Loomis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Lupton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roweis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Snedden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Strauss</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Tucker</surname></persName>
		</author>
		<idno type="doi">doi:10.1086/524677</idno>
	</analytic>
	<monogr>
		<title level="j">The Astrophysical Journal</title>
		<imprint>
			<biblScope unit="volume">674</biblScope>
			<biblScope unit="page" from="1217" to="1233" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Causality</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Causal discovery with continuous additive noise models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mooij</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Alkes</forename><forename type="middle">L</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><forename type="middle">J</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Robert</forename><forename type="middle">M</forename><surname>Plenge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">E</forename><surname>Weinblatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Shadick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nancy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">David</forename><surname>Reich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Genetics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="904" to="909" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On causal and anticausal learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Schölkopf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Janzing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sgouritsa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mooij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 29th International Conference on Machine Learning (ICML)</title>
		<editor>Langford, J and Pineau, J</editor>
		<meeting>the 29th International Conference on Machine Learning (ICML)<address><addrLine>New York, NY, USA</addrLine></address></meeting>
		<imprint>
			<publisher>Omnipress</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="1255" to="1262" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Kepler Presearch Data Conditioning II -A Bayesian Approach to Systematic Error Correction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Stumpe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Van Cleve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Barclay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Fanelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Girouard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Kolodziejczak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Mccauliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Twicken</surname></persName>
		</author>
		<idno type="doi">doi:10.1086/667697</idno>
	</analytic>
	<monogr>
		<title level="j">Publications of the Astronomical Society of the Pacific</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="1000" to="1014" />
			<date type="published" when="2012-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Causation, prediction, and search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
	<note>2nd edition</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Accounting for non-genetic factors improves the power of eQTL studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Stegle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Oliver</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anitha</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Richard</forename><surname>Durbin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Winn</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Research in Computational Molecular Biology, 12th Annual International Conference, RECOMB</title>
		<meeting>Research in Computational Molecular Biology, 12th Annual International Conference, RECOMB</meeting>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="page" from="411" to="422" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Kepler Presearch Data Conditioning I -Architecture and Algorithms for Error Correction in Kepler Light Curves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Stumpe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Van Cleve</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Twicken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Barclay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Fanelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">R</forename><surname>Girouard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Kolodziejczak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Mccauliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morris</forename></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Publications of the Astronomical Society of the Pacific</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="985" to="999" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A unified mixed-model method for association mapping that accounts for multiple levels of relatedness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jianming</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pressoir</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Gael</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Briggs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Vroh</forename><surname>Bi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Irie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Yamasaki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Masanori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><forename type="middle">F</forename><surname>Doebley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">D</forename><surname>Mcmullen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Brandon</forename><forename type="middle">S</forename><surname>Gaut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dahlia</forename><forename type="middle">M</forename><surname>Nielsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">James</forename><forename type="middle">B</forename><surname>Holland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stephen</forename><surname>Kresovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Buckler</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Genetics</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="203" to="208" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
