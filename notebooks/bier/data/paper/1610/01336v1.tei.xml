<?xml version="1.0" encoding="UTF-8"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /mnt/ResearchCloud/Projects/ExoPlanets/notebooks/grobid/grobid-0.5.2/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<encodingDesc>
			<appInfo>
				<application version="0.5.2" ident="GROBID" when="2018-12-04T16:29+0000">
					<ref target="https://github.com/kermitt2/grobid">GROBID - A machine learning software for extracting information from scholarly documents</ref>
				</application>
			</appInfo>
		</encodingDesc>
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">ON CORRELATED-NOISE ANALYSES APPLIED TO EXOPLANET LIGHT CURVES</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2016-10-05">5 Oct 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Patricio</forename><surname>Cubillos</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Physics</orgName>
								<orgName type="laboratory">Planetary Sciences Group</orgName>
								<orgName type="institution">University of Central Florida</orgName>
								<address>
									<postCode>32816-2385</postCode>
									<settlement>Orlando</settlement>
									<region>FL</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Space Research Institute</orgName>
								<orgName type="institution">Austrian Academy of Sciences</orgName>
								<address>
									<addrLine>Schmiedlstrasse 6</addrLine>
									<postCode>A-8042</postCode>
									<settlement>Graz</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joseph</forename><surname>Harrington</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Physics</orgName>
								<orgName type="laboratory">Planetary Sciences Group</orgName>
								<orgName type="institution">University of Central Florida</orgName>
								<address>
									<postCode>32816-2385</postCode>
									<settlement>Orlando</settlement>
									<region>FL</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><forename type="middle">J</forename><surname>Loredo</surname></persName>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Cornell Center for Astrophysics and Planetary Sciences</orgName>
								<orgName type="department" key="dep2">Space Sciences Building</orgName>
								<orgName type="institution">Cornell University</orgName>
								<address>
									<postCode>14853-6801</postCode>
									<settlement>Ithaca</settlement>
									<region>NY</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nate</forename><forename type="middle">B</forename><surname>Lust</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Physics</orgName>
								<orgName type="laboratory">Planetary Sciences Group</orgName>
								<orgName type="institution">University of Central Florida</orgName>
								<address>
									<postCode>32816-2385</postCode>
									<settlement>Orlando</settlement>
									<region>FL</region>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Astrophysical Sciences</orgName>
								<orgName type="institution">Princeton University</orgName>
								<address>
									<postCode>08544</postCode>
									<settlement>Princeton</settlement>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jasmina</forename><surname>Blecic</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Physics</orgName>
								<orgName type="laboratory">Planetary Sciences Group</orgName>
								<orgName type="institution">University of Central Florida</orgName>
								<address>
									<postCode>32816-2385</postCode>
									<settlement>Orlando</settlement>
									<region>FL</region>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Department of Physics</orgName>
								<orgName type="institution">New York University Abu Dhabi</orgName>
								<address>
									<postBox>PO Box 129188</postBox>
									<settlement>Abu Dhabi</settlement>
									<country key="AE">UAE</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madison</forename><surname>Stemm</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Physics</orgName>
								<orgName type="laboratory">Planetary Sciences Group</orgName>
								<orgName type="institution">University of Central Florida</orgName>
								<address>
									<postCode>32816-2385</postCode>
									<settlement>Orlando</settlement>
									<region>FL</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">ON CORRELATED-NOISE ANALYSES APPLIED TO EXOPLANET LIGHT CURVES</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2016-10-05">5 Oct 2016</date>
						</imprint>
					</monogr>
					<note>IN PREPARATION FOR ApJ. DRAFT OF OCTOBER 6, 2016. Preprint typeset using L A T E X style AASTeX6 v. 1.0</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<profileDesc>
			<textClass>
				<keywords>methods: statistical -planets and satellites: fundamental parameters -techniques: photometric</keywords>
			</textClass>
			<abstract>
				<p>Time-correlated noise is a significant source of uncertainty when modeling exoplanet light-curve data. A correct assessment of correlated noise is fundamental to determine the true statistical significance of our findings. Here we review three of the most widely used correlated-noise estimators in the exoplanet field, the time-averaging, residual-permutation, and wavelet-likelihood methods. We argue that the residual-permutation method is unsound in estimating the uncertainty of parameter estimates. We thus recommend to refrain from this method altogether. We characterize the behavior of the time averaging&apos;s rms-vs.-bin-size curves at bin sizes similar to the total observation duration, which may lead to underestimated uncertainties. For the wavelet-likelihood method, we note errors in the published equations and provide a list of corrections. We further assess the performance of these techniques by injecting and retrieving eclipse signals into synthetic and real Spitzer light curves, analyzing the results in terms of the relative-accuracy and coverage-fraction statistics. Both the time-averaging and wavelet-likelihood methods significantly improve the estimate of the eclipse depth over a white-noise analysis (a Markov-chain Monte Carlo exploration assuming uncorrelated noise). However, the corrections are not perfect, when retrieving the eclipse depth from Spitzer datasets, these methods covered the true (injected) depth within the 68% credible region in only ∼45-65% of the trials. Lastly, we present our open-source model-fitting tool, Multi-Core Markov-Chain Monte Carlo (MC 3). This package uses Bayesian statistics to estimate the best-fitting values and the credible regions for the parameters for a (user-provided) model. MC 3 is a Python/C code, available at https://github.com/pcubillos/MCcubed.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">COMPUTING PARAMETER UNCERTAINTIES 3.1. Markov-chain Monte Carlo</head><p>In the Bayesian framework, a credible region for the parameters of a model, M, can be computed via the Markovchain Monte Carlo (MCMC) algorithm. The MCMC method generates a large number of random samples from the parameter space with a probability density proportional to the posterior probability distribution:</p><formula xml:id="formula_5">p(θ| y, M) ∝ p(θ|M)p( y|θ, M),<label>(6)</label></formula><p>where p(θ|M) is the prior probability distribution. A marginal highest-posterior-density (HPD) credible region for each parameter is then obtained from the interval that contains a certain fraction of the highest posterior density (typically 68%, 95%, or 99%) of the marginalized posterior (see Appendix A). For example, when the posterior follows a normal distribution, the 68.3% marginal credible interval corresponds to the interval contained within one standard deviation from the mean. Inference based on the likelihood function of Eq. (3) works well when the noise contributions are independent and normally distributed; however, it does not account for timecorrelated noise. Alternatively, an inference that uses the full covariance matrix, as in of Eq. (4), should account for correlated noise, although its calculation often becomes computationally prohibitive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Time Averaging</head><p>Pont et al. (2006) developed a method to compute the uncertainty of a transit or eclipse-depth estimation using the light-curve data points themselves. They considered the noise as the sum in quadrature of two components, a purely white (uncorrelated) source (characterized by a standard deviation per data point σ w ), and a purely time-correlated source (characterized by σ r ). <ref type="bibr" target="#b37">Pont et al. (2006)</ref> assumed the white-noise component to scale as σ w / √ n, with n the number of data points in the transit; whereas the time-correlated standard deviation, σ r , to be independent of the number of data points. Then for any given signal, the uncertainty of a measurement should scale as:</p><formula xml:id="formula_6">σ d = σ 2 w n + σ 2 r .<label>(7)</label></formula><p>For small n, σ d may be dominated by σ w / √ n, whereas as n increases, σ d approaches σ r . The time-averaging method uses this fact to estimate the contribution from the correlated noise. Note, however, that this hypothesized behavior is not typical of stationary correlated noise models exhibiting longrange dependence, which instead have σ d decreasing at a rate slower than 1/ √ n, but still monotonically decreasing to zero <ref type="bibr" target="#b3">(Beran et al. 2013</ref>).</p><p>We implement the time-averaging procedure as described by <ref type="bibr" target="#b46">Winn et al. (2007)</ref>. First, we calculate the residuals between the data points and the best-fitting model. Then, we group the residuals in time-ordered, non-overlapping bins of N elements each, and calculate their mean values. Lastly, we calculate the standard deviation (or root mean squared, rms) of the binned residuals, rms N . We repeat the process for a range of bin sizes from one to half the data size. The uncertainty of rms N is approximately σ rms = rms N / √ 2M (see Appendix C). Now, let σ 1 be the rms value of the non-binned residuals (presumed to be dominated by white noise). In the absence of correlated noise, the expected rms for the set of M bins, each containing N points, is given by the extrapolation of σ 1 ( <ref type="bibr" target="#b46">Winn et al. 2008)</ref>:</p><formula xml:id="formula_7">σ N = σ 1 √ N M M − 1 .<label>(8)</label></formula><p>The rms N and σ N curves are analogous to σ d and σ w , respectively. The time-averaging correction inflates the data uncertainties multiplying them by the ratio β N = rms N /σ N if β N is statistically larger than one (i.e., by more than 1σ β = σ rms /σ N ). Finally, one runs a white-noise MCMC analysis, i.e., with Eq. (3), using the inflated data errors. One typically visualizes both curves in an rms vs. bin size plot <ref type="figure" target="#fig_0">(Figure 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Behavior at Large Bin Sizes</head><p>One has to be aware that the binned-rms uncertainty σ rms is an asymptotic approximation. In the large bin-size regime (equivalently, small M ) that approximation is not justified. The reason is that the marginalized posterior distribution for rms N (Eq. 33), which has the form of an inverse-gamma distribution, becomes increasingly skewed as M decreases.</p><p>By comparing the 68%-credible-region error bars of the inverse-gamma formula with the asymptotic approximation, we find that the latter moderately overestimates the lower error bar by 5%-10% for M &lt; 200. For the upper error bar the asymptotic approximation underestimates the error by 5% to 450% between M = 200 and M = 2. If one does not consider the skewed error bars, it may seem that the rms curves deviate below the σ N curve at large bin sizes (e.g., <ref type="bibr" target="#b43">Stevenson et al. 2012a</ref><ref type="bibr" target="#b11">, Cubillos et al. 2013</ref><ref type="bibr" target="#b4">, Blecic et al. 2013</ref>). However, this deviation is not statistically significant when one computes the uncertainties with the correct posterior distribution.</p><p>Since the typical transit (or eclipse) observation does not last much longer than the duration of the transit itself (usually one-two hours of out-of-transit before and after), it is important to consider the asymmetric rms error bars to properly account for correlated noise. Furthermore, since the signalto-noise ratio of rms N decreases proportionally to √ M as N increases, one ideally wants the longest-possible observation duration to improve the constraint on β N at the desired timescale of the event.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Residual Permutation</head><p>Residual permutation (also called the prayer bead method) is inspired by nonparametric bootstrapping methods from frequentist statistics. Nonparametric bootstrap methods directly use the sampled data (typically via resampling) to generate a distribution that approximates the sampling distribution, p( y|θ * ), for the true parameter values, θ * . Nonparametric bootstrapping typically relies on independent resampling of the data or residuals (possibly re-scaled), with replacement (e.g., <ref type="bibr" target="#b13">Davison &amp; Hinkley 1997</ref><ref type="bibr" target="#b39">, Ruppert &amp; Matteson 2015</ref>.</p><p>The motivating idea of the residual-permutation approach is to shift the data while preserving the time ordering and, thus, preserving the correlation structure. While the structure is indeed preserved, the residual-permutation method does not resample with replacement, a crucial requrement for nonparametric bootstrapping to work, i.e., to produce independent replicated datasets (a resample of the entire time-series observation). When there is correlated noise, the shifted datasets do not correspond to an independent resampling from any distribution, and thus do not exhibit the variability necessary for correct uncertainty quantification (e.g., computing confidence levels or estimator bias).</p><p>In the exoplanet field, the residual-permutation technique has been repeatedly used to estimate parameter uncertainties. However, the name of the technique has been loosely used to describe similar, but not equivalent procedures over the past decade. <ref type="bibr" target="#b5">Bouchy et al. (2005)</ref>, <ref type="bibr" target="#b22">Gillon et al. (2007)</ref>, and Southworth (2008) all describe different methods, when referring to residual permutations. Some authors reference <ref type="bibr" target="#b27">Jenkins et al. (2002)</ref>, who actually use a "segmented bootstrap", applying the method for detection instead of parameter estimation. Furthermore, several authors have wrongly attributed the method to <ref type="bibr" target="#b35">Moutou et al. (2004)</ref>. Thus, there is a visible lack of rigor in the use of this method.</p><p>Currently, the most widely-used version of residual permutation is the one described by <ref type="bibr" target="#b41">Southworth (2008)</ref> or <ref type="bibr" target="#b46">Winn et al. (2008)</ref>. This implementation computes the residuals between the light curve and the best-fitting model, cyclically shifts the residuals (preserving the point-to-point structure and thus the "redness" of the noise) by a given number of data points, adds the residuals back to the model, and finds a new set of best-fitting parameters. Usually, either one repeats the shift-fit process for a large number of iterations with random shifts, or one sequentially shifts the residuals by one data point at a time, fitting all possible shifts. Each parameter uncertainty is then given by the respective standard deviation of the distribution of best-fitting values. As already noted, this does not correspond to a sound resampling procedure, thus we will not consider residual permutations for the subsequent analyses.</p><p>There is a significant literature on generalizing the independent and identically distributed nonparametric bootstrap idea to address time series problems with correlated noise; this is a topic of ongoing research. One widely used approach is the block bootstrap. Presuming the investigator knows or can estimate a longest scale for correlations, ∆t, the data are divided into blocks of length greater than ∆t, and bootstrap resampling is done by drawing blocks of data at random to build a replication. A particular block rigidly preserves the time ordering of a subset of the data; in replications, it will appear shifted in time by various amounts. This behavior resembles the behavior of the prayer bead method. But block resampling produces greater variability than shifting the entire data vector, and by sampling with replacement, it produces ensembles that approximate independent draws from a (dependent) sampling distribution. The "segmented bootstrap" devised by <ref type="bibr" target="#b27">Jenkins et al. (2002)</ref> for analysis of ground-based transit photometry is similar to the block bootstrap. The block bootstrap only works if the correlation scale is significantly shorter than the span of the data, which will often not be true for Spitzer exoplanet eclipse data, so we do not consider it further here. Further details about the block bootstrap and other methods for resampling dependent data may be found in <ref type="bibr" target="#b30">Lahiri (2003)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Wavelet Analysis</head><p>Carter &amp; Winn (2009) introduced to the exoplanet field a technique where the time-correlated noise is modeled using wavelet transforms <ref type="bibr" target="#b16">(Deriche &amp; Tewfik 1993</ref><ref type="bibr" target="#b50">, Wornell 1993</ref><ref type="bibr" target="#b48">, Wornell &amp; Oppenheim 1992a</ref>. This method projects the time series residuals into an orthonormal wavelet basis, where the off-diagonal terms of the covariance matrix become negligible, thus simplifying the likelihood function calculation. Furthermore, they assumed noise that has a power spectral density with frequency f , varying as 1/f γ . They parameterized the noise with three parameters, γ, σ ω , and σ r , as described in Equations <ref type="formula" target="#formula_0">(41)</ref>- <ref type="formula" target="#formula_2">(43)</ref> of <ref type="bibr" target="#b7">Carter &amp; Winn (2009)</ref>.</p><p>A thorough review of wavelets is beyond the scope of this work; see <ref type="bibr" target="#b32">Mallat (2008)</ref> and <ref type="bibr" target="#b50">Wornell (1996)</ref> for more comprehensive discussions. Briefly, a wavelet transform projects a time-series signal onto a basis of functions that are dilations and translations of a compact parent ("wavelet") function. The resulting transform has two dimensions, scale and location (in time). The discrete wavelet transform (DWT) consists of the hierarchical application over M dilation scales of an orthonormal wavelet transform on a discrete time-series signal. For a signal consisting of N = N 0 2 M uniformlyspaced samples (with N 0 integer), and a wavelet function with 2N 0 coefficients, the DWT produces N 0 scaling coefficients and N 0 2 m−1 wavelet coefficients at each scale m, totaling N 0 (2 M − 1) wavelet coefficients.</p><p>Carter &amp; Winn (2009) recommend the fourth-order Daubechies wavelet basis <ref type="bibr" target="#b12">(Daubechies 1988</ref>) for modeling time-series correlated noise, which we adopt in the current work. This is a basis well localized in time and frequency, well suited for 1/f γ noise <ref type="bibr" target="#b50">(Wornell 1996)</ref>. <ref type="bibr" target="#b7">Carter &amp; Winn (2009)</ref> found that correlations between the wavelet and scaling coefficients decays faster for the Daubechies basis than the Haar basis, producing negligible covariances. Another advantage is that since the Daubechies basis is well localized in time, it reduces artifacts arising from the assumption of a periodic boundary condition by the wavelet transform.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1.">Wavelet-based Likelihood</head><p>The likelihood function in the wavelet analysis is calculated in the following way. Let ǫ(t) be the fitting residuals of a time-series signal. Considering ǫ(t) as the contribution of a time-correlated (γ = 0) and an uncorrelated (γ = 0) component:</p><formula xml:id="formula_8">ǫ(t) = ǫ γ (t) + ǫ 0 (t),<label>(9)</label></formula><p>this method calculates the DWT of ǫ(t) to produce the wavelet, r m n , and scaling, ¯ r 1 n , coefficients of the signal. The variances of these coefficients are computed, respectively, as:</p><formula xml:id="formula_9">σ 2 W = σ 2 r 2 −γm + σ 2 ω (10) σ 2 S = σ 2 r 2 −γ g(γ) + σ 2 ω ,<label>(11)</label></formula><p>where σ ω and σ r parameterize the standard deviation of the uncorrelated and the correlated-noise signals, respectively, and g(γ) = 1/(2 1−γ − 1) for γ = 1 (following derivations from, e.g., <ref type="bibr" target="#b18">Fadili &amp; Bullmore 2002</ref><ref type="bibr" target="#b50">, Wornell 1993</ref> and g(γ) = 1/2 ln 2 for γ = 1 <ref type="bibr" target="#b7">(Carter &amp; Winn 2009</ref>) (see Appendix ??). Therefore, the wavelet-based likelihood function is given by</p><formula xml:id="formula_10">L(x, σ ω , σ r ) =    M m=1 N02 m−1 n=1 1 2πσ 2 W exp − (r m n ) 2 2σ 2 W    × n0 n=1 1 2πσ 2 S exp − (¯ r 1 n ) 2 2σ 2 S .<label>(12)</label></formula><p>Equation <ref type="formula" target="#formula_0">(12)</ref> allows one to fit a model, sample its parameter's posterior distribution, and determine the credible regions, while taking into account the effects of time-correlated noise.</p><p>During our review and implementation of the waveletlikelihood technique from <ref type="bibr" target="#b7">Carter &amp; Winn (2009)</ref>, we found a few oversights in their equations and code (available in the Astronomical Source Code Library, ASCL 1 ). See details in Appendix D.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">CORRELATED-NOISE TESTS FOR EXOPLANET ECLIPSE DATA</head><p>To assess the performance of the correlated-noise estimators described in Section 3, we carried out injection-retrieval eclipse simulations. We focus on estimating the secondaryeclipse depth in a light curve observation, creating synthetic light curves that resemble Spitzer InfraRed Array Camera (IRAC) observations in terms of the signal-to-noise ratio (S/N), known systematics, cadence, observation duration, and eclipse shape.</p><p>In our first experiment we test the estimators' performances when the time-correlated noise is described by a stochastic wavelet signal with a 1/f power spectral density (similar to the experiment of <ref type="bibr" target="#b7">Carter &amp; Winn 2009)</ref>. We test the case when the observation time span is similar to the eclipse-event duration (Section 4.1, typical of real Spitzer secondary eclipse observations) and for the hypothetical case when the time span lasted an order of magnitude longer than the eclipse event (Section 4.2). In a second experiment (Section 4.3) we test the estimators on a more realistic case by injecting a synthetic eclipse signal into Spitzer phase-curve datasets. In this simulation we generate synthetic light curves by combining a <ref type="bibr" target="#b33">Mandel &amp; Agol (2002)</ref> eclipse model, a linear ramp model, and a signal with both correlated and uncorrelated noise. The light-curve parameters closely follow those of a Spitzer observation of the WASP-12 system <ref type="table" target="#tab_0">(Table 1)</ref>. The signal consists of 1700 data points, with a cadence of ∼12 seconds between data points, spanning an orbital-phase range from 0.39 to 0.63, about twice the eclipse duration. We created three sets of 5000 light-curve realizations each. For each realization, we generate a zero-mean random normal distribution, which we add to the light curve as the uncorrelated noise signal. We adjust the variance of this signal (σ 2 ω ) to yield an eclipse-depth signal-to-noise ratio of 30. Additionally, we generate purely-correlated 1/f signals (σ ω = 0) using a Gaussian random number generator to produce wavelet coefficients with variances given by Equations (10) and (11). Then, we apply the inverse DWT to transform the signal from the wavelet basis to the time domain. Following the notation of <ref type="bibr" target="#b7">Carter &amp; Winn (2009)</ref>, we denote by α the ratio between the rms of the uncorrelated and correlated noise signals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Synthetic-noise Simulation</head><p>We constructed the signals in each of the three sets to have a pure uncorrelated noise, a weak time-correlated signal, and a strong correlated signal (α = 0.0, 0.25, and 0.5, respectively). <ref type="figure" target="#fig_1">Figure 2</ref> shows two synthetic light curves for α = 0.25 and 0.5. Note that our designations of "weak" and "strong" are, to some extent, arbitrary. We selected these limits based on our experience and tests: for α 0.20, the time-correlated signal becomes negligible compared to the uncorrelated-noise signal, whereas values of α ∼ 0.5 are on the level of what we have observed in some cases (e.g., WASP-8b, <ref type="bibr" target="#b11">Cubillos et al. 2013</ref>).</p><p>For each realization, we compute the parameter posteriors using the methods described in Section 3, excluding residual permutation, which we deem to be unsound. Our modelfitting routines only fix the eclipse ingress/egress-time parameter (usually poorly-constrained by eclipse data), leaving free the system flux, eclipse depth, eclipse midpoint, eclipse duration, and ramp slope. First, we carry out a "white analysis" (i.e., ignoring the time-correlation between data points) by using Equation (3) to compute the model-parameter bestfitting values (using the Levenberg-Marquardt algorithm) and their posterior distributions (using a MCMC).</p><p>Next, we use the best-fit results to calculate the timeaveraging rms-vs.-bin size curves. We retrieve the β factor at three timescales: at the ingress time, at the eclipse duration, and at the time of maximum β (β max , <ref type="figure" target="#fig_2">Figure 3)</ref>. In accordance with the discussion in Section 3.2.1, most β values at the eclipse-duration timescale (similar to the total observation duration) were not significant. Thus, we adopted β max as the scaling factor to calculate the time-averaging method uncertainties. Finally, we apply the wavelet-based likelihood method in an MCMC guided by Equation (12), simultaneously fitting the noise parameters (σ ω and σ r ) and the model parameters, while keeping γ fixed at 1. We find that a noninformative logarithmic prior on σ r handle the case with no correlated noise better than a flat prior. A log-flat prior is a scale-invariant prior that has an equal probability per order of magnitude. This is a more convenient prior when the parameter may range over several orders of magnitude (Gre- gory 2005). The only requirement is that the parameter value must be positive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.1.">Results</head><p>To assess the quality of the inferences from the time averaging and wavelet likelihood methods, we performed calibration tests, i.e., tests of the repeated-sampling (frequentist) performance of the inferences, when applied across an ensemble of simulated datasets.</p><p>The first test computes a measure of the relative accuracy of the eclipse depth estimates (i.e., accuracy relative to the reported uncertainty), also known as "number-of-sigma" statistic as described by <ref type="bibr" target="#b7">Carter &amp; Winn (2009)</ref>. The simulated datasets are large enough that the marginal posterior PDFs for the eclipse depth are typically nearly normal. This motivates measuring relative accuracy by the number of posterior standard deviations between the best-fit value and the true value used for a simulation,</p><formula xml:id="formula_11">N p = ˆ p − p σ p ,<label>(13)</label></formula><p>where p is the true eclipse depth used for the simulation, ˆ p is the best-fit estimate, and σ p is the standard deviation of the marginal posterior for p. If the marginal posterior were normal, and if σ p were constant across the simulations, we would expect N p to have normal standard deviation with mean N p zero, and standard deviation σ N unity. In principle, a departure of N p from zero would suggest a lack of accuracy of an analysis, whereas a departure of σ N from unity would suggest an under-or overestimated precision (σ N &gt; 1 or σ N &lt; 1, respectively). In general, however, neither condition rigorously holds; the posteriors are slightly non-normal, and the value of σ p varies a bit. As a result, we do not expect N p to have a standard normal distribution exactly (even for many simulations). Nevertheless, the mean and shape of the N p distribution can reveal significant calibration failures of inferences.</p><p>The second test examines the conditional coverage of marginal credible regions for the eclipse depth. For a set of simulations with parameters θ, we compute C Q (θ), the coverage of marginal credible regions for the eclipse depth that were computed to contain a fraction Q of the posterior probability. That is, we fix a size for the eclipse depth credible region to be tested (say, Q = 0.683 for a conventional "1σ" region), and we compute the fraction of times the credible region contains the true eclipse depth value.</p><p>Some caution is required in interpreting results of conditional coverage tests. Bayesian credible regions will not in general be perfectly calibrated for fixed θ. Rather, Bayesian methods produce regions with exact average coverage, i.e., with C Q (θ) = Q if one averages over the prior. The bottom line of these considerations is that, for a set of simulations with a fixed set of true parameter values, we do not expect C Q (θ) to equal Q exactly. But large departures from Q likely indicate problems with an inference procedure. It is possible, at least in principle, to more thoroughly verify calibration of Bayesian MCMC algorithms (e.g., to average over θ, or to consider all possible sizes of credible regions; see <ref type="bibr" target="#b9">Cook et al. 2006</ref>), but we focus on simpler conditional tests here. For the coverage calculations reported below, we used the 68.3% marginal highest posterior density credible region. <ref type="figure" target="#fig_4">Figure 4</ref> shows the N p distributions for each method and dataset. <ref type="table" target="#tab_1">Table 2</ref> shows the mean and standard deviation of N p and coverage fraction C Q=0.68 (i.e., the fraction of trials where the 68% HPD covers the true depth value). The white analysis of the uncorrelated-noise set serves as a control sample. As expected, the N p distribution for this case shows a negligible deviation from zero, a standard deviation close to one, and a 68%-HPD coverage fraction of ∼68%. The correlated-noise runs reveal the failure of the white analysis to account for correlated noise; as the correlated-noise component increases, the mean and standard deviation of N p increase (suggesting a decrease of accuracy and underestimated uncertainties), which is well correlated with the lower coverage fraction.</p><p>The time-averaging method seems to improve the precision for the correlated-noise runs with respect to those of the white analysis (less underestimated uncertainties), as shown by the smaller σ N . Accordingly, the coverage fractions closer to 68% indicate an improvement in the parameter estimation. Note that the time-averaging method does not affect the accuracy (with respect to the white analysis). Since all the data uncertainties are inflated by a common scaling factor, the best-fitting solution does not change. Therefore, the variation in N p is a consequence of the variation in the precision and any possible underlying correlation between precision and accuracy for the sample.  The wavelet method also seems to improve the parameter estimation of the correlated samples with respect to the white analysis. However, this time the method seems to overestimate the uncertainties, as shown by the coverage fractions greater than 68% and the values of σ N smaller than one. The values of N p lie at the same level as those of the white analysis.</p><p>Overall, both the time-averaging and wavelet methods improve the eclipse-depth estimation over a white analysis. For a sample size of 3000 trials, the coverage uncertainty is roughly 2% (from a root-N estimate). Since we carried out only a conditional study, there is an additional error budget to consider. Only a substantial mismatch between coverage and credible region size would be evidence that there is a problem. The results of the wavelet analysis may be evidence of a real coverage mismatch, but it is not at a level that would be surprising for conditional vs. average coverage. If real, this emphasizes the challenges of retrieving reliable parameter estimates from light curves affected by correlated noise, considering that we generated the synthetic signal with wavelet function.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Synthetic-noise for Long-duration Simulation</head><p>Here we describe tests of the time-averaging method for datasets long enough such that the eclipse duration lies at timescales where the asymptotic approximation is still valid. To do so, we replicate the previous simulation (synthetic transit, white noise, and 1/f noise signals) for an observation last-  ing ∼ 20 times the eclipse duration (akin to a phase-curve observation). We generate the light curve with the same eclipse configuration and system flux as in Section 4.2, keeping the cadence (17,000 data points total) and the value of σ ω at 64.5 counts. To conserve the noise rms ratios at α = 0.25 and 0.5, we set σ r = 774 and 1549 counts, respectively. In this case, we find that the time-averaging β scaling factors accurately inflate the data uncertainties to account for the time-correlated noise <ref type="figure" target="#fig_5">(Fig. 5)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Simulation with Spitzer-IRAC Noise</head><p>In this section we describe tests of the correlated-noise estimators for real exoplanet signals from the Spitzer IRAC instrument, which is more compelling than the previous test with synthetic data. We select two published phase-curve observations that are affected by correlated noise, a 4.5 µm HD 209458 b ( <ref type="bibr" target="#b52">Zellem et al. 2014</ref>) and a 3.6 µm WASP-14 b ( <ref type="bibr" target="#b47">Wong et al. 2015</ref>) dataset. The strength of the correlated noise in these two datasets is markedly different. The WASP-14 b not only presents higher levels of correlated noise (as reported by the time-averaging curves), but also presents sporadic short-duration flux anomalies (dips) along the observation. Thus, these two datasets allow us to test the correlated-noise estimators under true instrumental noise as detected by the telescope, under two different correlated-noise regimes. We specifically selected phase-curve observations to remove the astrophysical signals and trace the telescope systematics to the best of our knowledge.</p><p>We processed the Spitzer BCD data to obtain raw light curves using the Photometry for Orbits, Eclipses, and Transits (POET) pipeline <ref type="bibr" target="#b42">(Stevenson et al. 2010</ref><ref type="bibr" target="#b43">, 2012a</ref><ref type="bibr">,b, Campo et al. 2011</ref><ref type="bibr" target="#b36">, Nymeyer et al. 2011</ref><ref type="bibr" target="#b11">, Cubillos et al. 2013</ref>). The POET pipeline involves bad-pixel masking (sigma rejection), 2-dimensional Gaussian fitting to determine the target location, and interpolated aperture photometry to obtain raw light curves (for details see, e.g., <ref type="bibr" target="#b10">Cubillos et al. 2014</ref>). We remove the first couple hours of observation to avoid the time-dependent systematic.</p><p>We model the light curves using <ref type="bibr" target="#b33">Mandel &amp; Agol (2002)</ref> eclipse and transit models, a BLISS map model (to account for the intrapixel effect, <ref type="bibr" target="#b43">Stevenson et al. 2012a</ref>), and and a sinusoidal function (for the phase-curve variation, following <ref type="bibr" target="#b52">Zellem et al. 2014</ref>):</p><formula xml:id="formula_12">F (t) = 1 + c 0 + c 1 cos(2πt) + c 2 sin(2πt),<label>(14)</label></formula><p>where c 0 , c 1 , and c 2 are the model fitting parameters, and t is the time of the observation (measured in orbital phase). To avoid degeneracy with the other fitting parameters, we constrain c 0 by requiring F (t 0 ) = 1, with t 0 the eclipse midpoint time. We finally remove all astrophysical variations from the signal by dividing out the sinusoidal model and trimming the HD 209458 b phase curves to the span between the eclipse and transit (38.9 h long) and the WASP-14 b phase curve between the transit and eclipse (22.6 h long). The resulting light curves consist of flat curves containing only the intrapixel systematic variation and noise. These curves are our baseline to create the synthetic transit observations. To construct the trial samples, we inject an eclipse curve at random uniformly distributed times into the baseline, generating 3000 realizations for each dataset. We adopt eclipse parameters (duration, depth, ingress, and egress) similar to the observed values for each dataset ( <ref type="bibr" target="#b52">Zellem et al. 2014</ref><ref type="bibr" target="#b47">, Wong et al. 2015</ref>.</p><p>We analyze the data and outputs in the same manner as in Section 4.1.1. Our fitting model includes an eclipse and a BLISS-map model. In practical terms, we found that many times the MCMC for the wavelet method failed to converge or failed to fit well the entire light curve. This may be result of the wavelet noise model attempting to overfit the transit curve, or because the wavelet cannot appropriately model correlated-noise structure. Thus, for this analysis we trim the dataset to a window of 2.5 times the eclipse duration, centered at the input midpoint. <ref type="figure" target="#fig_6">Figure 6</ref> shows the resulting N p histograms for each method and dataset. The N p histograms for the WASP-14 b dataset are noticeably more irregular (non-Gaussian) than the histograms for the HD 2019458 b dataset. This may be result of the stronger correlated-noise systematics. This clearly complicates the interpretation of the N p statistics. Thus, we rely mostly on the coverage-fraction statistic, which is not affected by these nuances. The color code denotes the parameter-estimation method (see legend). The background gray contour denotes a standard normal distribution for comparison. All histograms are normalized such that the integral of each curve adds to one.  <ref type="table" target="#tab_2">Table 3</ref> presents the N p statistic and coverage-fraction results. Again, in both cases, both the time-averaging and wavelet methods improve the parameter estimation with respect to the white analysis (coverage fractions closer to 68%). However, none of the analyses completely correct the eclipse depth estimation. The low values of the coverage fractions hint towards an underestimation of the uncertainties, a lack of accuracy, or a combination of both. The irregular shape of the N p histograms, particularly for the WASP-14 b dataset, suggests that there are correlations between the accuracy and precision for the trials, which would be expected given the stronger correlated-noise component in the data. . Unlike other exoplanet model-fitting tools that are tailored to specific tasks, MC 3 allows the user to define the modeling function and, thus, it is a general-purpose statistical package. We developed the main bulk of the code in Python, with several extensions written in C, combining simplicity and high performance. The code runs in multiple parallel processors (through the built-in multiprocessing Python package). MC 3 provides statistically-robust model optimization (via Levenberg-Marquardt minimization) and credible-region estimation (via MCMC sampling) routines. The MCMC random sampling is done via the Metropolis Random Walk (MRW, using multivariate Gaussian proposals), the Differential-Evolution Markov-chain Monte Carlo <ref type="bibr">(DEMC, ter Braak 2006</ref>), or the Snooker-updater DEMC algorithms <ref type="bibr" target="#b45">(ter Braak &amp; Vrugt 2008)</ref>. While the proposal step sizes of the MRW are predetermined by the user and have to be manually adjusted before each run, the DEMC algorithms automatically adjust the scale and orientation of the proposal distribution. To do so, DEMC runs several chains in parallel, computing the proposed jump for a given chain from the difference between the parameter states of two other randomly selected chains. As the chains converge toward the posterior distribution, the proposal jumps will be mainly oriented along the desired distribution and will have adequate scales. Therefore, DEMC improves the MCMC efficiency in two ways: (1) it increases the acceptance rate to optimal levels ( 25%, <ref type="bibr" target="#b38">Roberts et al. 1997</ref>) by better sampling the parameter space, and (2) it eliminates the heuristic need for the user to adjust the proposal jump scales.</p><p>The Metropolis-Hastings acceptance rule implements both the ordinary likelihood function (Eq. 3) and the waveletbased likelihood (Eq. 12) using the fourth-order Daubechies wavelet. The priors can be bounded or unbounded uniform, log-scale uniform, or Gaussian. To assess that the MCMC is working properly, the code performs a chain-converge test using the <ref type="bibr" target="#b19">Gelman &amp; Rubin (1992)</ref> statistics. The code also produces several plots to help visualize the results: trace, rms-vs.-bin-size, marginal-posterior, and pairwise-posterior plots can indicate non-convergence, multi-modal posteriors, parameter correlations, correlated noise, or incorrect priors. At the end of the MCMC run the code returns the sampled posterior distribution of the parameters, their best-fitting values, their 68% HPD credible region, and the acceptance rate of the MCMC. The majority of the routines of this module derive from our POET pipeline and, thus, have been thoroughly tested for years.</p><p>The core structure of MC 3 consists of a central hub, which drives the MCMC exploration, and the workers, which evaluate the model for the given free parameters. The hub and the worker processes are connected through shared memory. MC 3 assigns one CPU to each worker (i.e., one for each chain). Each cycle (iteration) of the MCMC comprises the following steps: (1) generate the proposal state (the set of free parameters) for each chain, (2) evaluate the model for the proposed state, and (3) compute the Metropolis ratio and accept/reject the proposal state for each chain.</p><p>The MC 3 code runs from both the shell prompt and the Python interactive interpreter, and is available for Python 2.7 and Python 3. The user can configure the MCMC run either through a configuration file, command line arguments (prompt), and/or function arguments (Python interpreter). The minimum required inputs are the modeling function, the data being fitted, and starting estimate values for the free parameters. As optional arguments, the user can supply the data uncertainties, priors, and any extra arguments of the modeling function (in a manner much like the scipy.optimize.leastq routine). Additionally, the package allows the user to configure multiple features of the MCMC, e.g.: number of chains, number of iterations, burnin length, thinning factor, etc. The repository of the code includes a user manual and guided examples.</p><p>6. CONCLUSIONS Time-correlated noise is an important source of uncertainty for faint signals such as exoplanet light curves. Unless all systematics of the data are well understood, the correlated noise must be taken into account to obtain a reliable parameter estimation. We have reviewed three of the most widely used methods to assess time-correlated noise in exoplanet time-series data: time averaging, residual permutation, and wavelet-based likelihood, expanding the limited literature of tests to assess the quantitative results of these techniques. We focused specifically on the case of Spitzer secondary-eclipse time-series data.</p><p>We characterized the behavior of the time-averaging β correction factor at large bin sizes (the typical case for a transit observation). In this regime the assumed uncertainty of the rms curve is no longer valid, since the posterior adopts the form of a skewed inverse-gamma distribution. We also found the residual-permutation method unsound as a tool for quantifying uncertainty in parameter estimates, because it does not produce ensembles that mimic the behavior of independent draws from a probability distribution. The method is not supported by a consistent statistical basis. Finally, for the wavelet-likelihood method we detected and corrected errors in the published equations <ref type="bibr" target="#b7">Carter &amp; Winn (2009)</ref> and code <ref type="bibr">(Appendix D)</ref>.</p><p>To quantitatively test the performance of these methods, we carried out injection-retrieval simulations on synthetic eclipse light curves, creating a large number of trials for each simulation. We analyzed the results by (1) comparing the expectation and standard deviation of the relative accuracy against a normal distribution (following <ref type="bibr" target="#b7">Carter &amp; Winn 2009)</ref> and <ref type="formula" target="#formula_1">(2)</ref> computing the 68% coverage fraction (the fraction of trials where the 68% credible region contained the injected parameter). A correct Bayesian calculation would guarantee matching of the credible region probability and the average coverage (over the parameter space). Note that our simulations used a single true parameter value. A precise test of average coverage would require a substantial amount of computing time. Thus, our conditional coverage tests would indicate a problem with a method only if the coverage differed substantially from the credible level.</p><p>In our first simulation, we tested the case when the timecorrelated noise has a power spectral density of the form 1/f . Both the time-averaging and the wavelet-likelihood methods improved the eclipse-depth estimations over a white MCMC analysis. In this simulation the wavelet analysis is expected to perform well, since the wavelet precisely assumes a noise component with a 1/f power spectral density. We found small differences between the estimated conditional coverage and the credible levels. These diffrences are consistent with expectations, given both the limited precision from the size of the simulations, and the conditional nature of the tests. We also note that the performance of the time-averaging correction can be further improved if the total observation time is much longer than the eclipse duration (as in a phase-curve observation). This arises from the lower signal to noise of the rms N curve at large bin sizes.</p><p>In a further simulation we generated eclipse light-curve samples by injecting an eclipse signal into real Spitzer 3.6 µm and 4.5 µm IRAC time-series datasets, two sets with notoriously different correlated-noise signals. This experiment allowed us to assess the performance of the timecorrelated estimators without assuming a specific shape of the time-correlated signal. Both the time-averaging and the wavelet-likelihood methods significantly improved the uncertainty estimations compared to a white MCMC analysis, raising the coverage fraction from 15%-20% to ∼45-65%. However, they are not perfect, as the coverage fractions are still lower than the expected 68%, suggesting a lack of accuracy and (or) underestimated uncertainties.</p><p>In conclusion, it is always better to try to determine the best possible model for the systematics than simply inflating the parameter uncertainties (as in time averaging). However, these sub-optimal noise estimators are better than ignoring time-correlated noise. Luckily, the continuous development of advanced data analysis techniques like Gaussian Processes, Independent Component Analysis, or kernel regression decorrelation (see e.g., <ref type="bibr" target="#b26">Ingalls et al. 2016</ref>) will help to improve the best practices required to extract exoplanet data.</p><p>Lastly, we presented the open-source Python package Multi-Core Markov-Chain Monte Carlo, available at https://github.com/pcubillos/MCcubed. MC 3 implements all of the statistical routines described in this paper, allowing the user to estimate best-fitting model parameters and their credible region, while letting the user provide the modeling function. By releasing our code to the community, we hope not only to provide access to the routines discussed here, but also to encourage researchers to consider open development and cross-validation of the software tools used in the field.</p><p>We thank Rebekah Dawson for useful conversations. We thank the referee for comments that significantly improved the quality of the paper. We thank contributors to AstroPy <ref type="bibr">(Astropy Collaboration et al. 2013</ref> In the Bayesian context, given the posterior probability density, p(θ| y), of a parameter, θ, given the dataset, y, the highest posterior density region (or credible region), R, is defined by</p><formula xml:id="formula_13">C = R dθ p(θ| y)<label>(15)</label></formula><p>where C is the probability contained in the credible region. The region R is selected such that the posterior probability of any point inside R is larger than that of any point outside.</p><p>In practice, to calculate the credible region, one constructs a histogram of the sampled posterior distribution (normalized such that the sum equals one) and sorts the bins in descending order. Then one sequentially adds the values of p until reaching C. The credible-region boundaries are given by the smallest and largest values of θ for the samples considered in the sum, if the region is contiguous. B. WLS vs. GLS EXAMPLES To gain insight into the difference between weighted least squares estimates (WLS, those considering Eq. <ref type="formula" target="#formula_2">(3)</ref>) and generalized least squares estimates (GLS, those considering Eq. (4)), we consider examples with a simple correlated noise model: AR(1) autoregressive noise, for regularly sampled data. Our treatment adapts analyses by <ref type="bibr" target="#b53">Zellner (1971)</ref> and <ref type="bibr" target="#b40">Sivia &amp; Skilling (2006)</ref> on related models. In this model, the conditional expectation (regression) of the noise for sample i is proportional to the previous noise value; the actual value of the noise is the sum of this expectation and a new innovation contribution, ν i :</p><formula xml:id="formula_14">ǫ i = φǫ i−1 + ν i ,<label>(16)</label></formula><p>where φ is the autoregression parameter. The innovations are independent, with zero-mean normal PDFs with standard deviation s. The overall model for f (θ) is a hidden Markov model (HMM): "Markov" indicating that the prediction for the noise at time t i depends only on the noise at the previous time, and not on the whole noise history; and "hidden" because ǫ i is not directly observed (as it would be in a standard AR(1) model), rather, y i is observed, mixing uncertain model and noise contributions. The AR(1) model enables recursive construction of the joint distribution for the noise. The model specifies independent normal PDFs for the ν i terms, so the goal is to express the ǫ i values entirely in terms of ν i values. The probability for the first noise sample, ǫ 1 , is slightly complicated by the fact that it depends on innovations at times before there is data. However, ǫ i is a linear sum of terms that are each zero-mean normal, so it must itself have a normal PDF, with variance given by the sum of the variances of its contributions. Writing ǫ i−1 = ν i−1 + φ i−1 , and recursing, we find</p><formula xml:id="formula_15">ǫ 1 = ∞ j=0 φ j ν 1−j .<label>(17)</label></formula><p>The standard deviation of each term is φ j s, so the sum of the variances is</p><formula xml:id="formula_16">σ 2 ǫ = s 2 ∞ j=0 φ 2j = s 2 1 − φ 2 ,<label>(18)</label></formula><p>provided that |φ| &lt; 1. The marginal PDF for ǫ i at any time is a zero-mean normal with this variance; the noise time series is thus stationary (with the same marginal distribution at each time). We can write the joint PDF for all noise values in terms of factors that condition on the previous history:</p><formula xml:id="formula_17">p( ǫ) = p(ǫ 1 ) p(ǫ 2 |ǫ 1 ) p(ǫ 3 |ǫ 1:2 ) · · · p(ǫ n |ǫ 1:n−1 ),<label>(19)</label></formula><p>with ǫ i:j = (ǫ i , . . . , ǫ j ). Given the Markov property of the AR(1) model, the joint PDF simplifies to</p><formula xml:id="formula_18">p( ǫ) = p(ǫ 1 ) n i=2 p(ǫ i |ǫ i−1 ).<label>(20)</label></formula><p>Equation (16) implies that p(ǫ i |ǫ i−1 ) is the probability that ν i = ǫ i − φǫ i−1 . The factors appearing in Eq. <ref type="formula" target="#formula_1">(20)</ref> are thus</p><formula xml:id="formula_19">p(ǫ 1 ) = 1 − φ 2 s √ 2π e −ǫ 2 1 /2s 2<label>(21)</label></formula><p>and</p><formula xml:id="formula_20">p(ǫ i |ǫ i−1 ) = 1 s √ 2π exp − 1 2s 2 (ǫ i − φǫ i−1 ) 2 .<label>(22)</label></formula><p>The observation equation, Eq. (1), indicates that the probability for the data, y, is the probability that the noise values take on the values ǫ i = y i − f i (θ). Let r i (θ) ≡ y i − f i (θ) denote the residuals from adopting the model with parameters θ. Then the PDF for the data can be written </p><formula xml:id="formula_21">p( y|θ) = (1 − φ 2 ) 1/2 s n (2π) n/2 e −Q(θ)/2s 2 ,<label>(23)</label></formula><p>The first term-the sum of squared residuals-is just the "χ 2 " term that appears in WLS (see Eq. <ref type="formula" target="#formula_2">(3)</ref>). When φ = 0, AR(1) noise correlations introduce new contributions to Q(θ), including a term resembling a lag-1 autocorrelation. These terms correspond to changes in the model basis projections entailed by the correlations in a GLS analysis, versus a WLS analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.1. Example: Constant Signal</head><p>The simple case of a constant signal model of unknown amplitude, f (t; µ) = µ, is analytically tractable and is illuminating. Substituting r i = y i − µ and minimizing Q(µ) leads to the GLS estimatê estimatê µ = w n ¯ y + w 2 (y 1 + y n )/2 w n + w 2 ,</p><p>where ¯ y is the sample mean, ¯ y ≡ (1/n) i y i , and we have defined weights w n = n(1 − φ) and w 2 = 2φ. When φ = 0 (independent noise), ˆ µ is just the sample mean. Otherwise, ˆ µ is a weighted average of the full sample mean, and the average of the first and last (i.e., the most widely separated) samples. As φ approaches unity (strongly positively correlated noise), GLS instructs us to just average the most widely separated samples. In contrast, the WLS estimate is always the full sample mean. The WLS and GLS estimates thus will differ, not just in the uncertainties they assign to the mean, but also in the actual values of the estimates.</p><p>Q(µ) is quadratic in µ, so the likelihood function is a Gaussian function in µ. The reciprocal of the second derivative of Q(µ)/s 2 atˆµatˆ atˆµ gives the squared standard deviation of this Gaussian,</p><formula xml:id="formula_24">σ 2 µ = s 2 n(1 − φ) 2 − 2φ(1 − φ) .<label>(26)</label></formula><p>When φ = 0, we have σ µ = s/ √ n, the familiar "root-n" result. As φ approaches unity, the denominator decreases toward zero, and the uncertainty in µ grows. Roughly speaking, growing positive correlation decreases the effective sample size, inflating uncertainties. This motivates approaches like time averaging that attempt to account for correlation merely by inflating uncertainties. But such approaches do not account for the effect of correlations on the actual value of a finite-sample estimate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B.2. Example: Constant Baseline with One Dip</head><p>The effect of correlations on parameter estimates depends on the extent to which the correlations may mimic or distort the projections of the data onto the model components. When a model has components that vary slowly with respect to the correlation scale, the main effect of correlations is to change the effective sample size. But when a model has temporally localized components, correlations can significantly affect, not just the uncertainty scale, but also the best-fit parameter values.</p><p>To illustrate this, we used simulated AR(1) noise and the GLS likelihood function to model data generated from a baseline signal of amplitude a, with a localized dip of depth δ. We took the dip location and width to be known. For the illustration we report here, we simulated 51 observations with true parameter values θ = (a, δ) = (0, 2), with the dip spanning 10 samples in the middle of the time series. The noise was generated with an innovation standard deviation s = 1, and φ = 0.8, producing data with autocorrelation time scales ∼ 5. <ref type="figure" target="#fig_9">Figure 7</ref> displays examples of the simulated data and WLS and GLS best-fit function estimates. It is visually apparent that the WLS and GLS estimates sometimes differ. <ref type="figure">Figure 8</ref> shows contours of the posterior PDFs for (a, δ) from a representative simulation where the WLS and GLS estimates differ; here the WLS best-fit estimate is just outside of the 98% GLS credible region. Even when the WLS and GLS best-fit estimates did not differ too dramatically in, if δ is the standard deviation for σ, in the normal approximation, that matches the curvature at the peak, we have δ 2 ≈ −f (ˆ σ)/f ′′ (ˆ σ). Evaluating Equation (35) atˆσatˆ atˆσ, the first term vanishes (since f ′ (ˆ σ) = 0), and the remaining term gives an approximate standard deviation of:</p><formula xml:id="formula_25">δ ≈ r M √ 2 = s √ 2M .<label>(36)</label></formula><p>So, the mean and standard deviation sum for σ for large M is:</p><formula xml:id="formula_26">σ = s ± s √ 2M .<label>(37)</label></formula><p>D. WAVELET-LIKELIHOOD ERRATA This section reports three erratas found both in the published article of <ref type="bibr" target="#b7">Carter &amp; Winn (2009)</ref> and its associated ASCL code.</p><p>First, in the Likelihood equation, Eqs. <ref type="formula" target="#formula_1">(32)</ref> and <ref type="formula" target="#formula_0">(41)</ref> of <ref type="bibr" target="#b7">Carter &amp; Winn (2009)</ref>, the index for the scale, m, should start from 1 instead of 2. In this case the ASCL code has the correct value.</p><p>Next, the variance of the scaling coefficient in the ASCL code for γ = 1, equation <ref type="formula" target="#formula_2">(34)</ref> of the paper, is missing the factor 2 −γ = 2 −1 . The corrected equation should read:</p><formula xml:id="formula_27">σ 2 S = σ 2 r 4 ln 2 + σ 2 ω .<label>(38)</label></formula><p>The expression for the scaling coefficient for γ = 1 also seems to be wrong in the ASCL code. We can compute the variance of the wavelet coefficients following equation <ref type="formula" target="#formula_2">(37)</ref> of <ref type="bibr" target="#b50">Wornell (1993)</ref>:</p><formula xml:id="formula_28">ǫ m n ǫ m n = 2 −m 2π ∞ −∞ σ 2 x |ω| γ |Ψ(2 −m ω)| 2 dω.<label>(39)</label></formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Binned residuals rms vs. bin size (black curve with gray error bars) of WASP-8b Spitzer eclipse at 3.6 µm (PI J. Harrington, Program ID 60003, see Cubillos et al. 2013). The red curve corresponds to the expected rms for white noise (Equation 8). The sawtooth look of the curve arises from the discreet change in M , which becomes more significant as N increases. The vertical dashed lines mark the duration of ingress/egress (left) and eclipse (right). The gray vertical error bars denote the 1σ uncertainty of the rms residuals (rmsN / √ 2M ).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Simulated Spitzer time-series datasets. The top panels overplot the correlated (black) and uncorrelated (grey) noise components of the light curves vs. orbital phase. The bottom panels show the synthetic light curves (eclipse, ramp, and noise) vs. orbital phase in gray. The black solid line shows the noiseless model. The noise rms ratios are α = 0.25 (left panels) and α = 0.5 (right panels).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Top: Normalized distribution of β for the α = 0.25 set. The histograms represent β measured at the ingress-time and eclipse-duration timescales, and at the maximum value of β. The vertical dashed line marks β = 1. The colored shaded areas denote the corresponding fraction of trials that were more than 1σ β greater than one. The distributions for the other two sets (α = 0 and 0.5) were similar. Bottom: Normalized distribution of the bin sizes for βmax. The vertical dashed lines indicate the ingress time and eclipse duration.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Eclipse-depth histogram of the relative-accuracy statistic for synthetic-data simulations. The top, middle, and bottom panels show the results for the white-MCMC, wavelet-likelihood, and time-averaging methods, respectively. The color code denotes the sample (see legend). The background gray contour denotes a standard normal distribution for comparison. All histograms are normalized such that the integral of each curve adds to one.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Time-averaging eclipse-depth histogram of the relativeaccuracy statistic for the long-duration (20 times the eclipse duration) synthetic-data simulations. The color code denotes the sample (see legend). The background gray contour denotes a standard normal distribution for comparison. All histograms are normalized such that the integral of each curve adds to one.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Eclipse-depth histogram of the relative-accuracy statistic for real-noise simulations. The top and bottom panels show the results for the HD 209458 b and WASP-14 b datasets, respectively. The color code denotes the parameter-estimation method (see legend). The background gray contour denotes a standard normal distribution for comparison. All histograms are normalized such that the integral of each curve adds to one.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>5 .</head><label>5</label><figDesc>MULTI-CORE MARKOV-CHAIN MONTE CARLO (MC 3 ) CODE We implemented and made available all of the dis- cussed statistical methods into the open-source Python package Multi-Core Markov-Chain Monte Carlo (MC 3 , https://github.com/pcubillos/MCcubed)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. Eight sampled time series from the baseline-dip model with AR(1) noise. Curves of matching color connect the simulated data (solid), the GLS best-fit points (dashed), and the WLS best-fit points (dotted). The solid black curve shows the true (noiseless) function.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0" validated="true"><head>Table 1 . Synthetic light curve parameters</head><label>1</label><figDesc></figDesc><table>Parameter 
Value 
Eclipse depth (counts) 
98.1 
Eclipse duration (phase) 
0.1119 
Eclipse mid point (phase) 
0.5015 
Eclipse ingress/egress time (phase) 
0.013 
Ramp slope (counts/phase) 
0.006 
System flux (counts) 
25815 
σω (counts) 
64.5 
σr (counts) 
0, 230, and 459 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1" validated="false"><head>Table 2 . Relative-accuracy Statistics and Coverage Fraction for Synthetic-data Simulations</head><label>2</label><figDesc></figDesc><table>Estimation method 
Np 
σN 
C0.68 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2" validated="false"><head>Table 3 .</head><label>3</label><figDesc></figDesc><table>Relative-accuracy Statistics and Coverage Fraction for 
Real-noise Simulations 

Estimation method 
Np 
σN 
C0.68 

4.5 µm HD 209458 b 
White MCMC 
0.726 
2.772 
0.20 
Time Averaging 
0.444 
1.553 
0.46 
Wavelet 
0.428 
1.176 
0.54 
3.6 µm WASP-14 b 
White MCMC 
0.720 
5.901 
0.15 
Time Averaging 
0.202 
1.682 
0.64 
Wavelet 
1.286 
1.766 
0.54 

</table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3" validated="false"><head></head><label></label><figDesc>), SciPy, Matplotlib (Hunter 2007), the Python Programming Language, and the free and open-source community. PC was partly supported by the Fulbright Program for Foreign Students. JB was partly supported by the NASA Earth and Space Science Fellowship Program, grant NNX12AL83H. Part of this work is based on observations made with the Spitzer Space Telescope, which is operated by the Jet Propulsion Laboratory, Cali- fornia Institute of Technology under a contract with NASA. Support for this work was provided by NASA through an award issued by JPL/Caltech and through the NASA Sci- ence Mission Directorate's Astrophysics Data Analysis Pro- gram, grant NNX13AF38G, and its Planetary Atmospheres Program, grant NNX12AI69G.</figDesc><table>Facility: Spitzer(IRAC) 
Software: MC 3 (https://github.com/pcubillos/MCcubed), 

Python A. BAYESIAN CREDIBLE REGION 
</table></figure>

			<note place="foot" n="1"> http://asterisk.apod.com/viewtopic.php?f=35&amp;t=21675</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 8.</head><p>Contours of the posterior PDF for (a, δ), from GLS (larger, thicker contours) and WLS (smaller, thinner contours) analyses. From inside to outside, the contours bound highest posterior density regions with 50%, 75%, 90%, 95%, and 99% of the posterior probability. Dots indicate the modes. Crosshairs indicate the true parameter values.</p><p>the WLS likelihood function not only has an incorrect uncertainty scale (which one might hope to fix via inflation), but does not correctly capture the shape of the PDF (i.e., the correlation between a and δ estimates).</p><p>The main message of these examples is that noise correlation not only can inflate uncertainties; it can also corrupt parameter estimates, particularly when parameters of interest pertain to temporally localized structure in the model, for which noise correlations can significantly change the data projections needed for accurate inference. Methods that seek to account for correlations only by inflating parameter uncertainties are at best suboptimal (producing larger estimation errors than could be achieved with a good correlated noise model), and can sometimes be significantly misleading.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C. STANDARD-DEVIATION UNCERTAINTY</head><p>The uncertainty of a parameter estimate in a problem with a fixed model dimension (number of parameters) and growing sample size typically decreases asymptotically at the √ M rate. That is, for estimating a Gaussian mean from M samples with the standard deviation σ, which is known, the uncertainty is σ/ √ M . However, this result says nothing about the actual size of the uncertainty at any particular sample size. When σ is unknown, it becomes the target of estimation, instead of (or in addition to) the mean. Here, we elaborate on the derivation of the uncertainty for the standard deviation of a Gaussian. The derivation uses the Laplace approximation for a normal standard deviation and its uncertainty, i.e., it finds a Gaussian distribution with a peak and curvature matching the marginal probability density function.</p><p>Given a normal distribution of values with unknown mean µ and standard deviation σ, let b i be the means for a sample of M groups of samples ("bins") drawn from this distribution. The sample mean, ¯ b, and the sample variance, s 2 , are defined as usual:</p><p>If the residual r i = b i − ¯ b and r 2 = i r 2 i , then the sample variance becomes s 2 = r 2 /M .</p><p>The likelihood function for our normal distribution with (µ, σ) is:</p><p>so the likelihood can be written is terms of ¯ b and r as:</p><p>To estimate µ and σ, we will adopt a flat prior for µ and a log-flat prior for σ, corresponding to p(σ) ∝ 1/σ. Then, the joint posterior probability p(µ, σ|D) for µ and σ, given the data D is:</p><p>with p(σ) the prior probability on σ.</p><p>Calculate the marginal posterior density for σ by integrating over µ:</p><p>The µ dependence is in the last exponential factor, a Gaussian that integrates to σ √ 2π. We denote the result as f (σ):</p><p>We estimate σ with its mode, ˆ σ, which maximizes f (σ). The first derivative of f (σ) is:</p><p>so that setting f ′ (ˆ σ) = 0 givesˆσgivesˆ givesˆσ = r/ √ M = s, as one might expect.</p><p>For a simple estimate of the uncertainty, let's consider a Gaussian approximation with mean atˆσatˆ atˆσ. The curvature (second derivative) of σ atˆσatˆ atˆσ:</p><p>determines the standard deviation. When f (x) is of the form of a normal distribution with mean m and standard deviation w, it is easy to show that f ′′ (m) = −f (m)/w 2 . So, Assuming an ideal bandpass -i.e., eq. (3) of Wornell (1993)-and with a change of variable, u = 2 −m ω, we reproduce eq. <ref type="formula">(24)</ref> of <ref type="bibr" target="#b7">Carter &amp; Winn (2009)</ref>:</p><p>Analogously, the variance for the scaling coefficient assuming an ideal bandpass -i.e., eq. <ref type="formula">(10)</ref> of Wornell (1993):</p><p>. <ref type="formula">(45)</ref> This indicates that g(γ) = 1/(2 1−γ − 1) for γ = 1, the inverse of the value given in the ASCL code from <ref type="bibr" target="#b7">Carter &amp; Winn (2009)</ref>. The same result can be derived from equations <ref type="formula">(16)</ref> and <ref type="formula">(17)</ref> of <ref type="bibr" target="#b18">Fadili &amp; Bullmore (2002)</ref>. These derivations of ǫ m n ǫ m n and ¯ ǫ m n ¯ ǫ m n are not valid for γ = 1; in fact, Eq. (45) diverges to +∞ from the left and to −∞ from the right as we approach γ = 1. Then, how can one get to g(γ = 1) = 1/2 ln 2?.</p><p>Lastly, Section 4.1 of <ref type="bibr" target="#b7">Carter &amp; Winn (2009)</ref> mentions that they used a dataset of 1024 elements, and that their DWT produced 1023 wavelet coefficients and 1 scaling coefficient (implying N 0 = 1). This is inconsistent with the wavelet used (a fourth-order Daubechies wavelet), for which N 0 = 2. This wavelet's DWT returns 2 scaling coefficients and 1022 wavelet coefficients (for the given dataset). The ASCL code is also suited to perform a likelihood calculation assuming N 0 = 1, resulting in each likelihood term having an m value offset by 1.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">B</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Knutson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Deming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Steffen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Henry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Charbonneau</surname></persName>
		</author>
		<idno>1007.4378</idno>
	</analytic>
	<monogr>
		<title level="j">ApJ</title>
		<imprint>
			<biblScope unit="volume">721</biblScope>
			<biblScope unit="page">1861</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<orgName type="collaboration">Astropy Collaboration</orgName>
		</author>
		<idno>1307.6212</idno>
	</analytic>
	<monogr>
		<title level="j">A&amp;A</title>
		<imprint>
			<biblScope unit="volume">558</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ballard</surname></persName>
		</author>
		<idno>1009.0755</idno>
	</analytic>
	<monogr>
		<title level="j">PASP</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<date type="published" when="1341" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Beran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kulik</surname></persName>
		</author>
		<idno>978-3-642-35511-0; 978-3-642-35512-7</idno>
		<title level="m">Long-memory processes</title>
		<meeting><address><addrLine>Heidelberg), xviii+884, ISBN</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Blecic</surname></persName>
		</author>
		<idno>1111.2363</idno>
	</analytic>
	<monogr>
		<title level="j">ApJ</title>
		<imprint>
			<biblScope unit="volume">779</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bouchy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Melo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">C</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mayor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Queloz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Udry</surname></persName>
		</author>
		<idno type="arXiv">arXiv:astro-ph/0410346</idno>
	</analytic>
	<monogr>
		<title level="j">A&amp;A</title>
		<imprint>
			<biblScope unit="volume">431</biblScope>
			<date type="published" when="1105" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Campo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1003.2763</idno>
	</analytic>
	<monogr>
		<title level="j">ApJ</title>
		<imprint>
			<biblScope unit="volume">727</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Carter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Winn</surname></persName>
		</author>
		<idno>0909.0747</idno>
	</analytic>
	<monogr>
		<title level="j">ApJ</title>
		<imprint>
			<biblScope unit="volume">704</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Charbonneau</surname></persName>
		</author>
		<idno type="arXiv">arXiv:astro-ph/0503457</idno>
	</analytic>
	<monogr>
		<title level="j">ApJ</title>
		<imprint>
			<biblScope unit="volume">626</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Computational and Graphical Statistics</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">675</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cubillos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Harrington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Madhusudhan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S D</forename><surname>Foster</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">B</forename><surname>Lust</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Hardy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">O</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ApJ</title>
		<imprint>
			<biblScope unit="volume">797</biblScope>
			<biblScope unit="page">3093</biblScope>
			<date type="published" when="1411" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cubillos</surname></persName>
		</author>
		<idno>1303.5468</idno>
	</analytic>
	<monogr>
		<title level="j">ApJ</title>
		<imprint>
			<biblScope unit="volume">768</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Daubechies</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Communications on Pure and Applied Mathematics</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page">909</biblScope>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">V</forename><surname>Hinkley</surname></persName>
		</author>
		<idno>x+582, ISBN: 0-521-57391-2</idno>
	</analytic>
	<monogr>
		<title level="m">Bootstrap methods and their application</title>
		<meeting><address><addrLine>Cambridge</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1997" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>with 1 IBM-PC floppy disk (3.5 inch; HD)</note>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Deming</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>In prep</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B.-O</forename><surname>Demory</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Seager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Benneke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Deming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Jackson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ApJL</title>
		<imprint>
			<biblScope unit="volume">751</biblScope>
			<biblScope unit="page" from="1205" to="1766" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Deriche</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tewfik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trans. Sig. Proc</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page">2977</biblScope>
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Aigrain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Barstow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Amundsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tremblin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mourier</surname></persName>
		</author>
		<idno>1504.05942</idno>
	</analytic>
	<monogr>
		<title level="j">MNRAS</title>
		<imprint>
			<biblScope unit="volume">451</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Fadili</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bullmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">217</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Fazio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">154</biblScope>
			<biblScope unit="page">457</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
	<note>ApJS</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">P</forename><surname>Gibson</surname></persName>
		</author>
		<idno>1409.5668</idno>
	</analytic>
	<monogr>
		<title level="j">MNRAS</title>
		<imprint>
			<biblScope unit="volume">445</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">P</forename><surname>Gibson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Aigrain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Osborne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pont</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MNRAS</title>
		<imprint>
			<biblScope unit="page">3251</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>419, 2683, ADS, 1109</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gillon</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0707.2261</idno>
	</analytic>
	<monogr>
		<title level="j">A&amp;A</title>
		<imprint>
			<biblScope unit="volume">471</biblScope>
			<biblScope unit="page">51</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Bayesian Logical Data Analysis for the Physical Sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Gregory</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Cambridge University Press</publisher>
			<biblScope unit="page">52184150</biblScope>
			<pubPlace>New York, NY, USA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Harrington</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Luszcz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Seager</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Deming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Richardson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">447</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Hunter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computing In Science &amp; Engineering</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">90</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G</forename><surname>Ingalls</surname></persName>
		</author>
		<idno>1601.05101</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Jenkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Caldwell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Borucki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ads Jordán</surname></persName>
		</author>
		<idno>1310.6048</idno>
	</analytic>
	<monogr>
		<title level="j">ApJ</title>
		<imprint>
			<biblScope unit="volume">564</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>ApJ</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Knutson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Charbonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Burrows</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Megeath</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0709.3984</idno>
	</analytic>
	<monogr>
		<title level="j">ApJ</title>
		<imprint>
			<biblScope unit="volume">673</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">A</forename><surname>Knutson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Charbonneau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">B</forename><surname>Cowan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Fortney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Showman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Henry</surname></persName>
		</author>
		<idno type="arXiv">arXiv:0908.1977</idno>
	</analytic>
	<monogr>
		<title level="j">ApJ</title>
		<imprint>
			<biblScope unit="volume">703</biblScope>
			<biblScope unit="page">769</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Resampling methods for dependent data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Lahiri</surname></persName>
		</author>
		<idno>xiv+374, ISBN: 0-387-00928-0</idno>
	</analytic>
	<monogr>
		<title level="j">Springer Series in Statistics</title>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename><surname>Lewis</surname></persName>
		</author>
		<idno>1302.5084</idno>
	</analytic>
	<monogr>
		<title level="j">ApJ</title>
		<imprint>
			<biblScope unit="volume">766</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">A Wavelet Tour of Signal Processing, Third Edition: The Sparse Way</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mallat</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Academic Press</publisher>
			<biblScope unit="page">9780123743701</biblScope>
		</imprint>
	</monogr>
	<note>3rd edn.</note>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mandel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Agol</surname></persName>
		</author>
		<idno type="arXiv">arXiv:astro-ph/0210099</idno>
		<title level="m">ApJL, 580, L171, ADS</title>
		<imprint>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Morello</surname></persName>
		</author>
		<idno>1503.05309</idno>
	</analytic>
	<monogr>
		<title level="j">ApJ</title>
		<imprint>
			<biblScope unit="volume">808</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Moutou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Bouchy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mayor</surname></persName>
		</author>
		<idno type="arXiv">arXiv:astro-ph/0407635</idno>
	</analytic>
	<monogr>
		<title level="j">A&amp;A</title>
		<imprint>
			<biblScope unit="volume">424</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nymeyer</surname></persName>
		</author>
		<idno>1005.1017</idno>
	</analytic>
	<monogr>
		<title level="j">ApJ</title>
		<imprint>
			<biblScope unit="volume">742</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Pont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Zucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Queloz</surname></persName>
		</author>
		<idno type="arXiv">arXiv:astro-ph/0608597</idno>
	</analytic>
	<monogr>
		<title level="j">MNRAS</title>
		<imprint>
			<biblScope unit="volume">373</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gilks</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annals of Applied Probability</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">110</biblScope>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Statistics and data analysis for financial engineering-with R examples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ruppert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Matteson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Springer Texts in Statistics</title>
		<meeting><address><addrLine>New York), xxvi+719, ISBN</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="978" to="979" />
		</imprint>
	</monogr>
	<note>2nd edn</note>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Data Analysis: A Bayesian Tutorial</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sivia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Skilling</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>Oxford University Press</publisher>
			<biblScope unit="page">198568320</biblScope>
			<pubPlace>USA</pubPlace>
		</imprint>
	</monogr>
	<note>2nd edn.</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Southworth</surname></persName>
		</author>
		<idno>0802.3764</idno>
	</analytic>
	<monogr>
		<title level="j">MNRAS</title>
		<imprint>
			<biblScope unit="volume">386</biblScope>
			<date type="published" when="1644" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Stevenson</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1010.4591</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">464</biblScope>
			<biblScope unit="page">1161</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Stevenson</surname></persName>
		</author>
		<idno>1207.4245</idno>
	</analytic>
	<monogr>
		<title level="j">ApJ</title>
		<imprint>
			<biblScope unit="volume">754</biblScope>
			<date type="published" when="1108" />
		</imprint>
	</monogr>
	<note>ApJ</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ter Braak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page">239</biblScope>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J F</forename><surname>Ter Braak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Vrugt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page">435</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Winn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ADS</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page">4475</biblScope>
			<date type="published" when="1076" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Wong</surname></persName>
		</author>
		<idno>1505.03158</idno>
	</analytic>
	<monogr>
		<title level="j">ApJ</title>
		<imprint>
			<biblScope unit="volume">811</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wornell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Oppenheim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Signal Processing</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page">611</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
				<title level="m">Information Theory, IEEE Transactions on</title>
		<imprint>
			<date type="published" when="1992" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page">785</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
				<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">W</forename><surname>Wornell</surname></persName>
		</author>
		<title level="m">Signal Processing with Fractals: A Wavelet-based Approach</title>
		<meeting><address><addrLine>Upper Saddle River, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice Hall PTR</publisher>
			<date type="published" when="1428" />
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page">13120999</biblScope>
		</imprint>
	</monogr>
	<note>Proceedings of the IEEE</note>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C.-F</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">501</biblScope>
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Zellem</surname></persName>
		</author>
		<idno>1405.5923</idno>
	</analytic>
	<monogr>
		<title level="j">ApJ</title>
		<imprint>
			<biblScope unit="volume">790</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>ADS</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">An introduction to Bayesian inference in econometrics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Zellner</surname></persName>
		</author>
		<idno>ISBN: 978-0-471-98165-7</idno>
		<imprint>
			<date type="published" when="1971" />
			<publisher>J. Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
