{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "# from unidecode import unidecode\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy import displacy\n",
    "nlp = spacy.load('en_core_web_md', disable=[\"ner\", \"textcat\", \"entity_ruler\", \"merge_noun_chunks\", \"merge_entities\", \"merge_subtokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\"compact\": True, \"bg\": \"#09a3d5\",\n",
    "           \"color\": \"white\", \"font\": \"Source Sans Pro\",\"collapse_phrases\":False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfExoplanetsDoc=pd.read_pickle(\"/Users/gerdgrasshoff/Dropbox/temp/df_doc.pcl\")\n",
    "# dfExoplanetsDoc=pd.read_pickle(\"c:/Dropbox/temp/df_doc.pcl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dfExoplanetsDoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for doc in dfExoplanetsDoc:\n",
    "    sent = []\n",
    "    for sent in doc.sents:\n",
    "              sentences.append(sent.string.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfExoplanetsDoc[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showsentence(nrdoc,nr):\n",
    "    s=list(dfExoplanetsDoc[nrdoc].sents)\n",
    "    return(s[nr])\n",
    "def splitsent(doc,nr):\n",
    "    return(list(doc.sents)[nr])\n",
    "def lsent(doc):\n",
    "    return(list(doc.sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=lsent(dfExoplanetsDoc[10])\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency label\n",
    "https://github.com/clir/clearnlp-guidelines/blob/master/md/specifications/dependency_labels.md\n",
    "\n",
    "https://stackoverflow.com/questions/40288323/what-do-spacys-part-of-speech-and-dependency-tags-mean/40288324\n",
    "\n",
    "https://nlp.stanford.edu/software/dependencies_manual.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "satz=s[1]\n",
    "satz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(nlp(satz), style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(t.text,t.pos_,t.dep_,t.head.text,t.head.pos_,[c for c in t.children]) for t in satz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phil_satz(satz):\n",
    "    merkmal = dict({\"satz\":satz.text})\n",
    "    for t in satz:\n",
    "        if t.dep_ == \"ROOT\":\n",
    "            r=t.head.text\n",
    "            merkmal.update({\"act\":r})\n",
    "#    print(\"root:\",merkmal[\"act\"])\n",
    "    for t in satz:\n",
    "#        print(\"CHECK\",t.text,\"             ATT=\",t.dep_,t.head.text,t.head.pos_)\n",
    "        if t.dep_ == \"dobj\" and t.head.pos_ == \"VERB\":\n",
    "            merkmal.update({\"obj\":''.join(w.text_with_ws for w in t.subtree)})\n",
    "        if t.dep_ == \"nsubj\" and merkmal[\"act\"]==t.head.text:\n",
    "            merkmal.update({\"subject\":t.text.lower()})\n",
    "        if t.dep_ in (\"ccomp\"):\n",
    "            merkmal.update({\"ccomp\":''.join(w.text_with_ws for w in t.subtree)})\n",
    "        if t.dep_ in (\"acomp\"):\n",
    "            merkmal.update({\"acomp\":''.join(w.text_with_ws for w in t.subtree)})\n",
    "\n",
    "    return(merkmal)\n",
    "phil_satz(satz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[]\n",
    "df=pd.DataFrame(columns=[\"satz\",\"subject\",\"act\",\"ccomp\",\"acomp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    s=sentences[i]\n",
    "    p=phil_satz(nlp(s))\n",
    "    df=df.append(p,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 260)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=df[df[\"subject\"]==\"we\"]\n",
    "dfs.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAct=df.groupby([\"subject\",\"act\"]).size().sort_values(ascending=False).reset_index()\n",
    "dfAct[dfAct[\"subject\"]==\"we\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
